name: Supervised Classification, features: dresses-sales
{'X_train': {'cols': 0.13864942528735633, 'rows': 0.8160919540229885}, 'X_valid': {'cols': 0.14962121212121213, 'rows': 0.8295454545454546}, 'X_test': {'cols': 0.14733333333333334, 'rows': 0.8}}
dataset sizes
(356, 12) (88, 12) (125, 12)
dropped dataset sizes
(65, 12) (15, 12) (25, 12)
key: 7944, k: 1/4, dataset: 23381, missing: None, impute: None
{'d_model': 23, 'embedding_size': 81, 'embedding_layers': 3, 'encoder_heads': 4, 'encoder_layers': 5, 'decoder_heads': 3, 'decoder_layers': 3, 'net_size': 109, 'net_layers': 3, 'max_steps': 2206, 'learning_rate': 0.0001, 'batch_size': 128, 'early_stop': 0.730604498135526, 'noise_std': 0.1424050966091465}
MAP
2 device(s)
optimizer: adam, lr: 9.999999747378752e-05, batch_size=128
  0%|                                                                                                                                                                                                                                                                                              | 0/1103 [00:00<?, ?it/s]
  0%|                                                                                                                                                                                                                                                                                                 | 0/2 [00:00<?, ?it/s]

Final test loss: 1.2891578674316406, epoch: 1086, time: 0:01:14.649796
(125, 2)
softmax
0.5193937 -2.0751665
0.9204349 0.07956513

strategy:None, acc lsam:0.56
strategy:None, nll lsam:1.4021351337432861
name: Supervised Classification, features: dresses-sales
{'X_train': {'cols': 0.13842592592592592, 'rows': 0.8027777777777778}, 'X_valid': {'cols': 0.1574074074074074, 'rows': 0.8111111111111111}, 'X_test': {'cols': 0.146, 'rows': 0.832}}
dataset sizes
(366, 12) (90, 12) (125, 12)
dropped dataset sizes
(72, 12) (17, 12) (21, 12)
key: 6605, k: 2/4, dataset: 23381, missing: None, impute: None
{'d_model': 23, 'embedding_size': 81, 'embedding_layers': 3, 'encoder_heads': 4, 'encoder_layers': 5, 'decoder_heads': 3, 'decoder_layers': 3, 'net_size': 109, 'net_layers': 3, 'max_steps': 2206, 'learning_rate': 0.0001, 'batch_size': 128, 'early_stop': 0.730604498135526, 'noise_std': 0.1424050966091465}
MAP
2 device(s)
optimizer: adam, lr: 9.999999747378752e-05, batch_size=128
  0%|                                                                                                                                                                                                                                                                                              | 0/1103 [00:00<?, ?it/s]

 48%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                           | 525/1103 [00:37<00:29, 19.58it/s, l=1.33, tl=inf, tlc=1.35, tc=0, e=-.693]

 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 606/1103 [00:42<00:25, 19.35it/s, l=1.31, tl=inf, tlc=1.45, tc=0, e=-.693]





 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                    | 1004/1103 [01:00<00:04, 20.13it/s, l=1.28, tl=1.25, tlc=1.37, tc=110, e=-.693]

  0%|                                                                                                                                                                                                                                                                                                 | 0/1 [00:00<?, ?it/s]
(125, 2)
softmax
0.2558559 -2.0367036
0.8643496 0.13565043
strategy:None, acc lsam:0.568
strategy:None, nll lsam:1.3863664865493774
name: Supervised Classification, features: dresses-sales
{'X_train': {'cols': 0.1506782945736434, 'rows': 0.813953488372093}, 'X_valid': {'cols': 0.14631782945736435, 'rows': 0.8023255813953488}, 'X_test': {'cols': 0.12533333333333332, 'rows': 0.792}}
dataset sizes
(372, 12) (86, 12) (125, 12)
dropped dataset sizes
(70, 12) (17, 12) (26, 12)
key: 1642, k: 3/4, dataset: 23381, missing: None, impute: None
{'d_model': 23, 'embedding_size': 81, 'embedding_layers': 3, 'encoder_heads': 4, 'encoder_layers': 5, 'decoder_heads': 3, 'decoder_layers': 3, 'net_size': 109, 'net_layers': 3, 'max_steps': 2206, 'learning_rate': 0.0001, 'batch_size': 128, 'early_stop': 0.730604498135526, 'noise_std': 0.1424050966091465}
MAP
2 device(s)

  0%|                                                                                                                                                                                                                                                                                              | 0/1103 [00:00<?, ?it/s]


 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                              | 809/1103 [00:47<00:12, 22.78it/s, l=1.29, tl=1.46, tlc=1.46, tc=0, e=-.693]
  0%|                                                                                                                                                                                                                                                                                                 | 0/2 [00:00<?, ?it/s]

Final test loss: 1.390979528427124, epoch: 956, time: 0:00:53.353044
(125, 2)
softmax
-0.8795702 -2.8724468
0.8742492 0.12575085
strategy:None, acc lsam:0.592
strategy:None, nll lsam:1.3435109853744507
name: Supervised Classification, features: dresses-sales
{'X_train': {'cols': 0.14429695181907573, 'rows': 0.8112094395280236}, 'X_valid': {'cols': 0.14411764705882354, 'rows': 0.8117647058823529}, 'X_test': {'cols': 0.13799999999999998, 'rows': 0.784}}
dataset sizes
(350, 12) (85, 12) (125, 12)
dropped dataset sizes
(64, 12) (16, 12) (27, 12)
key: 5429, k: 4/4, dataset: 23381, missing: None, impute: None
{'d_model': 23, 'embedding_size': 81, 'embedding_layers': 3, 'encoder_heads': 4, 'encoder_layers': 5, 'decoder_heads': 3, 'decoder_layers': 3, 'net_size': 109, 'net_layers': 3, 'max_steps': 2206, 'learning_rate': 0.0001, 'batch_size': 128, 'early_stop': 0.730604498135526, 'noise_std': 0.1424050966091465}
MAP
2 device(s)

  0%|                                                                                                                                                                                                                                                                                              | 0/1103 [00:00<?, ?it/s]

  5%|██████████▉                                                                                                                                                                                                                                 | 51/1103 [00:12<00:47, 22.16it/s, l=1.41, tl=inf, tlc=1.41, tc=0, e=-.693]


 48%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                            | 524/1103 [00:35<00:24, 23.51it/s, l=1.3, tl=inf, tlc=1.48, tc=0, e=-.693]



 70%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                      | 775/1103 [00:47<00:14, 22.83it/s, l=1.28, tl=inf, tlc=1.36, tc=0, e=-.693]
  0%|                                                                                                                                                                                                                                                                                                 | 0/2 [00:00<?, ?it/s]

Final test loss: 1.2286152839660645, epoch: 1007, time: 0:00:56.539688
(125, 2)
softmax
3.5286384 -1.6829982
0.8595006 0.1404994
strategy:None, acc lsam:0.544

strategy:None, nll lsam:1.3258391618728638