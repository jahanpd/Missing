2022-07-10 21:55:51 ERROR 400 response executing GraphQL.
2022-07-10 21:55:51 ERROR {"errors":[{"message":"Invalid sweep config: 2 is not of type 'string'\n\nFailed validating 'type' in schema['properties']['name']:\n    {'description': 'Name of metric', 'type': 'string'}\n\nOn instance['name']:\n    2","path":["upsertSweep"]}],"data":{"upsertSweep":null}}
2022-07-10 21:55:51 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/lib/retry.py", line 108, in __call__
    result = self._call_fn(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 158, in execute
    return self.client.execute(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 52, in execute
    result = self._get_result(document, *args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 60, in _get_result
    return self.transport.execute(document, *args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py", line 39, in execute
    request.raise_for_status()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/requests/models.py", line 1021, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.wandb.ai/graphql

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 1982, in upsert_sweep
    raise (e)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 1967, in upsert_sweep
    response = self.gql(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/lib/retry.py", line 124, in __call__
    if not check_retry_fn(e):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 1958, in no_retry_4xx
    raise UsageError(body["errors"][0]["message"])
wandb.errors.UsageError: Invalid sweep config: 2 is not of type 'string'

Failed validating 'type' in schema['properties']['name']:
    {'description': 'Name of metric', 'type': 'string'}

On instance['name']:
    2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 916, in sweep
    sweep_id, warnings = api.upsert_sweep(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 102, in upsert_sweep
    return self.api.upsert_sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 1982, in upsert_sweep
    raise (e)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 1967, in upsert_sweep
    response = self.gql(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/lib/retry.py", line 124, in __call__
    if not check_retry_fn(e):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 1958, in no_retry_4xx
    raise UsageError(body["errors"][0]["message"])
wandb.errors.CommError: Invalid sweep config: 2 is not of type 'string'

Failed validating 'type' in schema['properties']['name']:
    {'description': 'Name of metric', 'type': 'string'}

On instance['name']:
    2

2022-07-11 10:07:32 INFO Running runs: []
2022-07-11 10:07:33 INFO Agent received command: run
2022-07-11 10:07:33 INFO Agent starting run with config:
	decoder_heads: 1
	decoder_layers: 9
	early_stopping: 0.3861218020668905
	embedding_layers: 3
	embedding_size: 9
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.005359984234769254
	max_steps: 8920
	net_layers: 6
	net_size: 94
	noise_std: 6.432568090783187
2022-07-11 10:07:33 INFO About to run command: /usr/bin/env python  --model LSAM --dataset 0 --k 4 --repeats 1 --decoder_heads=1 --decoder_layers=9 --early_stopping=0.3861218020668905 --embedding_layers=3 --embedding_size=9 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.005359984234769254 --max_steps=8920 --net_layers=6 --net_size=94 --noise_std=6.432568090783187
2022-07-11 10:07:38 INFO Running runs: ['rka2ac8x']
2022-07-11 10:07:38 INFO Cleaning up finished run: rka2ac8x
2022-07-11 10:07:38 INFO Agent received command: run
2022-07-11 10:07:38 INFO Agent starting run with config:
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.8888181189909824
	embedding_layers: 2
	embedding_size: 17
	encoder_heads: 2
	encoder_layers: 10
	learning_rate: 0.01892762571762766
	max_steps: 7353
	net_layers: 2
	net_size: 121
	noise_std: 4.816570625915341
2022-07-11 10:07:38 INFO About to run command: /usr/bin/env python  --model LSAM --dataset 0 --k 4 --repeats 1 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.8888181189909824 --embedding_layers=2 --embedding_size=17 --encoder_heads=2 --encoder_layers=10 --learning_rate=0.01892762571762766 --max_steps=7353 --net_layers=2 --net_size=121 --noise_std=4.816570625915341
2022-07-11 10:07:43 INFO Running runs: ['b4p5hq6r']
2022-07-11 10:07:43 INFO Cleaning up finished run: b4p5hq6r
2022-07-11 10:07:44 INFO Agent received command: run
2022-07-11 10:07:44 INFO Agent starting run with config:
	decoder_heads: 3
	decoder_layers: 3
	early_stopping: 0.9379472041499528
	embedding_layers: 1
	embedding_size: 53
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.002410773809277303
	max_steps: 7039
	net_layers: 3
	net_size: 44
	noise_std: 5.935312061100498
2022-07-11 10:07:44 INFO About to run command: /usr/bin/env python  --model LSAM --dataset 0 --k 4 --repeats 1 --decoder_heads=3 --decoder_layers=3 --early_stopping=0.9379472041499528 --embedding_layers=1 --embedding_size=53 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.002410773809277303 --max_steps=7039 --net_layers=3 --net_size=44 --noise_std=5.935312061100498
2022-07-11 10:07:49 INFO Running runs: ['pgtgtpmq']
2022-07-11 10:07:49 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-11 10:07:49 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-11 10:07:55 INFO Running runs: []
2022-07-11 10:07:56 INFO Agent received command: run
2022-07-11 10:07:56 INFO Agent starting run with config:
	lightgbm_learning_rate: 10
	max_bin: 77
	max_depth: 5
	min_data_in_leaf: 4
	num_iterations: 4
	num_leaves: 6
2022-07-11 10:07:56 INFO About to run command: /usr/bin/env python  --model LightGBM --dataset 0 --k 4 --repeats 1 --lightgbm_learning_rate=10 --max_bin=77 --max_depth=5 --min_data_in_leaf=4 --num_iterations=4 --num_leaves=6
2022-07-11 10:08:01 INFO Running runs: ['wz8pdjuh']
2022-07-11 10:08:01 INFO Cleaning up finished run: wz8pdjuh
2022-07-11 10:08:02 INFO Agent received command: run
2022-07-11 10:08:02 INFO Agent starting run with config:
	lightgbm_learning_rate: 2
	max_bin: 38
	max_depth: 8
	min_data_in_leaf: 5
	num_iterations: 4
	num_leaves: 4
2022-07-11 10:08:02 INFO About to run command: /usr/bin/env python  --model LightGBM --dataset 0 --k 4 --repeats 1 --lightgbm_learning_rate=2 --max_bin=38 --max_depth=8 --min_data_in_leaf=5 --num_iterations=4 --num_leaves=4
2022-07-11 10:22:21 INFO Running runs: []
2022-07-11 10:22:21 INFO Agent received command: run
2022-07-11 10:22:21 INFO Agent starting run with config:
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 0.5258536111693287
	embedding_layers: 3
	embedding_size: 87
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.04969635038488753
	max_steps: 3268
	net_layers: 1
	net_size: 54
	noise_std: 1.8264905168017065
2022-07-11 10:22:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --decoder_heads=3 --decoder_layers=8 --early_stopping=0.5258536111693287 --embedding_layers=3 --embedding_size=87 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.04969635038488753 --max_steps=3268 --net_layers=1 --net_size=54 --noise_std=1.8264905168017065
2022-07-11 10:22:26 INFO Running runs: ['1lszd8wk']
2022-07-11 10:22:37 INFO Cleaning up finished run: 1lszd8wk
2022-07-11 10:22:37 INFO Agent received command: run
2022-07-11 10:22:37 INFO Agent starting run with config:
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.985156390724366
	embedding_layers: 4
	embedding_size: 87
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.04895722129091067
	max_steps: 4604
	net_layers: 2
	net_size: 112
	noise_std: 4.895408300240416
2022-07-11 10:22:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --decoder_heads=1 --decoder_layers=7 --early_stopping=0.985156390724366 --embedding_layers=4 --embedding_size=87 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.04895722129091067 --max_steps=4604 --net_layers=2 --net_size=112 --noise_std=4.895408300240416
2022-07-11 10:23:56 INFO Running runs: []
2022-07-11 10:23:56 INFO Agent received command: run
2022-07-11 10:23:56 INFO Agent starting run with config:
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.01701539858718959
	embedding_layers: 4
	embedding_size: 69
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.010368334990591728
	max_steps: 3786
	net_layers: 6
	net_size: 107
	noise_std: 3.0412764832858152
2022-07-11 10:23:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --decoder_heads=1 --decoder_layers=7 --early_stopping=0.01701539858718959 --embedding_layers=4 --embedding_size=69 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.010368334990591728 --max_steps=3786 --net_layers=6 --net_size=107 --noise_std=3.0412764832858152
2022-07-11 10:24:01 INFO Running runs: ['dkyjbsuw']
2022-07-11 10:28:06 INFO Running runs: []
2022-07-11 10:28:07 INFO Agent received command: run
2022-07-11 10:28:07 INFO Agent starting run with config:
	decoder_heads: 2
	decoder_layers: 10
	early_stopping: 0.8670114961845203
	embedding_layers: 2
	embedding_size: 35
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.0006010060588777084
	max_steps: 8683
	net_layers: 5
	net_size: 25
	noise_std: 0.7725464784181794
2022-07-11 10:28:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --decoder_heads=2 --decoder_layers=10 --early_stopping=0.8670114961845203 --embedding_layers=2 --embedding_size=35 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.0006010060588777084 --max_steps=8683 --net_layers=5 --net_size=25 --noise_std=0.7725464784181794
2022-07-11 10:28:12 INFO Running runs: ['hzhc6e4z']
2022-07-11 10:30:01 INFO Running runs: []
2022-07-11 10:30:01 INFO Agent received command: run
2022-07-11 10:30:01 INFO Agent starting run with config:
	lightgbm_learning_rate: 7
	max_bin: 101
	max_depth: 2
	min_data_in_leaf: 4
	num_iterations: 4
	num_leaves: 3
2022-07-11 10:30:01 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=7 --max_bin=101 --max_depth=2 --min_data_in_leaf=4 --num_iterations=4 --num_leaves=3
2022-07-11 10:30:06 INFO Running runs: ['wmg7017h']
2022-07-11 10:30:23 INFO Cleaning up finished run: wmg7017h
2022-07-11 10:30:23 INFO Agent received command: run
2022-07-11 10:30:23 INFO Agent starting run with config:
	lightgbm_learning_rate: 9
	max_bin: 33
	max_depth: 8
	min_data_in_leaf: 3
	num_iterations: 2
	num_leaves: 3
2022-07-11 10:30:23 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=9 --max_bin=33 --max_depth=8 --min_data_in_leaf=3 --num_iterations=2 --num_leaves=3
2022-07-11 10:30:28 INFO Running runs: ['xgaq4lpz']
2022-07-11 10:30:55 INFO Cleaning up finished run: xgaq4lpz
2022-07-11 10:31:22 INFO Agent received command: run
2022-07-11 10:31:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 1
	max_bin: 111
	max_depth: 9
	min_data_in_leaf: 1
	num_iterations: 4
	num_leaves: 2
2022-07-11 10:31:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=1 --max_bin=111 --max_depth=9 --min_data_in_leaf=1 --num_iterations=4 --num_leaves=2
2022-07-11 10:31:27 INFO Running runs: ['1rgylk4h']
2022-07-11 10:35:44 INFO Running runs: []
2022-07-11 10:35:44 INFO Agent received command: run
2022-07-11 10:35:44 INFO Agent starting run with config:
	d_model: 7
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.24084852673630475
	embedding_layers: 2
	embedding_size: 95
	encoder_heads: 2
	encoder_layers: 3
	learning_rate: 0.038038074558916606
	max_steps: 9344
	net_layers: 1
	net_size: 122
	noise_std: 0.7522384879586114
2022-07-11 10:35:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --d_model=7 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.24084852673630475 --embedding_layers=2 --embedding_size=95 --encoder_heads=2 --encoder_layers=3 --learning_rate=0.038038074558916606 --max_steps=9344 --net_layers=1 --net_size=122 --noise_std=0.7522384879586114
2022-07-11 10:35:49 INFO Running runs: ['u3fi5h57']
2022-07-11 10:54:04 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/4l8mfcep not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/4l8mfcep not found

2022-07-11 10:54:05 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/6m22n6f2 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/6m22n6f2 not found

2022-07-11 10:54:08 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/f0eiuyw0 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/f0eiuyw0 not found

2022-07-11 10:54:08 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/p6o53s4n not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/p6o53s4n not found

2022-07-11 10:54:11 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/havm3uqu not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/havm3uqu not found

2022-07-11 10:54:12 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/cl6lwpyz not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/cl6lwpyz not found

2022-07-11 10:54:14 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/j13oi5lo not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/j13oi5lo not found

2022-07-11 10:54:15 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/g5z5tjzv not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/g5z5tjzv not found

2022-07-11 10:54:18 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/lzg7xvz9 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/lzg7xvz9 not found

2022-07-11 10:54:19 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/7dqwii7a not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/7dqwii7a not found

2022-07-11 10:54:21 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/n4fhmcbg not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/n4fhmcbg not found

2022-07-11 10:54:22 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/887upcmq not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/887upcmq not found

2022-07-11 10:57:50 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/zpbsf0oi not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/zpbsf0oi not found

2022-07-11 10:57:51 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/4x2ciwlg not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/4x2ciwlg not found

2022-07-11 10:57:54 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/a795h9im not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/a795h9im not found

2022-07-11 10:57:59 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/typd2s7t not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/typd2s7t not found

2022-07-11 10:58:00 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/hxctsklq not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/hxctsklq not found

2022-07-11 10:58:02 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/9br82cg5 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/9br82cg5 not found

2022-07-11 10:58:03 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/2f29ahe0 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/2f29ahe0 not found

2022-07-11 10:58:05 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/phcvi91h not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/phcvi91h not found

2022-07-11 10:58:07 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/2hyirbuv not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/2hyirbuv not found

2022-07-11 10:58:09 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/lsam/whgcap6s not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/lsam/whgcap6s not found

2022-07-11 11:03:02 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/amj4x59n not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/amj4x59n not found

2022-07-11 11:03:03 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/ztmnv0rb not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/ztmnv0rb not found

2022-07-11 11:03:06 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/gc8i5fah not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/gc8i5fah not found

2022-07-11 11:03:07 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/2x26uzm9 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/2x26uzm9 not found

2022-07-11 11:03:26 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/tm9ybv1i not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/tm9ybv1i not found

2022-07-11 11:03:27 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/0xohayz9 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/0xohayz9 not found

2022-07-11 11:04:21 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/4nip9mno not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/4nip9mno not found

2022-07-11 11:04:21 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/up6f5bdp not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/up6f5bdp not found

2022-07-11 11:04:24 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/dz5dzclt not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/dz5dzclt not found

2022-07-11 11:04:25 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/8h30nmln not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/8h30nmln not found

2022-07-11 11:04:42 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/rnhrqer4 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/rnhrqer4 not found

2022-07-11 11:04:43 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/kkmuyyt1 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/kkmuyyt1 not found

2022-07-11 11:04:45 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/04bbx9wu not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/04bbx9wu not found

2022-07-11 11:04:46 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/LSAM/f4vbvq2i not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/LSAM/f4vbvq2i not found

2022-07-11 11:15:04 INFO Running runs: []
2022-07-11 11:15:04 INFO Agent received command: run
2022-07-11 11:15:04 INFO Agent starting run with config:
	batch_size: 128
	d_model: 46
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.4062950770761812
	embedding_layers: 2
	embedding_size: 68
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 7291
	net_layers: 2
	net_size: 84
	noise_std: 0.8882307847953055
2022-07-11 11:15:04 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=46 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.4062950770761812 --embedding_layers=2 --embedding_size=68 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.0005 --max_steps=7291 --net_layers=2 --net_size=84 --noise_std=0.8882307847953055
2022-07-11 11:15:09 INFO Running runs: ['d7jq2mlg']
2022-07-11 11:15:09 INFO Cleaning up finished run: d7jq2mlg
2022-07-11 11:15:10 INFO Agent received command: run
2022-07-11 11:15:10 INFO Agent starting run with config:
	batch_size: 64
	d_model: 54
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.7020736588871954
	embedding_layers: 1
	embedding_size: 33
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.01
	max_steps: 6920
	net_layers: 3
	net_size: 90
	noise_std: 0.812382982729102
2022-07-11 11:15:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=54 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.7020736588871954 --embedding_layers=1 --embedding_size=33 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.01 --max_steps=6920 --net_layers=3 --net_size=90 --noise_std=0.812382982729102
2022-07-11 11:15:15 INFO Running runs: ['npxqknxk']
2022-07-11 11:15:15 INFO Cleaning up finished run: npxqknxk
2022-07-11 11:15:16 INFO Agent received command: run
2022-07-11 11:15:16 INFO Agent starting run with config:
	batch_size: 64
	d_model: 49
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.9195056475869462
	embedding_layers: 2
	embedding_size: 36
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 4297
	net_layers: 3
	net_size: 115
	noise_std: 0.5657809860384324
2022-07-11 11:15:16 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=49 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.9195056475869462 --embedding_layers=2 --embedding_size=36 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.001 --max_steps=4297 --net_layers=3 --net_size=115 --noise_std=0.5657809860384324
2022-07-11 11:18:30 INFO Running runs: []
2022-07-11 11:18:31 INFO Agent received command: run
2022-07-11 11:18:31 INFO Agent starting run with config:
	batch_size: 64
	d_model: 85
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.8282235315055306
	embedding_layers: 1
	embedding_size: 85
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 3549
	net_layers: 3
	net_size: 86
	noise_std: 1.1647694401466189
2022-07-11 11:18:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=85 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.8282235315055306 --embedding_layers=1 --embedding_size=85 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.0001 --max_steps=3549 --net_layers=3 --net_size=86 --noise_std=1.1647694401466189
2022-07-11 11:18:36 INFO Running runs: ['zen3v02r']
2022-07-11 11:20:23 INFO Running runs: []
2022-07-11 11:20:24 INFO Agent received command: run
2022-07-11 11:20:24 INFO Agent starting run with config:
	batch_size: 4
	d_model: 32
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.5555333716195381
	embedding_layers: 1
	embedding_size: 19
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.0005
	max_steps: 1742
	net_layers: 2
	net_size: 62
	noise_std: 0.8731369682169096
2022-07-11 11:20:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=32 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.5555333716195381 --embedding_layers=1 --embedding_size=19 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.0005 --max_steps=1742 --net_layers=2 --net_size=62 --noise_std=0.8731369682169096
2022-07-11 11:20:29 INFO Running runs: ['mfuonsk4']
2022-07-11 11:21:05 INFO Running runs: []
2022-07-11 11:21:42 INFO Running runs: []
2022-07-11 11:21:43 INFO Agent received command: run
2022-07-11 11:21:43 INFO Agent starting run with config:
	batch_size: 32
	d_model: 17
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.11472836999902648
	embedding_layers: 1
	embedding_size: 55
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 6995
	net_layers: 1
	net_size: 9
	noise_std: 1.1763545218626132
2022-07-11 11:21:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=17 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.11472836999902648 --embedding_layers=1 --embedding_size=55 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.0005 --max_steps=6995 --net_layers=1 --net_size=9 --noise_std=1.1763545218626132
2022-07-11 11:21:48 INFO Running runs: ['1a30tf68']
2022-07-11 11:25:59 INFO Cleaning up finished run: 1a30tf68
2022-07-11 11:25:59 INFO Agent received command: run
2022-07-11 11:25:59 INFO Agent starting run with config:
	batch_size: 32
	d_model: 92
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.5759732284349983
	embedding_layers: 2
	embedding_size: 21
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 7820
	net_layers: 1
	net_size: 47
	noise_std: 0.34141488339454445
2022-07-11 11:25:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=92 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.5759732284349983 --embedding_layers=2 --embedding_size=21 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0005 --max_steps=7820 --net_layers=1 --net_size=47 --noise_std=0.34141488339454445
2022-07-11 11:26:04 INFO Running runs: ['gkrt4wed']
2022-07-11 11:36:07 INFO Cleaning up finished run: gkrt4wed
2022-07-11 11:36:08 INFO Agent received command: run
2022-07-11 11:36:08 INFO Agent starting run with config:
	batch_size: 64
	d_model: 17
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.24285403864257504
	embedding_layers: 1
	embedding_size: 12
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 8413
	net_layers: 2
	net_size: 120
	noise_std: 0.6224842565928234
2022-07-11 11:36:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=17 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.24285403864257504 --embedding_layers=1 --embedding_size=12 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.001 --max_steps=8413 --net_layers=2 --net_size=120 --noise_std=0.6224842565928234
2022-07-11 11:36:13 INFO Running runs: ['qk8c1ew1']
2022-07-11 11:41:28 INFO Cleaning up finished run: qk8c1ew1
2022-07-11 11:41:29 INFO Agent received command: run
2022-07-11 11:41:29 INFO Agent starting run with config:
	batch_size: 16
	d_model: 60
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.44656311075111776
	embedding_layers: 3
	embedding_size: 39
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.0005
	max_steps: 6734
	net_layers: 2
	net_size: 47
	noise_std: 0.25116320915392126
2022-07-11 11:41:29 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=60 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.44656311075111776 --embedding_layers=3 --embedding_size=39 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.0005 --max_steps=6734 --net_layers=2 --net_size=47 --noise_std=0.25116320915392126
2022-07-11 11:41:34 INFO Running runs: ['1onr6kj7']
2022-07-11 11:49:19 INFO Cleaning up finished run: 1onr6kj7
2022-07-11 11:49:20 INFO Agent received command: run
2022-07-11 11:49:20 INFO Agent starting run with config:
	batch_size: 8
	d_model: 96
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.7129824954642864
	embedding_layers: 3
	embedding_size: 17
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 5647
	net_layers: 2
	net_size: 30
	noise_std: 0.0890397662438452
2022-07-11 11:49:20 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=96 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.7129824954642864 --embedding_layers=3 --embedding_size=17 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0005 --max_steps=5647 --net_layers=2 --net_size=30 --noise_std=0.0890397662438452
2022-07-11 11:49:25 INFO Running runs: ['mri9yuf9']
2022-07-11 11:59:12 INFO Cleaning up finished run: mri9yuf9
2022-07-11 11:59:13 INFO Agent received command: run
2022-07-11 11:59:13 INFO Agent starting run with config:
	batch_size: 64
	d_model: 106
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.8971737716634349
	embedding_layers: 3
	embedding_size: 21
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 4327
	net_layers: 1
	net_size: 9
	noise_std: 0.07207511832538759
2022-07-11 11:59:13 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=106 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.8971737716634349 --embedding_layers=3 --embedding_size=21 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0001 --max_steps=4327 --net_layers=1 --net_size=9 --noise_std=0.07207511832538759
2022-07-11 11:59:18 INFO Running runs: ['31547tvj']
2022-07-11 12:07:16 INFO Cleaning up finished run: 31547tvj
2022-07-11 12:07:17 INFO Agent received command: run
2022-07-11 12:07:17 INFO Agent starting run with config:
	batch_size: 4
	d_model: 107
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.47074695172245096
	embedding_layers: 2
	embedding_size: 14
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 8249
	net_layers: 3
	net_size: 35
	noise_std: 0.5069516209280871
2022-07-11 12:07:17 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=107 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.47074695172245096 --embedding_layers=2 --embedding_size=14 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.0001 --max_steps=8249 --net_layers=3 --net_size=35 --noise_std=0.5069516209280871
2022-07-11 12:07:22 INFO Running runs: ['o3dr1ge5']
2022-07-11 12:18:42 INFO Cleaning up finished run: o3dr1ge5
2022-07-11 12:18:42 INFO Agent received command: run
2022-07-11 12:18:42 INFO Agent starting run with config:
	batch_size: 16
	d_model: 49
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.4715187479640536
	embedding_layers: 2
	embedding_size: 22
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 4333
	net_layers: 1
	net_size: 66
	noise_std: 0.03155820558426675
2022-07-11 12:18:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=49 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.4715187479640536 --embedding_layers=2 --embedding_size=22 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.001 --max_steps=4333 --net_layers=1 --net_size=66 --noise_std=0.03155820558426675
2022-07-11 12:18:47 INFO Running runs: ['s7yltdap']
2022-07-11 12:24:51 INFO Cleaning up finished run: s7yltdap
2022-07-11 12:24:52 INFO Agent received command: run
2022-07-11 12:24:52 INFO Agent starting run with config:
	batch_size: 4
	d_model: 126
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.8892043308443996
	embedding_layers: 3
	embedding_size: 11
	encoder_heads: 5
	encoder_layers: 2
	learning_rate: 0.005
	max_steps: 6836
	net_layers: 2
	net_size: 91
	noise_std: 0.10200929461367832
2022-07-11 12:24:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=126 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.8892043308443996 --embedding_layers=3 --embedding_size=11 --encoder_heads=5 --encoder_layers=2 --learning_rate=0.005 --max_steps=6836 --net_layers=2 --net_size=91 --noise_std=0.10200929461367832
2022-07-11 12:24:57 INFO Running runs: ['lmpmski7']
2022-07-11 12:38:09 INFO Cleaning up finished run: lmpmski7
2022-07-11 12:38:10 INFO Agent received command: run
2022-07-11 12:38:10 INFO Agent starting run with config:
	batch_size: 128
	d_model: 35
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.2024814760986944
	embedding_layers: 2
	embedding_size: 78
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 9094
	net_layers: 2
	net_size: 20
	noise_std: 0.3472942780500259
2022-07-11 12:38:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=35 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.2024814760986944 --embedding_layers=2 --embedding_size=78 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.0001 --max_steps=9094 --net_layers=2 --net_size=20 --noise_std=0.3472942780500259
2022-07-11 12:38:15 INFO Running runs: ['7514tukn']
2022-07-11 12:45:32 INFO Cleaning up finished run: 7514tukn
2022-07-11 12:45:33 INFO Agent received command: run
2022-07-11 12:45:33 INFO Agent starting run with config:
	batch_size: 64
	d_model: 15
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.31154208520427273
	embedding_layers: 2
	embedding_size: 35
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 4931
	net_layers: 3
	net_size: 36
	noise_std: 0.2472427964839849
2022-07-11 12:45:33 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=15 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.31154208520427273 --embedding_layers=2 --embedding_size=35 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0005 --max_steps=4931 --net_layers=3 --net_size=36 --noise_std=0.2472427964839849
2022-07-11 12:45:38 INFO Running runs: ['mze6u0tp']
2022-07-11 12:51:42 INFO Cleaning up finished run: mze6u0tp
2022-07-11 12:51:42 INFO Agent received command: run
2022-07-11 12:51:42 INFO Agent starting run with config:
	batch_size: 32
	d_model: 12
	decoder_heads: 3
	decoder_layers: 3
	early_stopping: 0.7789381480607094
	embedding_layers: 2
	embedding_size: 22
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 6051
	net_layers: 2
	net_size: 19
	noise_std: 0.4861693651754422
2022-07-11 12:51:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=12 --decoder_heads=3 --decoder_layers=3 --early_stopping=0.7789381480607094 --embedding_layers=2 --embedding_size=22 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.0005 --max_steps=6051 --net_layers=2 --net_size=19 --noise_std=0.4861693651754422
2022-07-11 12:51:47 INFO Running runs: ['k5hujg5z']
2022-07-11 13:01:30 INFO Cleaning up finished run: k5hujg5z
2022-07-11 13:01:31 INFO Agent received command: run
2022-07-11 13:01:31 INFO Agent starting run with config:
	batch_size: 8
	d_model: 16
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.24121076039158215
	embedding_layers: 3
	embedding_size: 54
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 8488
	net_layers: 2
	net_size: 58
	noise_std: 0.6949946063976423
2022-07-11 13:01:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=16 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.24121076039158215 --embedding_layers=3 --embedding_size=54 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0001 --max_steps=8488 --net_layers=2 --net_size=58 --noise_std=0.6949946063976423
2022-07-11 13:01:36 INFO Running runs: ['a0q264r0']
2022-07-11 13:09:44 INFO Cleaning up finished run: a0q264r0
2022-07-11 13:09:45 INFO Agent received command: run
2022-07-11 13:09:45 INFO Agent starting run with config:
	batch_size: 32
	d_model: 46
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.5769533827966451
	embedding_layers: 2
	embedding_size: 65
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 3516
	net_layers: 2
	net_size: 21
	noise_std: 0.10840423026318924
2022-07-11 13:09:45 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=46 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.5769533827966451 --embedding_layers=2 --embedding_size=65 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.0001 --max_steps=3516 --net_layers=2 --net_size=21 --noise_std=0.10840423026318924
2022-07-11 13:09:50 INFO Running runs: ['0g98rf3c']
2022-07-11 13:15:13 INFO Cleaning up finished run: 0g98rf3c
2022-07-11 13:15:14 INFO Agent received command: run
2022-07-11 13:15:14 INFO Agent starting run with config:
	batch_size: 32
	d_model: 16
	decoder_heads: 3
	decoder_layers: 3
	early_stopping: 0.33904200707898147
	embedding_layers: 3
	embedding_size: 54
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 2798
	net_layers: 2
	net_size: 14
	noise_std: 0.26214948205604754
2022-07-11 13:15:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=16 --decoder_heads=3 --decoder_layers=3 --early_stopping=0.33904200707898147 --embedding_layers=3 --embedding_size=54 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.001 --max_steps=2798 --net_layers=2 --net_size=14 --noise_std=0.26214948205604754
2022-07-11 13:15:19 INFO Running runs: ['3onypqxo']
2022-07-11 13:19:13 INFO Cleaning up finished run: 3onypqxo
2022-07-11 13:19:14 INFO Agent received command: run
2022-07-11 13:19:14 INFO Agent starting run with config:
	batch_size: 16
	d_model: 45
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.055046644712474446
	embedding_layers: 2
	embedding_size: 9
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 7014
	net_layers: 2
	net_size: 45
	noise_std: 1.2808846729867116
2022-07-11 13:19:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=45 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.055046644712474446 --embedding_layers=2 --embedding_size=9 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.0001 --max_steps=7014 --net_layers=2 --net_size=45 --noise_std=1.2808846729867116
2022-07-11 13:19:19 INFO Running runs: ['0y3x1ujb']
2022-07-11 13:23:34 INFO Cleaning up finished run: 0y3x1ujb
2022-07-11 13:23:35 INFO Agent received command: run
2022-07-11 13:23:35 INFO Agent starting run with config:
	batch_size: 32
	d_model: 21
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.07540748399198327
	embedding_layers: 3
	embedding_size: 28
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 7603
	net_layers: 1
	net_size: 15
	noise_std: 0.6721996260553168
2022-07-11 13:23:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=21 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.07540748399198327 --embedding_layers=3 --embedding_size=28 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0005 --max_steps=7603 --net_layers=1 --net_size=15 --noise_std=0.6721996260553168
2022-07-11 13:23:40 INFO Running runs: ['kvg4xcas']
2022-07-11 13:28:02 INFO Cleaning up finished run: kvg4xcas
2022-07-11 13:28:02 INFO Agent received command: run
2022-07-11 13:28:02 INFO Agent starting run with config:
	batch_size: 64
	d_model: 25
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.3008247423464888
	embedding_layers: 2
	embedding_size: 26
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 5808
	net_layers: 1
	net_size: 44
	noise_std: 0.403663878965206
2022-07-11 13:28:02 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=25 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.3008247423464888 --embedding_layers=2 --embedding_size=26 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001 --max_steps=5808 --net_layers=1 --net_size=44 --noise_std=0.403663878965206
2022-07-11 13:28:07 INFO Running runs: ['dqueworo']
2022-07-11 13:34:50 INFO Cleaning up finished run: dqueworo
2022-07-11 13:34:51 INFO Agent received command: run
2022-07-11 13:34:51 INFO Agent starting run with config:
	batch_size: 128
	d_model: 26
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.2652303145775621
	embedding_layers: 1
	embedding_size: 100
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 4146
	net_layers: 1
	net_size: 23
	noise_std: 0.33747369252731596
2022-07-11 13:34:51 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=26 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.2652303145775621 --embedding_layers=1 --embedding_size=100 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.0001 --max_steps=4146 --net_layers=1 --net_size=23 --noise_std=0.33747369252731596
2022-07-11 13:34:56 INFO Running runs: ['7vf12twc']
2022-07-11 13:40:57 INFO Cleaning up finished run: 7vf12twc
2022-07-11 13:40:58 INFO Agent received command: run
2022-07-11 13:40:58 INFO Agent starting run with config:
	batch_size: 8
	d_model: 53
	decoder_heads: 3
	decoder_layers: 3
	early_stopping: 0.1944907913156574
	embedding_layers: 1
	embedding_size: 9
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 7399
	net_layers: 3
	net_size: 9
	noise_std: 0.8151038501638692
2022-07-11 13:40:58 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=53 --decoder_heads=3 --decoder_layers=3 --early_stopping=0.1944907913156574 --embedding_layers=1 --embedding_size=9 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.0001 --max_steps=7399 --net_layers=3 --net_size=9 --noise_std=0.8151038501638692
2022-07-11 13:41:03 INFO Running runs: ['ni5jemtr']
2022-07-11 13:47:24 INFO Cleaning up finished run: ni5jemtr
2022-07-11 13:47:25 INFO Agent received command: run
2022-07-11 13:47:25 INFO Agent starting run with config:
	batch_size: 8
	d_model: 53
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.22449449139030075
	embedding_layers: 1
	embedding_size: 65
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 1782
	net_layers: 2
	net_size: 22
	noise_std: 0.0938768651460394
2022-07-11 13:47:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=53 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.22449449139030075 --embedding_layers=1 --embedding_size=65 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001 --max_steps=1782 --net_layers=2 --net_size=22 --noise_std=0.0938768651460394
2022-07-11 13:47:30 INFO Running runs: ['vn9mqtfy']
2022-07-11 13:51:30 INFO Cleaning up finished run: vn9mqtfy
2022-07-11 13:51:30 INFO Agent received command: run
2022-07-11 13:51:30 INFO Agent starting run with config:
	batch_size: 64
	d_model: 15
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.071807218653133
	embedding_layers: 1
	embedding_size: 15
	encoder_heads: 3
	encoder_layers: 4
	learning_rate: 0.0005
	max_steps: 4545
	net_layers: 1
	net_size: 103
	noise_std: 0.5659207618241856
2022-07-11 13:51:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=15 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.071807218653133 --embedding_layers=1 --embedding_size=15 --encoder_heads=3 --encoder_layers=4 --learning_rate=0.0005 --max_steps=4545 --net_layers=1 --net_size=103 --noise_std=0.5659207618241856
2022-07-11 13:51:36 INFO Running runs: ['bqd8whkb']
2022-07-11 13:55:14 INFO Cleaning up finished run: bqd8whkb
2022-07-11 13:55:14 INFO Agent received command: run
2022-07-11 13:55:14 INFO Agent starting run with config:
	batch_size: 8
	d_model: 16
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.048066871607595374
	embedding_layers: 1
	embedding_size: 53
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 8470
	net_layers: 1
	net_size: 19
	noise_std: 0.047740094316241946
2022-07-11 13:55:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=16 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.048066871607595374 --embedding_layers=1 --embedding_size=53 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.0001 --max_steps=8470 --net_layers=1 --net_size=19 --noise_std=0.047740094316241946
2022-07-11 13:55:19 INFO Running runs: ['olree6pi']
2022-07-11 14:02:09 INFO Cleaning up finished run: olree6pi
2022-07-11 14:02:10 INFO Agent received command: run
2022-07-11 14:02:10 INFO Agent starting run with config:
	batch_size: 128
	d_model: 116
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.1468516096438619
	embedding_layers: 1
	embedding_size: 46
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 3962
	net_layers: 1
	net_size: 45
	noise_std: 0.38761211720553873
2022-07-11 14:02:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=116 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.1468516096438619 --embedding_layers=1 --embedding_size=46 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0005 --max_steps=3962 --net_layers=1 --net_size=45 --noise_std=0.38761211720553873
2022-07-11 14:02:15 INFO Running runs: ['2kbsfr7l']
2022-07-11 14:06:13 INFO Cleaning up finished run: 2kbsfr7l
2022-07-11 14:06:14 INFO Agent received command: run
2022-07-11 14:06:14 INFO Agent starting run with config:
	batch_size: 8
	d_model: 51
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.23490854845962095
	embedding_layers: 2
	embedding_size: 19
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 6237
	net_layers: 1
	net_size: 23
	noise_std: 0.5132283386757313
2022-07-11 14:06:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=51 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.23490854845962095 --embedding_layers=2 --embedding_size=19 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.0001 --max_steps=6237 --net_layers=1 --net_size=23 --noise_std=0.5132283386757313
2022-07-11 14:06:19 INFO Running runs: ['xplsp2nv']
2022-07-11 14:12:40 INFO Cleaning up finished run: xplsp2nv
2022-07-11 14:12:40 INFO Agent received command: run
2022-07-11 14:12:40 INFO Agent starting run with config:
	batch_size: 32
	d_model: 31
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.13933962289744395
	embedding_layers: 1
	embedding_size: 28
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 7807
	net_layers: 2
	net_size: 73
	noise_std: 1.458433213279888
2022-07-11 14:12:40 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=31 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.13933962289744395 --embedding_layers=1 --embedding_size=28 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0005 --max_steps=7807 --net_layers=2 --net_size=73 --noise_std=1.458433213279888
2022-07-11 14:12:45 INFO Running runs: ['rm923kis']
2022-07-11 14:17:45 INFO Cleaning up finished run: rm923kis
2022-07-11 14:17:45 INFO Agent received command: run
2022-07-11 14:17:45 INFO Agent starting run with config:
	batch_size: 128
	d_model: 61
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.03147366377191163
	embedding_layers: 2
	embedding_size: 28
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 1299
	net_layers: 3
	net_size: 42
	noise_std: 0.12543789878181308
2022-07-11 14:17:45 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=61 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.03147366377191163 --embedding_layers=2 --embedding_size=28 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.0005 --max_steps=1299 --net_layers=3 --net_size=42 --noise_std=0.12543789878181308
2022-07-11 14:17:50 INFO Running runs: ['imz2js29']
2022-07-11 14:20:17 INFO Cleaning up finished run: imz2js29
2022-07-11 14:20:18 INFO Agent received command: run
2022-07-11 14:20:18 INFO Agent starting run with config:
	batch_size: 16
	d_model: 25
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.017811705465178185
	embedding_layers: 3
	embedding_size: 54
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 6630
	net_layers: 3
	net_size: 16
	noise_std: 0.3162053672185694
2022-07-11 14:20:18 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=25 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.017811705465178185 --embedding_layers=3 --embedding_size=54 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001 --max_steps=6630 --net_layers=3 --net_size=16 --noise_std=0.3162053672185694
2022-07-11 14:20:23 INFO Running runs: ['dh3f3q8w']
2022-07-11 14:24:55 INFO Cleaning up finished run: dh3f3q8w
2022-07-11 14:24:55 INFO Agent received command: run
2022-07-11 14:24:55 INFO Agent starting run with config:
	batch_size: 8
	d_model: 33
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.03208335618077629
	embedding_layers: 2
	embedding_size: 35
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 9604
	net_layers: 1
	net_size: 32
	noise_std: 0.32007081624760797
2022-07-11 14:24:55 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=33 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.03208335618077629 --embedding_layers=2 --embedding_size=35 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001 --max_steps=9604 --net_layers=1 --net_size=32 --noise_std=0.32007081624760797
2022-07-11 14:25:00 INFO Running runs: ['e2u83exa']
2022-07-11 14:32:26 INFO Cleaning up finished run: e2u83exa
2022-07-11 14:32:27 INFO Agent received command: run
2022-07-11 14:32:27 INFO Agent starting run with config:
	batch_size: 64
	d_model: 54
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.38405156880260494
	embedding_layers: 1
	embedding_size: 75
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 4922
	net_layers: 1
	net_size: 20
	noise_std: 1.181463311329243
2022-07-11 14:32:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=54 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.38405156880260494 --embedding_layers=1 --embedding_size=75 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001 --max_steps=4922 --net_layers=1 --net_size=20 --noise_std=1.181463311329243
2022-07-11 14:32:32 INFO Running runs: ['934drfai']
2022-07-11 14:37:36 INFO Cleaning up finished run: 934drfai
2022-07-11 14:37:43 INFO Running runs: []
2022-07-11 14:37:43 INFO Agent received command: run
2022-07-11 14:37:43 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.22930124381688477
	max_bin: 203
	max_depth: 21
	min_data_in_leaf: 29
	num_iterations: 761
	num_leaves: 36
2022-07-11 14:37:43 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.22930124381688477 --max_bin=203 --max_depth=21 --min_data_in_leaf=29 --num_iterations=761 --num_leaves=36
2022-07-11 14:37:48 INFO Running runs: ['bg7kcw5w']
2022-07-11 14:38:05 INFO Cleaning up finished run: bg7kcw5w
2022-07-11 14:38:05 INFO Agent received command: run
2022-07-11 14:38:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8312469233900823
	max_bin: 29
	max_depth: 28
	min_data_in_leaf: 15
	num_iterations: 932
	num_leaves: 15
2022-07-11 14:38:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8312469233900823 --max_bin=29 --max_depth=28 --min_data_in_leaf=15 --num_iterations=932 --num_leaves=15
2022-07-11 14:38:10 INFO Running runs: ['nn06f69x']
2022-07-11 14:38:26 INFO Cleaning up finished run: nn06f69x
2022-07-11 14:38:27 INFO Agent received command: run
2022-07-11 14:38:27 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08237423773538133
	max_bin: 225
	max_depth: 9
	min_data_in_leaf: 12
	num_iterations: 134
	num_leaves: 7
2022-07-11 14:38:27 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08237423773538133 --max_bin=225 --max_depth=9 --min_data_in_leaf=12 --num_iterations=134 --num_leaves=7
2022-07-11 14:38:32 INFO Running runs: ['u5if3mrl']
2022-07-11 14:38:48 INFO Cleaning up finished run: u5if3mrl
2022-07-11 14:38:49 INFO Agent received command: run
2022-07-11 14:38:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8835678894382731
	max_bin: 106
	max_depth: 13
	min_data_in_leaf: 10
	num_iterations: 503
	num_leaves: 11
2022-07-11 14:38:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8835678894382731 --max_bin=106 --max_depth=13 --min_data_in_leaf=10 --num_iterations=503 --num_leaves=11
2022-07-11 14:38:54 INFO Running runs: ['t53lgf7p']
2022-07-11 14:39:10 INFO Cleaning up finished run: t53lgf7p
2022-07-11 14:39:11 INFO Agent received command: run
2022-07-11 14:39:11 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.22622901399112427
	max_bin: 103
	max_depth: 26
	min_data_in_leaf: 28
	num_iterations: 804
	num_leaves: 9
2022-07-11 14:39:11 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.22622901399112427 --max_bin=103 --max_depth=26 --min_data_in_leaf=28 --num_iterations=804 --num_leaves=9
2022-07-11 14:39:16 INFO Running runs: ['ephftgu1']
2022-07-11 14:39:32 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-11 14:39:32 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-11 14:39:40 INFO Running runs: []
2022-07-11 14:39:41 INFO Agent received command: run
2022-07-11 14:39:41 INFO Agent starting run with config:
	batch_size: 8
	d_model: 76
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.30562827343653987
	embedding_layers: 2
	embedding_size: 20
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 3925
	net_layers: 3
	net_size: 27
	noise_std: 1.1531540056566072
2022-07-11 14:39:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=76 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.30562827343653987 --embedding_layers=2 --embedding_size=20 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.0001 --max_steps=3925 --net_layers=3 --net_size=27 --noise_std=1.1531540056566072
2022-07-11 14:39:46 INFO Running runs: ['lklmq5aj']
2022-07-11 14:45:41 INFO Cleaning up finished run: lklmq5aj
2022-07-11 14:45:41 INFO Agent received command: run
2022-07-11 14:45:41 INFO Agent starting run with config:
	batch_size: 32
	d_model: 50
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.8925765118282807
	embedding_layers: 2
	embedding_size: 98
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.005
	max_steps: 9558
	net_layers: 1
	net_size: 120
	noise_std: 0.053325835968707894
2022-07-11 14:45:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=50 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.8925765118282807 --embedding_layers=2 --embedding_size=98 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.005 --max_steps=9558 --net_layers=1 --net_size=120 --noise_std=0.053325835968707894
2022-07-11 14:45:46 INFO Running runs: ['se4od9nz']
2022-07-11 14:51:52 INFO Running runs: []
2022-07-11 14:51:52 INFO Agent received command: run
2022-07-11 14:51:52 INFO Agent starting run with config:
	batch_size: 4
	d_model: 109
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.10919689164452706
	embedding_layers: 2
	embedding_size: 50
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.01
	max_steps: 7445
	net_layers: 2
	net_size: 84
	noise_std: 0.03128918185416736
2022-07-11 14:51:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=109 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.10919689164452706 --embedding_layers=2 --embedding_size=50 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.01 --max_steps=7445 --net_layers=2 --net_size=84 --noise_std=0.03128918185416736
2022-07-11 14:51:57 INFO Running runs: ['if3c4emm']
2022-07-11 15:33:16 INFO Running runs: []
2022-07-11 15:33:16 INFO Agent received command: run
2022-07-11 15:33:16 INFO Agent starting run with config:
	batch_size: 16
	d_model: 100
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.2837406764195045
	embedding_layers: 1
	embedding_size: 111
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 2988
	net_layers: 2
	net_size: 115
	noise_std: 0.9363792673115032
2022-07-11 15:33:16 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=100 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.2837406764195045 --embedding_layers=1 --embedding_size=111 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.001 --max_steps=2988 --net_layers=2 --net_size=115 --noise_std=0.9363792673115032
2022-07-11 15:33:21 INFO Running runs: ['pdf9ejy2']
2022-07-11 15:39:54 INFO Running runs: []
2022-07-11 15:39:54 INFO Agent received command: run
2022-07-11 15:39:54 INFO Agent starting run with config:
	batch_size: 64
	d_model: 97
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.5056457389253799
	embedding_layers: 1
	embedding_size: 117
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 3746
	net_layers: 1
	net_size: 122
	noise_std: 0.7195268131745153
2022-07-11 15:39:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=97 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.5056457389253799 --embedding_layers=1 --embedding_size=117 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.0005 --max_steps=3746 --net_layers=1 --net_size=122 --noise_std=0.7195268131745153
2022-07-11 15:39:59 INFO Running runs: ['wv2ow50o']
2022-07-11 15:45:44 INFO Cleaning up finished run: wv2ow50o
2022-07-11 15:45:45 INFO Agent received command: run
2022-07-11 15:45:45 INFO Agent starting run with config:
	batch_size: 4
	d_model: 124
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.00923830799442138
	embedding_layers: 1
	embedding_size: 81
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.01
	max_steps: 4384
	net_layers: 1
	net_size: 16
	noise_std: 0.9382074043473888
2022-07-11 15:45:45 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=124 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.00923830799442138 --embedding_layers=1 --embedding_size=81 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.01 --max_steps=4384 --net_layers=1 --net_size=16 --noise_std=0.9382074043473888
2022-07-11 15:45:50 INFO Running runs: ['grm3ui5w']
2022-07-11 15:47:05 INFO Running runs: []
2022-07-11 15:47:06 INFO Agent received command: run
2022-07-11 15:47:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8494565718194481
	max_bin: 65
	max_depth: 6
	min_data_in_leaf: 18
	num_iterations: 924
	num_leaves: 11
2022-07-11 15:47:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8494565718194481 --max_bin=65 --max_depth=6 --min_data_in_leaf=18 --num_iterations=924 --num_leaves=11
2022-07-11 15:47:11 INFO Running runs: ['jzr9nhof']
2022-07-11 15:48:57 INFO Running runs: []
2022-07-11 15:48:58 INFO Agent received command: run
2022-07-11 15:48:58 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.40528725055013515
	max_bin: 65
	max_depth: 25
	min_data_in_leaf: 10
	num_iterations: 884
	num_leaves: 6
2022-07-11 15:48:58 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.40528725055013515 --max_bin=65 --max_depth=25 --min_data_in_leaf=10 --num_iterations=884 --num_leaves=6
2022-07-11 15:49:03 INFO Running runs: ['rafijuei']
2022-07-11 15:49:19 INFO Cleaning up finished run: rafijuei
2022-07-11 15:49:19 INFO Agent received command: run
2022-07-11 15:49:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.021986205839747752
	max_bin: 252
	max_depth: 8
	min_data_in_leaf: 22
	num_iterations: 620
	num_leaves: 39
2022-07-11 15:49:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.021986205839747752 --max_bin=252 --max_depth=8 --min_data_in_leaf=22 --num_iterations=620 --num_leaves=39
2022-07-11 15:49:24 INFO Running runs: ['f768675w']
2022-07-11 15:49:41 INFO Cleaning up finished run: f768675w
2022-07-11 15:49:41 INFO Agent received command: run
2022-07-11 15:49:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5725214907277081
	max_bin: 8
	max_depth: 19
	min_data_in_leaf: 15
	num_iterations: 217
	num_leaves: 18
2022-07-11 15:49:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.5725214907277081 --max_bin=8 --max_depth=19 --min_data_in_leaf=15 --num_iterations=217 --num_leaves=18
2022-07-11 15:49:46 INFO Running runs: ['xukolwb5']
2022-07-11 15:50:02 INFO Cleaning up finished run: xukolwb5
2022-07-11 15:50:03 INFO Agent received command: run
2022-07-11 15:50:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9356468549785792
	max_bin: 202
	max_depth: 11
	min_data_in_leaf: 21
	num_iterations: 329
	num_leaves: 9
2022-07-11 15:50:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9356468549785792 --max_bin=202 --max_depth=11 --min_data_in_leaf=21 --num_iterations=329 --num_leaves=9
2022-07-11 15:50:08 INFO Running runs: ['jtctr5up']
2022-07-11 15:50:24 INFO Cleaning up finished run: jtctr5up
2022-07-11 15:50:25 INFO Agent received command: run
2022-07-11 15:50:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9845457683983494
	max_bin: 169
	max_depth: 10
	min_data_in_leaf: 12
	num_iterations: 422
	num_leaves: 23
2022-07-11 15:50:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9845457683983494 --max_bin=169 --max_depth=10 --min_data_in_leaf=12 --num_iterations=422 --num_leaves=23
2022-07-11 15:50:30 INFO Running runs: ['qc5xncp5']
2022-07-11 15:50:46 INFO Cleaning up finished run: qc5xncp5
2022-07-11 15:50:47 INFO Agent received command: run
2022-07-11 15:50:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.13884516477472564
	max_bin: 253
	max_depth: 11
	min_data_in_leaf: 30
	num_iterations: 648
	num_leaves: 40
2022-07-11 15:50:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.13884516477472564 --max_bin=253 --max_depth=11 --min_data_in_leaf=30 --num_iterations=648 --num_leaves=40
2022-07-11 15:50:52 INFO Running runs: ['rnhcbzbw']
2022-07-11 15:51:08 INFO Cleaning up finished run: rnhcbzbw
2022-07-11 15:51:08 INFO Agent received command: run
2022-07-11 15:51:08 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0702463429682626
	max_bin: 221
	max_depth: 11
	min_data_in_leaf: 15
	num_iterations: 843
	num_leaves: 39
2022-07-11 15:51:08 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0702463429682626 --max_bin=221 --max_depth=11 --min_data_in_leaf=15 --num_iterations=843 --num_leaves=39
2022-07-11 15:51:13 INFO Running runs: ['c6dihwxu']
2022-07-11 15:51:30 INFO Cleaning up finished run: c6dihwxu
2022-07-11 15:51:30 INFO Agent received command: run
2022-07-11 15:51:30 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06144610919685478
	max_bin: 242
	max_depth: 4
	min_data_in_leaf: 26
	num_iterations: 920
	num_leaves: 25
2022-07-11 15:51:30 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06144610919685478 --max_bin=242 --max_depth=4 --min_data_in_leaf=26 --num_iterations=920 --num_leaves=25
2022-07-11 15:51:35 INFO Running runs: ['zirlrloc']
2022-07-11 15:51:51 INFO Cleaning up finished run: zirlrloc
2022-07-11 15:51:52 INFO Agent received command: run
2022-07-11 15:51:52 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05225027590279241
	max_bin: 175
	max_depth: 12
	min_data_in_leaf: 22
	num_iterations: 329
	num_leaves: 36
2022-07-11 15:51:52 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05225027590279241 --max_bin=175 --max_depth=12 --min_data_in_leaf=22 --num_iterations=329 --num_leaves=36
2022-07-11 15:51:57 INFO Running runs: ['wl2l91f1']
2022-07-11 15:52:13 INFO Cleaning up finished run: wl2l91f1
2022-07-11 15:52:15 INFO Agent received command: run
2022-07-11 15:52:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.01302052007518284
	max_bin: 204
	max_depth: 27
	min_data_in_leaf: 22
	num_iterations: 733
	num_leaves: 38
2022-07-11 15:52:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.01302052007518284 --max_bin=204 --max_depth=27 --min_data_in_leaf=22 --num_iterations=733 --num_leaves=38
2022-07-11 15:52:20 INFO Running runs: ['216uwfc4']
2022-07-11 15:52:36 INFO Cleaning up finished run: 216uwfc4
2022-07-11 15:52:36 INFO Agent received command: run
2022-07-11 15:52:36 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.29050309505161753
	max_bin: 254
	max_depth: 26
	min_data_in_leaf: 18
	num_iterations: 798
	num_leaves: 35
2022-07-11 15:52:36 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.29050309505161753 --max_bin=254 --max_depth=26 --min_data_in_leaf=18 --num_iterations=798 --num_leaves=35
2022-07-11 15:52:41 INFO Running runs: ['vj6gcehb']
2022-07-11 15:52:57 INFO Cleaning up finished run: vj6gcehb
2022-07-11 15:52:58 INFO Agent received command: run
2022-07-11 15:52:58 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08090414164726034
	max_bin: 120
	max_depth: 29
	min_data_in_leaf: 23
	num_iterations: 951
	num_leaves: 38
2022-07-11 15:52:58 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08090414164726034 --max_bin=120 --max_depth=29 --min_data_in_leaf=23 --num_iterations=951 --num_leaves=38
2022-07-11 15:53:03 INFO Running runs: ['990fyd4o']
2022-07-11 15:53:19 INFO Cleaning up finished run: 990fyd4o
2022-07-11 15:53:20 INFO Agent received command: run
2022-07-11 15:53:20 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09539704808126216
	max_bin: 253
	max_depth: 23
	min_data_in_leaf: 21
	num_iterations: 408
	num_leaves: 40
2022-07-11 15:53:20 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09539704808126216 --max_bin=253 --max_depth=23 --min_data_in_leaf=21 --num_iterations=408 --num_leaves=40
2022-07-11 15:53:25 INFO Running runs: ['xo3rqrci']
2022-07-11 15:53:41 INFO Cleaning up finished run: xo3rqrci
2022-07-11 15:53:42 INFO Agent received command: run
2022-07-11 15:53:42 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.023612029924308664
	max_bin: 182
	max_depth: 25
	min_data_in_leaf: 22
	num_iterations: 737
	num_leaves: 33
2022-07-11 15:53:42 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.023612029924308664 --max_bin=182 --max_depth=25 --min_data_in_leaf=22 --num_iterations=737 --num_leaves=33
2022-07-11 15:53:47 INFO Running runs: ['pxikz3q8']
2022-07-11 15:54:03 INFO Cleaning up finished run: pxikz3q8
2022-07-11 15:54:03 INFO Agent received command: run
2022-07-11 15:54:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.043349486622177635
	max_bin: 223
	max_depth: 5
	min_data_in_leaf: 23
	num_iterations: 612
	num_leaves: 39
2022-07-11 15:54:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.043349486622177635 --max_bin=223 --max_depth=5 --min_data_in_leaf=23 --num_iterations=612 --num_leaves=39
2022-07-11 15:54:08 INFO Running runs: ['rxxtz2xr']
2022-07-11 15:54:24 INFO Cleaning up finished run: rxxtz2xr
2022-07-11 15:54:25 INFO Agent received command: run
2022-07-11 15:54:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3809632371587205
	max_bin: 133
	max_depth: 9
	min_data_in_leaf: 14
	num_iterations: 165
	num_leaves: 32
2022-07-11 15:54:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3809632371587205 --max_bin=133 --max_depth=9 --min_data_in_leaf=14 --num_iterations=165 --num_leaves=32
2022-07-11 15:54:30 INFO Running runs: ['j25pyipt']
2022-07-11 15:54:46 INFO Cleaning up finished run: j25pyipt
2022-07-11 15:54:46 INFO Agent received command: run
2022-07-11 15:54:46 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8322422983320662
	max_bin: 244
	max_depth: 8
	min_data_in_leaf: 24
	num_iterations: 283
	num_leaves: 23
2022-07-11 15:54:46 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8322422983320662 --max_bin=244 --max_depth=8 --min_data_in_leaf=24 --num_iterations=283 --num_leaves=23
2022-07-11 15:54:51 INFO Running runs: ['0qd6gb2s']
2022-07-11 15:55:08 INFO Cleaning up finished run: 0qd6gb2s
2022-07-11 15:55:08 INFO Agent received command: run
2022-07-11 15:55:08 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.45284368961658583
	max_bin: 105
	max_depth: 13
	min_data_in_leaf: 16
	num_iterations: 883
	num_leaves: 20
2022-07-11 15:55:08 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.45284368961658583 --max_bin=105 --max_depth=13 --min_data_in_leaf=16 --num_iterations=883 --num_leaves=20
2022-07-11 15:55:13 INFO Running runs: ['plozxrf3']
2022-07-11 15:55:29 INFO Cleaning up finished run: plozxrf3
2022-07-11 15:55:30 INFO Agent received command: run
2022-07-11 15:55:30 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.20153203412954268
	max_bin: 79
	max_depth: 14
	min_data_in_leaf: 26
	num_iterations: 777
	num_leaves: 38
2022-07-11 15:55:30 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.20153203412954268 --max_bin=79 --max_depth=14 --min_data_in_leaf=26 --num_iterations=777 --num_leaves=38
2022-07-11 15:55:35 INFO Running runs: ['8y154xmr']
2022-07-11 15:55:51 INFO Cleaning up finished run: 8y154xmr
2022-07-11 15:55:52 INFO Agent received command: run
2022-07-11 15:55:52 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.1505557820902934
	max_bin: 101
	max_depth: 11
	min_data_in_leaf: 20
	num_iterations: 285
	num_leaves: 40
2022-07-11 15:55:52 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.1505557820902934 --max_bin=101 --max_depth=11 --min_data_in_leaf=20 --num_iterations=285 --num_leaves=40
2022-07-11 15:55:57 INFO Running runs: ['irug69ir']
2022-07-11 15:56:13 INFO Cleaning up finished run: irug69ir
2022-07-11 15:56:13 INFO Agent received command: run
2022-07-11 15:56:13 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.43748485514066815
	max_bin: 36
	max_depth: 21
	min_data_in_leaf: 14
	num_iterations: 778
	num_leaves: 37
2022-07-11 15:56:13 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.43748485514066815 --max_bin=36 --max_depth=21 --min_data_in_leaf=14 --num_iterations=778 --num_leaves=37
2022-07-11 15:56:18 INFO Running runs: ['0qjfbi5p']
2022-07-11 15:56:34 INFO Cleaning up finished run: 0qjfbi5p
2022-07-11 15:56:35 INFO Agent received command: run
2022-07-11 15:56:35 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.28097773004117377
	max_bin: 176
	max_depth: 26
	min_data_in_leaf: 18
	num_iterations: 630
	num_leaves: 6
2022-07-11 15:56:35 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.28097773004117377 --max_bin=176 --max_depth=26 --min_data_in_leaf=18 --num_iterations=630 --num_leaves=6
2022-07-11 15:56:40 INFO Running runs: ['859aep5m']
2022-07-11 15:56:56 INFO Cleaning up finished run: 859aep5m
2022-07-11 15:56:57 INFO Agent received command: run
2022-07-11 15:56:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6172994188524175
	max_bin: 183
	max_depth: 7
	min_data_in_leaf: 11
	num_iterations: 280
	num_leaves: 20
2022-07-11 15:56:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6172994188524175 --max_bin=183 --max_depth=7 --min_data_in_leaf=11 --num_iterations=280 --num_leaves=20
2022-07-11 15:57:02 INFO Running runs: ['rt5vgrgt']
2022-07-11 15:57:18 INFO Cleaning up finished run: rt5vgrgt
2022-07-11 15:57:18 INFO Agent received command: run
2022-07-11 15:57:18 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5550665157100659
	max_bin: 64
	max_depth: 26
	min_data_in_leaf: 29
	num_iterations: 453
	num_leaves: 22
2022-07-11 15:57:18 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.5550665157100659 --max_bin=64 --max_depth=26 --min_data_in_leaf=29 --num_iterations=453 --num_leaves=22
2022-07-11 15:57:23 INFO Running runs: ['k5r917w5']
2022-07-11 15:57:39 INFO Cleaning up finished run: k5r917w5
2022-07-11 15:57:40 INFO Agent received command: run
2022-07-11 15:57:40 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8165975571299955
	max_bin: 163
	max_depth: 29
	min_data_in_leaf: 16
	num_iterations: 332
	num_leaves: 21
2022-07-11 15:57:40 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8165975571299955 --max_bin=163 --max_depth=29 --min_data_in_leaf=16 --num_iterations=332 --num_leaves=21
2022-07-11 15:57:45 INFO Running runs: ['9t9z023y']
2022-07-11 15:58:01 INFO Cleaning up finished run: 9t9z023y
2022-07-11 15:58:02 INFO Agent received command: run
2022-07-11 15:58:02 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5302207426671973
	max_bin: 63
	max_depth: 14
	min_data_in_leaf: 12
	num_iterations: 193
	num_leaves: 35
2022-07-11 15:58:02 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.5302207426671973 --max_bin=63 --max_depth=14 --min_data_in_leaf=12 --num_iterations=193 --num_leaves=35
2022-07-11 15:58:07 INFO Running runs: ['8m05wyvd']
2022-07-11 15:58:23 INFO Cleaning up finished run: 8m05wyvd
2022-07-11 15:58:23 INFO Agent received command: run
2022-07-11 15:58:23 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.7444584395076186
	max_bin: 127
	max_depth: 4
	min_data_in_leaf: 15
	num_iterations: 986
	num_leaves: 26
2022-07-11 15:58:23 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.7444584395076186 --max_bin=127 --max_depth=4 --min_data_in_leaf=15 --num_iterations=986 --num_leaves=26
2022-07-11 15:58:28 INFO Running runs: ['2ue5h4oq']
2022-07-11 15:58:44 INFO Cleaning up finished run: 2ue5h4oq
2022-07-11 15:58:45 INFO Agent received command: run
2022-07-11 15:58:45 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.853296243250335
	max_bin: 201
	max_depth: 13
	min_data_in_leaf: 16
	num_iterations: 622
	num_leaves: 32
2022-07-11 15:58:45 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.853296243250335 --max_bin=201 --max_depth=13 --min_data_in_leaf=16 --num_iterations=622 --num_leaves=32
2022-07-11 15:58:50 INFO Running runs: ['erk6e1je']
2022-07-11 15:59:06 INFO Cleaning up finished run: erk6e1je
2022-07-11 15:59:07 INFO Agent received command: run
2022-07-11 15:59:07 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.7073406588624804
	max_bin: 52
	max_depth: 31
	min_data_in_leaf: 29
	num_iterations: 840
	num_leaves: 13
2022-07-11 15:59:07 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.7073406588624804 --max_bin=52 --max_depth=31 --min_data_in_leaf=29 --num_iterations=840 --num_leaves=13
2022-07-11 15:59:12 INFO Running runs: ['p7hmts5m']
2022-07-11 15:59:28 INFO Cleaning up finished run: p7hmts5m
2022-07-11 15:59:29 INFO Agent received command: run
2022-07-11 15:59:29 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.45179354267807015
	max_bin: 81
	max_depth: 10
	min_data_in_leaf: 25
	num_iterations: 170
	num_leaves: 27
2022-07-11 15:59:29 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.45179354267807015 --max_bin=81 --max_depth=10 --min_data_in_leaf=25 --num_iterations=170 --num_leaves=27
2022-07-11 15:59:34 INFO Running runs: ['wotagyij']
2022-07-11 15:59:50 INFO Cleaning up finished run: wotagyij
2022-07-11 15:59:58 INFO Running runs: []
2022-07-11 15:59:58 INFO Agent received command: run
2022-07-11 15:59:58 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.606508950758106
	max_bin: 244
	max_depth: 4
	min_data_in_leaf: 16
	num_iterations: 147
	num_leaves: 36
2022-07-11 15:59:58 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.606508950758106 --max_bin=244 --max_depth=4 --min_data_in_leaf=16 --num_iterations=147 --num_leaves=36
2022-07-11 16:00:03 INFO Running runs: ['ev6dkoo0']
2022-07-11 16:00:19 INFO Cleaning up finished run: ev6dkoo0
2022-07-11 16:00:20 INFO Agent received command: run
2022-07-11 16:00:20 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4599054940370544
	max_bin: 61
	max_depth: 29
	min_data_in_leaf: 18
	num_iterations: 851
	num_leaves: 18
2022-07-11 16:00:20 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4599054940370544 --max_bin=61 --max_depth=29 --min_data_in_leaf=18 --num_iterations=851 --num_leaves=18
2022-07-11 16:02:27 INFO Running runs: []
2022-07-11 16:02:28 INFO Agent received command: run
2022-07-11 16:02:28 INFO Agent starting run with config:
	batch_size: 8
	d_model: 120
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.9242974465379726
	embedding_layers: 2
	embedding_size: 120
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 1372
	net_layers: 1
	net_size: 27
	noise_std: 1.4709825307059137
2022-07-11 16:02:28 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=120 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.9242974465379726 --embedding_layers=2 --embedding_size=120 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.0005 --max_steps=1372 --net_layers=1 --net_size=27 --noise_std=1.4709825307059137
2022-07-11 16:02:33 INFO Running runs: ['undl14gn']
2022-07-11 16:06:43 INFO Running runs: []
2022-07-11 16:06:43 INFO Agent received command: run
2022-07-11 16:06:43 INFO Agent starting run with config:
	batch_size: 128
	d_model: 23
	decoder_heads: 3
	decoder_layers: 3
	early_stopping: 0.730604498135526
	embedding_layers: 3
	embedding_size: 81
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 2206
	net_layers: 3
	net_size: 109
	noise_std: 0.1424050966091465
2022-07-11 16:06:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=23 --decoder_heads=3 --decoder_layers=3 --early_stopping=0.730604498135526 --embedding_layers=3 --embedding_size=81 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0001 --max_steps=2206 --net_layers=3 --net_size=109 --noise_std=0.1424050966091465
2022-07-11 16:06:48 INFO Running runs: ['ir0sm4a3']
2022-07-11 16:11:35 INFO Cleaning up finished run: ir0sm4a3
2022-07-11 16:11:35 INFO Agent received command: run
2022-07-11 16:11:35 INFO Agent starting run with config:
	batch_size: 64
	d_model: 65
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.21401960280654
	embedding_layers: 3
	embedding_size: 55
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 3644
	net_layers: 2
	net_size: 15
	noise_std: 1.2316486843977787
2022-07-11 16:11:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=65 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.21401960280654 --embedding_layers=3 --embedding_size=55 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.001 --max_steps=3644 --net_layers=2 --net_size=15 --noise_std=1.2316486843977787
2022-07-11 16:11:40 INFO Running runs: ['1s1af5so']
2022-07-11 16:14:34 INFO Cleaning up finished run: 1s1af5so
2022-07-11 16:14:35 INFO Agent received command: run
2022-07-11 16:14:35 INFO Agent starting run with config:
	batch_size: 4
	d_model: 8
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.8864035879335181
	embedding_layers: 1
	embedding_size: 10
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.01
	max_steps: 3249
	net_layers: 1
	net_size: 27
	noise_std: 0.5793960811327484
2022-07-11 16:14:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=8 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.8864035879335181 --embedding_layers=1 --embedding_size=10 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.01 --max_steps=3249 --net_layers=1 --net_size=27 --noise_std=0.5793960811327484
2022-07-11 16:14:40 INFO Running runs: ['ac3xc9xm']
2022-07-11 16:19:00 INFO Cleaning up finished run: ac3xc9xm
2022-07-11 16:19:01 INFO Agent received command: run
2022-07-11 16:19:01 INFO Agent starting run with config:
	batch_size: 4
	d_model: 91
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.20694729400679024
	embedding_layers: 2
	embedding_size: 18
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 1016
	net_layers: 2
	net_size: 105
	noise_std: 1.3545301150087905
2022-07-11 16:19:01 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=91 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.20694729400679024 --embedding_layers=2 --embedding_size=18 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.0005 --max_steps=1016 --net_layers=2 --net_size=105 --noise_std=1.3545301150087905
2022-07-11 16:19:06 INFO Running runs: ['srzxd60n']
2022-07-11 16:20:38 INFO Cleaning up finished run: srzxd60n
2022-07-11 16:20:39 INFO Agent received command: run
2022-07-11 16:20:39 INFO Agent starting run with config:
	batch_size: 64
	d_model: 128
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.2647089191803703
	embedding_layers: 1
	embedding_size: 108
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.01
	max_steps: 3099
	net_layers: 1
	net_size: 95
	noise_std: 0.25017570149983537
2022-07-11 16:20:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=128 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.2647089191803703 --embedding_layers=1 --embedding_size=108 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.01 --max_steps=3099 --net_layers=1 --net_size=95 --noise_std=0.25017570149983537
2022-07-11 16:20:44 INFO Running runs: ['uk4hcyil']
2022-07-11 16:25:03 INFO Cleaning up finished run: uk4hcyil
2022-07-11 16:25:04 INFO Agent received command: run
2022-07-11 16:25:04 INFO Agent starting run with config:
	batch_size: 4
	d_model: 83
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.7844846977255571
	embedding_layers: 3
	embedding_size: 33
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.005
	max_steps: 3876
	net_layers: 2
	net_size: 65
	noise_std: 0.6704442154060406
2022-07-11 16:25:04 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=83 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.7844846977255571 --embedding_layers=3 --embedding_size=33 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.005 --max_steps=3876 --net_layers=2 --net_size=65 --noise_std=0.6704442154060406
2022-07-11 16:25:09 INFO Running runs: ['hr5myids']
2022-07-11 16:29:18 INFO Cleaning up finished run: hr5myids
2022-07-11 16:29:19 INFO Agent received command: run
2022-07-11 16:29:19 INFO Agent starting run with config:
	batch_size: 8
	d_model: 14
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.1240112331627885
	embedding_layers: 1
	embedding_size: 64
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 1531
	net_layers: 1
	net_size: 37
	noise_std: 0.03582764881581339
2022-07-11 16:29:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=14 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.1240112331627885 --embedding_layers=1 --embedding_size=64 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.0005 --max_steps=1531 --net_layers=1 --net_size=37 --noise_std=0.03582764881581339
2022-07-11 16:29:24 INFO Running runs: ['05qu6vsr']
2022-07-11 16:31:06 INFO Cleaning up finished run: 05qu6vsr
2022-07-11 16:31:07 INFO Agent received command: run
2022-07-11 16:31:07 INFO Agent starting run with config:
	batch_size: 128
	d_model: 84
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.2733859606755895
	embedding_layers: 2
	embedding_size: 54
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 3104
	net_layers: 1
	net_size: 117
	noise_std: 1.46456955970622
2022-07-11 16:31:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=84 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.2733859606755895 --embedding_layers=2 --embedding_size=54 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.0005 --max_steps=3104 --net_layers=1 --net_size=117 --noise_std=1.46456955970622
2022-07-11 16:31:12 INFO Running runs: ['90ykidtq']
2022-07-11 16:31:31 INFO Running runs: []
2022-07-11 16:31:32 INFO Agent received command: run
2022-07-11 16:31:32 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6413588456286632
	max_bin: 171
	max_depth: 11
	min_data_in_leaf: 17
	num_iterations: 740
	num_leaves: 40
2022-07-11 16:31:32 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6413588456286632 --max_bin=171 --max_depth=11 --min_data_in_leaf=17 --num_iterations=740 --num_leaves=40
2022-07-11 16:31:37 INFO Running runs: ['4rd25x2l']
2022-07-11 16:31:53 INFO Cleaning up finished run: 4rd25x2l
2022-07-11 16:31:53 INFO Agent received command: run
2022-07-11 16:31:53 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3479823627715395
	max_bin: 190
	max_depth: 24
	min_data_in_leaf: 29
	num_iterations: 545
	num_leaves: 16
2022-07-11 16:31:53 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3479823627715395 --max_bin=190 --max_depth=24 --min_data_in_leaf=29 --num_iterations=545 --num_leaves=16
2022-07-11 16:31:58 INFO Running runs: ['735ypdwd']
2022-07-11 16:32:14 INFO Cleaning up finished run: 735ypdwd
2022-07-11 16:32:15 INFO Agent received command: run
2022-07-11 16:32:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.018911517537921307
	max_bin: 16
	max_depth: 24
	min_data_in_leaf: 25
	num_iterations: 450
	num_leaves: 8
2022-07-11 16:32:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.018911517537921307 --max_bin=16 --max_depth=24 --min_data_in_leaf=25 --num_iterations=450 --num_leaves=8
2022-07-11 16:32:20 INFO Running runs: ['0a71m2c0']
2022-07-11 16:32:36 INFO Cleaning up finished run: 0a71m2c0
2022-07-11 16:32:37 INFO Agent received command: run
2022-07-11 16:32:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3925159102674816
	max_bin: 6
	max_depth: 18
	min_data_in_leaf: 13
	num_iterations: 211
	num_leaves: 11
2022-07-11 16:32:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3925159102674816 --max_bin=6 --max_depth=18 --min_data_in_leaf=13 --num_iterations=211 --num_leaves=11
2022-07-11 16:32:42 INFO Running runs: ['tt9ukkol']
2022-07-11 16:32:58 INFO Cleaning up finished run: tt9ukkol
2022-07-11 16:32:58 INFO Agent received command: run
2022-07-11 16:32:58 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9219968719742389
	max_bin: 235
	max_depth: 13
	min_data_in_leaf: 22
	num_iterations: 129
	num_leaves: 10
2022-07-11 16:32:58 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9219968719742389 --max_bin=235 --max_depth=13 --min_data_in_leaf=22 --num_iterations=129 --num_leaves=10
2022-07-11 16:37:51 INFO Running runs: []
2022-07-11 16:37:52 INFO Agent received command: run
2022-07-11 16:37:52 INFO Agent starting run with config:
	batch_size: 8
	d_model: 15
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.46210794664396504
	embedding_layers: 3
	embedding_size: 100
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.005
	max_steps: 1841
	net_layers: 3
	net_size: 20
	noise_std: 0.8059473576627122
2022-07-11 16:37:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=15 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.46210794664396504 --embedding_layers=3 --embedding_size=100 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.005 --max_steps=1841 --net_layers=3 --net_size=20 --noise_std=0.8059473576627122
2022-07-11 16:37:57 INFO Running runs: ['8dr4jvgj']
2022-07-11 16:40:22 INFO Cleaning up finished run: 8dr4jvgj
2022-07-11 16:40:22 INFO Agent received command: run
2022-07-11 16:40:22 INFO Agent starting run with config:
	batch_size: 4
	d_model: 106
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.5603870144715553
	embedding_layers: 2
	embedding_size: 48
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.005
	max_steps: 1413
	net_layers: 3
	net_size: 77
	noise_std: 1.366750950846629
2022-07-11 16:40:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=106 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.5603870144715553 --embedding_layers=2 --embedding_size=48 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.005 --max_steps=1413 --net_layers=3 --net_size=77 --noise_std=1.366750950846629
2022-07-11 16:40:27 INFO Running runs: ['9jkwol3h']
2022-07-11 16:42:35 INFO Running runs: []
2022-07-11 16:42:35 INFO Agent received command: run
2022-07-11 16:42:35 INFO Agent starting run with config:
	batch_size: 4
	d_model: 37
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.3326364403571648
	embedding_layers: 3
	embedding_size: 128
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 1219
	net_layers: 2
	net_size: 26
	noise_std: 0.18936166354594233
2022-07-11 16:42:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=37 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.3326364403571648 --embedding_layers=3 --embedding_size=128 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0005 --max_steps=1219 --net_layers=2 --net_size=26 --noise_std=0.18936166354594233
2022-07-11 16:42:40 INFO Running runs: ['w1r3bxkw']
2022-07-11 16:48:39 INFO Running runs: []
2022-07-11 16:48:40 INFO Agent received command: run
2022-07-11 16:48:40 INFO Agent starting run with config:
	batch_size: 128
	d_model: 109
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.6984677669721122
	embedding_layers: 2
	embedding_size: 43
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 1674
	net_layers: 1
	net_size: 32
	noise_std: 0.14709127571092903
2022-07-11 16:48:40 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=128 --d_model=109 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.6984677669721122 --embedding_layers=2 --embedding_size=43 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.001 --max_steps=1674 --net_layers=1 --net_size=32 --noise_std=0.14709127571092903
2022-07-11 16:48:45 INFO Running runs: ['k7lligyi']
2022-07-11 16:49:31 INFO Running runs: []
2022-07-11 16:49:31 INFO Agent received command: run
2022-07-11 16:49:31 INFO Agent starting run with config:
	batch_size: 16
	d_model: 98
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.664321307157808
	embedding_layers: 2
	embedding_size: 61
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.01
	max_steps: 1808
	net_layers: 3
	net_size: 120
	noise_std: 0.7552749810733955
2022-07-11 16:49:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=98 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.664321307157808 --embedding_layers=2 --embedding_size=61 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.01 --max_steps=1808 --net_layers=3 --net_size=120 --noise_std=0.7552749810733955
2022-07-11 16:49:36 INFO Running runs: ['dmdtx32i']
2022-07-11 16:53:13 INFO Cleaning up finished run: dmdtx32i
2022-07-11 16:53:14 INFO Agent received command: run
2022-07-11 16:53:14 INFO Agent starting run with config:
	batch_size: 8
	d_model: 23
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.8520222842645039
	embedding_layers: 2
	embedding_size: 102
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.01
	max_steps: 1578
	net_layers: 4
	net_size: 91
	noise_std: 0.8199682643390744
2022-07-11 16:53:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=23 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.8520222842645039 --embedding_layers=2 --embedding_size=102 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.01 --max_steps=1578 --net_layers=4 --net_size=91 --noise_std=0.8199682643390744
2022-07-11 16:53:19 INFO Running runs: ['8yz6uu2g']
2022-07-11 16:56:23 INFO Cleaning up finished run: 8yz6uu2g
2022-07-11 16:56:24 INFO Agent received command: run
2022-07-11 16:56:24 INFO Agent starting run with config:
	batch_size: 4
	d_model: 25
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.9272230561829606
	embedding_layers: 2
	embedding_size: 20
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.005
	max_steps: 2905
	net_layers: 2
	net_size: 63
	noise_std: 1.454395301238074
2022-07-11 16:56:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=25 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.9272230561829606 --embedding_layers=2 --embedding_size=20 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.005 --max_steps=2905 --net_layers=2 --net_size=63 --noise_std=1.454395301238074
2022-07-11 16:56:29 INFO Running runs: ['s1l2wfrj']
2022-07-11 17:02:00 INFO Cleaning up finished run: s1l2wfrj
2022-07-11 17:02:00 INFO Agent received command: run
2022-07-11 17:02:00 INFO Agent starting run with config:
	batch_size: 8
	d_model: 17
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.6878395174356551
	embedding_layers: 2
	embedding_size: 37
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 2661
	net_layers: 2
	net_size: 70
	noise_std: 0.8669034230384287
2022-07-11 17:02:00 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=17 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.6878395174356551 --embedding_layers=2 --embedding_size=37 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.0005 --max_steps=2661 --net_layers=2 --net_size=70 --noise_std=0.8669034230384287
2022-07-11 17:02:05 INFO Running runs: ['mt5bbo7a']
2022-07-11 17:06:53 INFO Cleaning up finished run: mt5bbo7a
2022-07-11 17:06:54 INFO Agent received command: run
2022-07-11 17:06:54 INFO Agent starting run with config:
	batch_size: 16
	d_model: 16
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.9234935821316004
	embedding_layers: 3
	embedding_size: 11
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 2422
	net_layers: 3
	net_size: 34
	noise_std: 1.0063042537740263
2022-07-11 17:06:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=16 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.9234935821316004 --embedding_layers=3 --embedding_size=11 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0005 --max_steps=2422 --net_layers=3 --net_size=34 --noise_std=1.0063042537740263
2022-07-11 17:06:59 INFO Running runs: ['uks3emnb']
2022-07-11 17:12:19 INFO Cleaning up finished run: uks3emnb
2022-07-11 17:12:20 INFO Agent received command: run
2022-07-11 17:12:20 INFO Agent starting run with config:
	batch_size: 32
	d_model: 4
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.7689360809811933
	embedding_layers: 1
	embedding_size: 25
	encoder_heads: 1
	encoder_layers: 7
	learning_rate: 0.0005
	max_steps: 3544
	net_layers: 3
	net_size: 45
	noise_std: 0.7401656592002392
2022-07-11 17:12:20 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=4 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.7689360809811933 --embedding_layers=1 --embedding_size=25 --encoder_heads=1 --encoder_layers=7 --learning_rate=0.0005 --max_steps=3544 --net_layers=3 --net_size=45 --noise_std=0.7401656592002392
2022-07-11 17:12:25 INFO Running runs: ['8frpdyi5']
2022-07-11 17:18:31 INFO Cleaning up finished run: 8frpdyi5
2022-07-11 17:18:31 INFO Agent received command: run
2022-07-11 17:18:31 INFO Agent starting run with config:
	batch_size: 4
	d_model: 35
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.9484710333431994
	embedding_layers: 2
	embedding_size: 35
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 2486
	net_layers: 1
	net_size: 18
	noise_std: 0.49130422739122825
2022-07-11 17:18:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=35 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.9484710333431994 --embedding_layers=2 --embedding_size=35 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.001 --max_steps=2486 --net_layers=1 --net_size=18 --noise_std=0.49130422739122825
2022-07-11 17:18:36 INFO Running runs: ['rirc60fv']
2022-07-11 17:27:29 INFO Running runs: []
2022-07-11 17:27:30 INFO Agent received command: run
2022-07-11 17:27:30 INFO Agent starting run with config:
	batch_size: 64
	d_model: 82
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.1422986474688951
	embedding_layers: 4
	embedding_size: 125
	encoder_heads: 3
	encoder_layers: 6
	learning_rate: 0.01
	max_steps: 2609
	net_layers: 2
	net_size: 123
	noise_std: 0.8476090265630052
2022-07-11 17:27:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=82 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.1422986474688951 --embedding_layers=4 --embedding_size=125 --encoder_heads=3 --encoder_layers=6 --learning_rate=0.01 --max_steps=2609 --net_layers=2 --net_size=123 --noise_std=0.8476090265630052
2022-07-11 17:27:35 INFO Running runs: ['mmhnrej5']
2022-07-11 17:28:30 INFO Running runs: []
2022-07-11 17:28:53 INFO Agent received command: run
2022-07-11 17:28:53 INFO Agent starting run with config:
	batch_size: 128
	d_model: 38
	decoder_heads: 5
	decoder_layers: 8
	early_stopping: 0.4012751553523244
	embedding_layers: 2
	embedding_size: 50
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 1990
	net_layers: 4
	net_size: 114
	noise_std: 0.7965098700664103
2022-07-11 17:28:53 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=38 --decoder_heads=5 --decoder_layers=8 --early_stopping=0.4012751553523244 --embedding_layers=2 --embedding_size=50 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.001 --max_steps=1990 --net_layers=4 --net_size=114 --noise_std=0.7965098700664103
2022-07-11 17:28:58 INFO Running runs: ['4h5anmz0']
2022-07-11 17:37:21 INFO Running runs: []
2022-07-11 17:37:22 INFO Agent received command: run
2022-07-11 17:37:22 INFO Agent starting run with config:
	batch_size: 8
	d_model: 61
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.197731413502771
	embedding_layers: 1
	embedding_size: 92
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 3192
	net_layers: 4
	net_size: 34
	noise_std: 1.0283899606241371
2022-07-11 17:37:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=61 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.197731413502771 --embedding_layers=1 --embedding_size=92 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.001 --max_steps=3192 --net_layers=4 --net_size=34 --noise_std=1.0283899606241371
2022-07-11 17:37:27 INFO Running runs: ['nugzizgi']
2022-07-11 17:39:08 INFO Running runs: []
2022-07-11 17:39:10 INFO Agent received command: run
2022-07-11 17:39:10 INFO Agent starting run with config:
	batch_size: 16
	d_model: 105
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.3143104305786659
	embedding_layers: 4
	embedding_size: 89
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 3383
	net_layers: 4
	net_size: 105
	noise_std: 0.6535098925900598
2022-07-11 17:39:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=105 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.3143104305786659 --embedding_layers=4 --embedding_size=89 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.0001 --max_steps=3383 --net_layers=4 --net_size=105 --noise_std=0.6535098925900598
2022-07-11 17:39:15 INFO Running runs: ['fug5vm4m']
2022-07-11 17:42:25 INFO Cleaning up finished run: fug5vm4m
2022-07-11 17:42:25 INFO Agent received command: run
2022-07-11 17:42:25 INFO Agent starting run with config:
	batch_size: 128
	d_model: 39
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.5960849142269037
	embedding_layers: 1
	embedding_size: 71
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 2450
	net_layers: 3
	net_size: 17
	noise_std: 0.6135884127363703
2022-07-11 17:42:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=39 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.5960849142269037 --embedding_layers=1 --embedding_size=71 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.001 --max_steps=2450 --net_layers=3 --net_size=17 --noise_std=0.6135884127363703
2022-07-11 17:42:30 INFO Running runs: ['3s3vnwtr']
2022-07-11 17:47:07 INFO Cleaning up finished run: 3s3vnwtr
2022-07-11 17:47:08 INFO Agent received command: run
2022-07-11 17:47:08 INFO Agent starting run with config:
	batch_size: 4
	d_model: 47
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.34132370907834797
	embedding_layers: 2
	embedding_size: 102
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 4508
	net_layers: 4
	net_size: 56
	noise_std: 1.01536803958099
2022-07-11 17:47:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=47 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.34132370907834797 --embedding_layers=2 --embedding_size=102 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0001 --max_steps=4508 --net_layers=4 --net_size=56 --noise_std=1.01536803958099
2022-07-11 17:47:13 INFO Running runs: ['kuzdr6e5']
2022-07-11 17:51:45 INFO Cleaning up finished run: kuzdr6e5
2022-07-11 17:51:45 INFO Agent received command: run
2022-07-11 17:51:45 INFO Agent starting run with config:
	batch_size: 64
	d_model: 80
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.3135770340366141
	embedding_layers: 2
	embedding_size: 123
	encoder_heads: 2
	encoder_layers: 7
	learning_rate: 0.0005
	max_steps: 1050
	net_layers: 1
	net_size: 45
	noise_std: 0.9727232307616384
2022-07-11 17:51:45 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=80 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.3135770340366141 --embedding_layers=2 --embedding_size=123 --encoder_heads=2 --encoder_layers=7 --learning_rate=0.0005 --max_steps=1050 --net_layers=1 --net_size=45 --noise_std=0.9727232307616384
2022-07-11 17:51:50 INFO Running runs: ['ywj6hki0']
2022-07-11 17:54:11 INFO Cleaning up finished run: ywj6hki0
2022-07-11 17:54:12 INFO Agent received command: run
2022-07-11 17:54:12 INFO Agent starting run with config:
	batch_size: 128
	d_model: 13
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.822563859628209
	embedding_layers: 4
	embedding_size: 13
	encoder_heads: 5
	encoder_layers: 2
	learning_rate: 0.001
	max_steps: 4576
	net_layers: 1
	net_size: 122
	noise_std: 0.32580509636203764
2022-07-11 17:54:12 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=13 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.822563859628209 --embedding_layers=4 --embedding_size=13 --encoder_heads=5 --encoder_layers=2 --learning_rate=0.001 --max_steps=4576 --net_layers=1 --net_size=122 --noise_std=0.32580509636203764
2022-07-11 17:54:17 INFO Running runs: ['5k0qyet3']
2022-07-11 18:02:22 INFO Cleaning up finished run: 5k0qyet3
2022-07-11 18:02:22 INFO Agent received command: run
2022-07-11 18:02:22 INFO Agent starting run with config:
	batch_size: 128
	d_model: 28
	decoder_heads: 5
	decoder_layers: 7
	early_stopping: 0.26629426455098004
	embedding_layers: 2
	embedding_size: 41
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 2281
	net_layers: 4
	net_size: 19
	noise_std: 0.5172907378923739
2022-07-11 18:02:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=28 --decoder_heads=5 --decoder_layers=7 --early_stopping=0.26629426455098004 --embedding_layers=2 --embedding_size=41 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.001 --max_steps=2281 --net_layers=4 --net_size=19 --noise_std=0.5172907378923739
2022-07-11 18:02:27 INFO Running runs: ['va93obq9']
2022-07-11 18:06:26 INFO Cleaning up finished run: va93obq9
2022-07-11 18:06:27 INFO Agent received command: run
2022-07-11 18:06:27 INFO Agent starting run with config:
	batch_size: 8
	d_model: 5
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.059258495085931395
	embedding_layers: 4
	embedding_size: 100
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 1945
	net_layers: 3
	net_size: 89
	noise_std: 1.3472836312312215
2022-07-11 18:06:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=5 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.059258495085931395 --embedding_layers=4 --embedding_size=100 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0005 --max_steps=1945 --net_layers=3 --net_size=89 --noise_std=1.3472836312312215
2022-07-11 18:06:32 INFO Running runs: ['9s7ndlde']
2022-07-11 18:08:21 INFO Cleaning up finished run: 9s7ndlde
2022-07-11 18:08:22 INFO Agent received command: run
2022-07-11 18:08:22 INFO Agent starting run with config:
	batch_size: 4
	d_model: 124
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.6861887548514902
	embedding_layers: 2
	embedding_size: 99
	encoder_heads: 2
	encoder_layers: 3
	learning_rate: 0.001
	max_steps: 4403
	net_layers: 4
	net_size: 12
	noise_std: 0.14228843073451863
2022-07-11 18:08:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=124 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.6861887548514902 --embedding_layers=2 --embedding_size=99 --encoder_heads=2 --encoder_layers=3 --learning_rate=0.001 --max_steps=4403 --net_layers=4 --net_size=12 --noise_std=0.14228843073451863
2022-07-11 18:08:27 INFO Running runs: ['1mj6r1tk']
2022-07-11 18:15:17 INFO Cleaning up finished run: 1mj6r1tk
2022-07-11 18:15:18 INFO Agent received command: run
2022-07-11 18:15:18 INFO Agent starting run with config:
	batch_size: 4
	d_model: 64
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.33114055557681743
	embedding_layers: 4
	embedding_size: 125
	encoder_heads: 5
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 2309
	net_layers: 1
	net_size: 29
	noise_std: 0.6410132773089892
2022-07-11 18:15:18 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=64 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.33114055557681743 --embedding_layers=4 --embedding_size=125 --encoder_heads=5 --encoder_layers=6 --learning_rate=0.0001 --max_steps=2309 --net_layers=1 --net_size=29 --noise_std=0.6410132773089892
2022-07-11 18:15:23 INFO Running runs: ['y60vy8v6']
2022-07-11 18:18:28 INFO Cleaning up finished run: y60vy8v6
2022-07-11 18:18:28 INFO Agent received command: run
2022-07-11 18:18:28 INFO Agent starting run with config:
	batch_size: 64
	d_model: 42
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.4088654443202945
	embedding_layers: 2
	embedding_size: 68
	encoder_heads: 2
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 3044
	net_layers: 3
	net_size: 21
	noise_std: 0.7342166659563272
2022-07-11 18:18:28 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=42 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.4088654443202945 --embedding_layers=2 --embedding_size=68 --encoder_heads=2 --encoder_layers=3 --learning_rate=0.0005 --max_steps=3044 --net_layers=3 --net_size=21 --noise_std=0.7342166659563272
2022-07-11 18:18:33 INFO Running runs: ['2uwi0vl3']
2022-07-11 18:23:09 INFO Cleaning up finished run: 2uwi0vl3
2022-07-11 18:23:09 INFO Agent received command: run
2022-07-11 18:23:09 INFO Agent starting run with config:
	batch_size: 16
	d_model: 97
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.00692509396885288
	embedding_layers: 4
	embedding_size: 109
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 2051
	net_layers: 2
	net_size: 30
	noise_std: 1.1636101199605875
2022-07-11 18:23:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=97 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.00692509396885288 --embedding_layers=4 --embedding_size=109 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0005 --max_steps=2051 --net_layers=2 --net_size=30 --noise_std=1.1636101199605875
2022-07-11 18:23:14 INFO Running runs: ['qfayf3td']
2022-07-11 18:25:39 INFO Cleaning up finished run: qfayf3td
2022-07-11 18:25:40 INFO Agent received command: run
2022-07-11 18:25:40 INFO Agent starting run with config:
	batch_size: 32
	d_model: 88
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.0900937203228258
	embedding_layers: 4
	embedding_size: 113
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 2087
	net_layers: 3
	net_size: 75
	noise_std: 1.1809956026946369
2022-07-11 18:25:40 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=88 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.0900937203228258 --embedding_layers=4 --embedding_size=113 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.0001 --max_steps=2087 --net_layers=3 --net_size=75 --noise_std=1.1809956026946369
2022-07-11 18:25:45 INFO Running runs: ['xo9vnqjm']
2022-07-11 18:28:10 INFO Cleaning up finished run: xo9vnqjm
2022-07-11 18:28:11 INFO Agent received command: run
2022-07-11 18:28:11 INFO Agent starting run with config:
	batch_size: 32
	d_model: 113
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.0854074210375686
	embedding_layers: 2
	embedding_size: 121
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 1393
	net_layers: 4
	net_size: 36
	noise_std: 1.0896919711399238
2022-07-11 18:28:11 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=113 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.0854074210375686 --embedding_layers=2 --embedding_size=121 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.0001 --max_steps=1393 --net_layers=4 --net_size=36 --noise_std=1.0896919711399238
2022-07-11 18:28:16 INFO Running runs: ['zkgbp0f7']
2022-07-11 18:30:15 INFO Cleaning up finished run: zkgbp0f7
2022-07-11 18:30:16 INFO Agent received command: run
2022-07-11 18:30:16 INFO Agent starting run with config:
	batch_size: 4
	d_model: 103
	decoder_heads: 1
	decoder_layers: 6
	early_stopping: 0.03227068631518282
	embedding_layers: 4
	embedding_size: 74
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.0005
	max_steps: 1857
	net_layers: 4
	net_size: 11
	noise_std: 1.1335623643200547
2022-07-11 18:30:16 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=103 --decoder_heads=1 --decoder_layers=6 --early_stopping=0.03227068631518282 --embedding_layers=4 --embedding_size=74 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.0005 --max_steps=1857 --net_layers=4 --net_size=11 --noise_std=1.1335623643200547
2022-07-11 18:30:21 INFO Running runs: ['brqjl3on']
2022-07-11 18:32:09 INFO Cleaning up finished run: brqjl3on
2022-07-11 18:32:10 INFO Agent received command: run
2022-07-11 18:32:10 INFO Agent starting run with config:
	batch_size: 4
	d_model: 113
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.5638998525217735
	embedding_layers: 2
	embedding_size: 122
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 1770
	net_layers: 2
	net_size: 13
	noise_std: 0.6870722478116305
2022-07-11 18:32:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=113 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.5638998525217735 --embedding_layers=2 --embedding_size=122 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.0001 --max_steps=1770 --net_layers=2 --net_size=13 --noise_std=0.6870722478116305
2022-07-11 18:32:15 INFO Running runs: ['yjsdd8iw']
2022-07-11 18:35:41 INFO Cleaning up finished run: yjsdd8iw
2022-07-11 18:35:42 INFO Agent received command: run
2022-07-11 18:35:42 INFO Agent starting run with config:
	batch_size: 128
	d_model: 30
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.2840781004876285
	embedding_layers: 2
	embedding_size: 83
	encoder_heads: 1
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 1386
	net_layers: 3
	net_size: 9
	noise_std: 0.4670335512714085
2022-07-11 18:35:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=30 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.2840781004876285 --embedding_layers=2 --embedding_size=83 --encoder_heads=1 --encoder_layers=7 --learning_rate=0.0001 --max_steps=1386 --net_layers=3 --net_size=9 --noise_std=0.4670335512714085
2022-07-11 18:35:47 INFO Running runs: ['a242j7vs']
2022-07-11 18:39:22 INFO Cleaning up finished run: a242j7vs
2022-07-11 18:39:24 INFO Agent received command: run
2022-07-11 18:39:24 INFO Agent starting run with config:
	batch_size: 16
	d_model: 57
	decoder_heads: 2
	decoder_layers: 7
	early_stopping: 0.08885743359053444
	embedding_layers: 3
	embedding_size: 107
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 2208
	net_layers: 4
	net_size: 48
	noise_std: 0.0346729524064187
2022-07-11 18:39:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=57 --decoder_heads=2 --decoder_layers=7 --early_stopping=0.08885743359053444 --embedding_layers=3 --embedding_size=107 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0005 --max_steps=2208 --net_layers=4 --net_size=48 --noise_std=0.0346729524064187
2022-07-11 18:39:29 INFO Running runs: ['sv1how1i']
2022-07-11 18:41:55 INFO Cleaning up finished run: sv1how1i
2022-07-11 18:41:56 INFO Agent received command: run
2022-07-11 18:41:56 INFO Agent starting run with config:
	batch_size: 4
	d_model: 54
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.03954711325198667
	embedding_layers: 2
	embedding_size: 126
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 1401
	net_layers: 3
	net_size: 94
	noise_std: 1.4830833735940492
2022-07-11 18:41:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=54 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.03954711325198667 --embedding_layers=2 --embedding_size=126 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0001 --max_steps=1401 --net_layers=3 --net_size=94 --noise_std=1.4830833735940492
2022-07-11 18:42:01 INFO Running runs: ['08unmazn']
2022-07-11 18:43:44 INFO Cleaning up finished run: 08unmazn
2022-07-11 18:43:44 INFO Agent received command: run
2022-07-11 18:43:44 INFO Agent starting run with config:
	batch_size: 64
	d_model: 44
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.03144585763955898
	embedding_layers: 4
	embedding_size: 113
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 2293
	net_layers: 4
	net_size: 23
	noise_std: 0.9028361415884196
2022-07-11 18:43:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=44 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.03144585763955898 --embedding_layers=4 --embedding_size=113 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0001 --max_steps=2293 --net_layers=4 --net_size=23 --noise_std=0.9028361415884196
2022-07-11 18:43:49 INFO Running runs: ['6zy5x1nw']
2022-07-11 18:45:44 INFO Cleaning up finished run: 6zy5x1nw
2022-07-11 18:45:45 INFO Agent received command: run
2022-07-11 18:45:45 INFO Agent starting run with config:
	batch_size: 32
	d_model: 23
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.17733406024468046
	embedding_layers: 3
	embedding_size: 121
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 1383
	net_layers: 4
	net_size: 23
	noise_std: 0.6897791459775521
2022-07-11 18:45:45 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=23 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.17733406024468046 --embedding_layers=3 --embedding_size=121 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0005 --max_steps=1383 --net_layers=4 --net_size=23 --noise_std=0.6897791459775521
2022-07-11 18:45:50 INFO Running runs: ['dmi6jwhz']
2022-07-11 18:48:06 INFO Cleaning up finished run: dmi6jwhz
2022-07-11 18:48:06 INFO Agent received command: run
2022-07-11 18:48:06 INFO Agent starting run with config:
	batch_size: 16
	d_model: 75
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 0.13488690140164197
	embedding_layers: 2
	embedding_size: 9
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1197
	net_layers: 3
	net_size: 16
	noise_std: 1.4140776796721208
2022-07-11 18:48:06 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=75 --decoder_heads=3 --decoder_layers=8 --early_stopping=0.13488690140164197 --embedding_layers=2 --embedding_size=9 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1197 --net_layers=3 --net_size=16 --noise_std=1.4140776796721208
2022-07-11 18:48:11 INFO Running runs: ['nn0ezaoa']
2022-07-11 18:50:20 INFO Cleaning up finished run: nn0ezaoa
2022-07-11 18:50:20 INFO Agent received command: run
2022-07-11 18:50:20 INFO Agent starting run with config:
	batch_size: 16
	d_model: 96
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.01643860225661864
	embedding_layers: 2
	embedding_size: 80
	encoder_heads: 2
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 4719
	net_layers: 4
	net_size: 18
	noise_std: 1.1764121911483068
2022-07-11 18:50:20 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=96 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.01643860225661864 --embedding_layers=2 --embedding_size=80 --encoder_heads=2 --encoder_layers=7 --learning_rate=0.0001 --max_steps=4719 --net_layers=4 --net_size=18 --noise_std=1.1764121911483068
2022-07-11 18:50:25 INFO Running runs: ['5mpr435v']
2022-07-11 18:53:24 INFO Cleaning up finished run: 5mpr435v
2022-07-11 18:53:24 INFO Agent received command: run
2022-07-11 18:53:24 INFO Agent starting run with config:
	batch_size: 128
	d_model: 92
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.04202562196876303
	embedding_layers: 3
	embedding_size: 39
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 1994
	net_layers: 4
	net_size: 30
	noise_std: 0.5227804813696477
2022-07-11 18:53:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=92 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.04202562196876303 --embedding_layers=3 --embedding_size=39 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0001 --max_steps=1994 --net_layers=4 --net_size=30 --noise_std=0.5227804813696477
2022-07-11 18:53:29 INFO Running runs: ['e063jt96']
2022-07-11 18:56:30 INFO Cleaning up finished run: e063jt96
2022-07-11 18:56:30 INFO Agent received command: run
2022-07-11 18:56:30 INFO Agent starting run with config:
	batch_size: 8
	d_model: 104
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.847714490087721
	embedding_layers: 4
	embedding_size: 121
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 4201
	net_layers: 4
	net_size: 17
	noise_std: 1.3143510060310284
2022-07-11 18:56:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=104 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.847714490087721 --embedding_layers=4 --embedding_size=121 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0001 --max_steps=4201 --net_layers=4 --net_size=17 --noise_std=1.3143510060310284
2022-07-11 18:56:35 INFO Running runs: ['pvo8p8d6']
2022-07-11 19:02:47 INFO Cleaning up finished run: pvo8p8d6
2022-07-11 19:02:48 INFO Agent received command: run
2022-07-11 19:02:48 INFO Agent starting run with config:
	batch_size: 4
	d_model: 127
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.16831966044940228
	embedding_layers: 1
	embedding_size: 29
	encoder_heads: 3
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 2279
	net_layers: 4
	net_size: 58
	noise_std: 0.15582822490455378
2022-07-11 19:02:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=127 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.16831966044940228 --embedding_layers=1 --embedding_size=29 --encoder_heads=3 --encoder_layers=6 --learning_rate=0.0001 --max_steps=2279 --net_layers=4 --net_size=58 --noise_std=0.15582822490455378
2022-07-11 19:02:53 INFO Running runs: ['8vdw3dan']
2022-07-11 19:05:30 INFO Cleaning up finished run: 8vdw3dan
2022-07-11 19:05:31 INFO Agent received command: run
2022-07-11 19:05:31 INFO Agent starting run with config:
	batch_size: 8
	d_model: 89
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.09230471508857618
	embedding_layers: 3
	embedding_size: 127
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1696
	net_layers: 1
	net_size: 66
	noise_std: 0.6427544672979323
2022-07-11 19:05:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=89 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.09230471508857618 --embedding_layers=3 --embedding_size=127 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1696 --net_layers=1 --net_size=66 --noise_std=0.6427544672979323
2022-07-11 19:05:36 INFO Running runs: ['5i8lkorv']
2022-07-11 19:07:37 INFO Cleaning up finished run: 5i8lkorv
2022-07-11 19:07:37 INFO Agent received command: run
2022-07-11 19:07:37 INFO Agent starting run with config:
	batch_size: 4
	d_model: 114
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.31151301200192427
	embedding_layers: 4
	embedding_size: 91
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0005
	max_steps: 4856
	net_layers: 4
	net_size: 19
	noise_std: 0.7432017367878093
2022-07-11 19:07:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=114 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.31151301200192427 --embedding_layers=4 --embedding_size=91 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0005 --max_steps=4856 --net_layers=4 --net_size=19 --noise_std=0.7432017367878093
2022-07-11 19:07:42 INFO Running runs: ['r5nmwx4d']
2022-07-11 19:11:58 INFO Cleaning up finished run: r5nmwx4d
2022-07-11 19:11:59 INFO Agent received command: run
2022-07-11 19:11:59 INFO Agent starting run with config:
	batch_size: 128
	d_model: 93
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.03550570195343372
	embedding_layers: 1
	embedding_size: 113
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 3457
	net_layers: 4
	net_size: 56
	noise_std: 1.0673925029723752
2022-07-11 19:11:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=93 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.03550570195343372 --embedding_layers=1 --embedding_size=113 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.001 --max_steps=3457 --net_layers=4 --net_size=56 --noise_std=1.0673925029723752
2022-07-11 19:12:04 INFO Running runs: ['vv9qw0dj']
2022-07-11 19:15:20 INFO Cleaning up finished run: vv9qw0dj
2022-07-11 19:15:21 INFO Agent received command: run
2022-07-11 19:15:21 INFO Agent starting run with config:
	batch_size: 4
	d_model: 93
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.40683762481186225
	embedding_layers: 3
	embedding_size: 106
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 2201
	net_layers: 4
	net_size: 12
	noise_std: 0.8271631516106542
2022-07-11 19:15:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=93 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.40683762481186225 --embedding_layers=3 --embedding_size=106 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=2201 --net_layers=4 --net_size=12 --noise_std=0.8271631516106542
2022-07-11 19:15:26 INFO Running runs: ['ws4sut1h']
2022-07-11 19:18:58 INFO Cleaning up finished run: ws4sut1h
2022-07-11 19:18:59 INFO Agent received command: run
2022-07-11 19:18:59 INFO Agent starting run with config:
	batch_size: 4
	d_model: 122
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.08378954744723355
	embedding_layers: 4
	embedding_size: 86
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 2402
	net_layers: 4
	net_size: 34
	noise_std: 0.4461823443767343
2022-07-11 19:18:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=122 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.08378954744723355 --embedding_layers=4 --embedding_size=86 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0001 --max_steps=2402 --net_layers=4 --net_size=34 --noise_std=0.4461823443767343
2022-07-11 19:19:04 INFO Running runs: ['kwvsq024']
2022-07-11 19:21:19 INFO Cleaning up finished run: kwvsq024
2022-07-11 20:27:08 INFO Running runs: []
2022-07-11 20:27:09 INFO Agent received command: run
2022-07-11 20:27:09 INFO Agent starting run with config:
	batch_size: 64
	d_model: 60
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.9558242352356172
	embedding_layers: 2
	embedding_size: 38
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 1671
	net_layers: 2
	net_size: 117
	noise_std: 0.5959276182529034
2022-07-11 20:27:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=60 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.9558242352356172 --embedding_layers=2 --embedding_size=38 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.001 --max_steps=1671 --net_layers=2 --net_size=117 --noise_std=0.5959276182529034
2022-07-11 20:27:14 INFO Running runs: ['u7ulmimo']
2022-07-11 20:31:02 INFO Cleaning up finished run: u7ulmimo
2022-07-11 20:31:03 INFO Agent received command: run
2022-07-11 20:31:03 INFO Agent starting run with config:
	batch_size: 64
	d_model: 27
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 0.5815489192582991
	embedding_layers: 2
	embedding_size: 95
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0005
	max_steps: 4759
	net_layers: 4
	net_size: 46
	noise_std: 1.3647888678852054
2022-07-11 20:31:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=27 --decoder_heads=3 --decoder_layers=8 --early_stopping=0.5815489192582991 --embedding_layers=2 --embedding_size=95 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0005 --max_steps=4759 --net_layers=4 --net_size=46 --noise_std=1.3647888678852054
2022-07-11 20:31:08 INFO Running runs: ['zynt4ds0']
2022-07-11 20:32:55 INFO Running runs: []
2022-07-11 20:32:56 INFO Agent received command: run
2022-07-11 20:32:56 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4351695728227999
	max_bin: 245
	max_depth: 13
	min_data_in_leaf: 19
	num_iterations: 759
	num_leaves: 32
2022-07-11 20:32:56 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4351695728227999 --max_bin=245 --max_depth=13 --min_data_in_leaf=19 --num_iterations=759 --num_leaves=32
2022-07-11 20:33:01 INFO Running runs: ['g6iu0oxc']
2022-07-11 20:33:17 INFO Cleaning up finished run: g6iu0oxc
2022-07-11 20:33:17 INFO Agent received command: run
2022-07-11 20:33:17 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.16027848086820673
	max_bin: 99
	max_depth: 21
	min_data_in_leaf: 14
	num_iterations: 834
	num_leaves: 23
2022-07-11 20:33:17 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.16027848086820673 --max_bin=99 --max_depth=21 --min_data_in_leaf=14 --num_iterations=834 --num_leaves=23
2022-07-11 20:33:22 INFO Running runs: ['g2wsqndl']
2022-07-11 20:33:38 INFO Cleaning up finished run: g2wsqndl
2022-07-11 20:33:39 INFO Agent received command: run
2022-07-11 20:33:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0766977268073491
	max_bin: 80
	max_depth: 30
	min_data_in_leaf: 18
	num_iterations: 437
	num_leaves: 9
2022-07-11 20:33:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0766977268073491 --max_bin=80 --max_depth=30 --min_data_in_leaf=18 --num_iterations=437 --num_leaves=9
2022-07-11 20:33:44 INFO Running runs: ['gleihjmm']
2022-07-11 20:34:00 INFO Cleaning up finished run: gleihjmm
2022-07-11 20:34:00 INFO Agent received command: run
2022-07-11 20:34:00 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05294777549007845
	max_bin: 71
	max_depth: 23
	min_data_in_leaf: 16
	num_iterations: 369
	num_leaves: 11
2022-07-11 20:34:00 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05294777549007845 --max_bin=71 --max_depth=23 --min_data_in_leaf=16 --num_iterations=369 --num_leaves=11
2022-07-11 20:34:05 INFO Running runs: ['uusqtcn6']
2022-07-11 20:34:21 INFO Cleaning up finished run: uusqtcn6
2022-07-11 20:34:22 INFO Agent received command: run
2022-07-11 20:34:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.030934213485700357
	max_bin: 11
	max_depth: 28
	min_data_in_leaf: 12
	num_iterations: 132
	num_leaves: 20
2022-07-11 20:34:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.030934213485700357 --max_bin=11 --max_depth=28 --min_data_in_leaf=12 --num_iterations=132 --num_leaves=20
2022-07-11 20:34:27 INFO Running runs: ['p147366n']
2022-07-11 20:34:43 INFO Cleaning up finished run: p147366n
2022-07-11 20:34:44 INFO Agent received command: run
2022-07-11 20:34:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09522103895389468
	max_bin: 34
	max_depth: 14
	min_data_in_leaf: 19
	num_iterations: 583
	num_leaves: 5
2022-07-11 20:34:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09522103895389468 --max_bin=34 --max_depth=14 --min_data_in_leaf=19 --num_iterations=583 --num_leaves=5
2022-07-11 20:34:49 INFO Running runs: ['7i39wb90']
2022-07-11 20:35:05 INFO Cleaning up finished run: 7i39wb90
2022-07-11 20:35:05 INFO Agent received command: run
2022-07-11 20:35:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.10593974039683374
	max_bin: 42
	max_depth: 22
	min_data_in_leaf: 23
	num_iterations: 331
	num_leaves: 7
2022-07-11 20:35:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.10593974039683374 --max_bin=42 --max_depth=22 --min_data_in_leaf=23 --num_iterations=331 --num_leaves=7
2022-07-11 20:35:10 INFO Running runs: ['sjk0ps6o']
2022-07-11 20:35:27 INFO Cleaning up finished run: sjk0ps6o
2022-07-11 20:35:27 INFO Agent received command: run
2022-07-11 20:35:27 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08963510591464252
	max_bin: 7
	max_depth: 24
	min_data_in_leaf: 29
	num_iterations: 151
	num_leaves: 5
2022-07-11 20:35:27 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08963510591464252 --max_bin=7 --max_depth=24 --min_data_in_leaf=29 --num_iterations=151 --num_leaves=5
2022-07-11 20:35:32 INFO Running runs: ['blt6qzdo']
2022-07-11 20:35:48 INFO Cleaning up finished run: blt6qzdo
2022-07-11 20:35:49 INFO Agent received command: run
2022-07-11 20:35:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.1888002823655479
	max_bin: 57
	max_depth: 16
	min_data_in_leaf: 21
	num_iterations: 108
	num_leaves: 8
2022-07-11 20:35:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.1888002823655479 --max_bin=57 --max_depth=16 --min_data_in_leaf=21 --num_iterations=108 --num_leaves=8
2022-07-11 20:35:54 INFO Running runs: ['tsq2my1s']
2022-07-11 20:36:10 INFO Cleaning up finished run: tsq2my1s
2022-07-11 20:36:11 INFO Agent received command: run
2022-07-11 20:36:11 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.060766198232692026
	max_bin: 19
	max_depth: 22
	min_data_in_leaf: 25
	num_iterations: 572
	num_leaves: 6
2022-07-11 20:36:11 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.060766198232692026 --max_bin=19 --max_depth=22 --min_data_in_leaf=25 --num_iterations=572 --num_leaves=6
2022-07-11 20:36:16 INFO Running runs: ['x8io8yq3']
2022-07-11 20:36:16 INFO Cleaning up finished run: x8io8yq3
2022-07-11 20:36:17 INFO Agent received command: run
2022-07-11 20:36:17 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.003257695153529916
	max_bin: 53
	max_depth: 28
	min_data_in_leaf: 29
	num_iterations: 357
	num_leaves: 5
2022-07-11 20:36:17 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.003257695153529916 --max_bin=53 --max_depth=28 --min_data_in_leaf=29 --num_iterations=357 --num_leaves=5
2022-07-11 20:36:22 INFO Running runs: ['qelxnuop']
2022-07-11 20:36:22 INFO Cleaning up finished run: qelxnuop
2022-07-11 20:36:23 INFO Agent received command: run
2022-07-11 20:36:23 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3058542773127294
	max_bin: 10
	max_depth: 32
	min_data_in_leaf: 24
	num_iterations: 505
	num_leaves: 9
2022-07-11 20:36:23 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3058542773127294 --max_bin=10 --max_depth=32 --min_data_in_leaf=24 --num_iterations=505 --num_leaves=9
2022-07-11 20:36:28 INFO Running runs: ['iwd30dke']
2022-07-11 20:36:28 INFO Cleaning up finished run: iwd30dke
2022-07-11 20:36:28 INFO Agent received command: run
2022-07-11 20:36:28 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.13584702666969717
	max_bin: 105
	max_depth: 24
	min_data_in_leaf: 24
	num_iterations: 429
	num_leaves: 7
2022-07-11 20:36:28 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.13584702666969717 --max_bin=105 --max_depth=24 --min_data_in_leaf=24 --num_iterations=429 --num_leaves=7
2022-07-11 20:36:33 INFO Running runs: ['igdih7y3']
2022-07-11 20:36:33 INFO Cleaning up finished run: igdih7y3
2022-07-11 20:36:34 INFO Agent received command: run
2022-07-11 20:36:34 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.012771038467579432
	max_bin: 22
	max_depth: 24
	min_data_in_leaf: 24
	num_iterations: 450
	num_leaves: 18
2022-07-11 20:36:34 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.012771038467579432 --max_bin=22 --max_depth=24 --min_data_in_leaf=24 --num_iterations=450 --num_leaves=18
2022-07-11 20:36:39 INFO Running runs: ['7e0tov3s']
2022-07-11 20:36:39 INFO Cleaning up finished run: 7e0tov3s
2022-07-11 20:36:40 INFO Agent received command: run
2022-07-11 20:36:40 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04266771377116052
	max_bin: 28
	max_depth: 27
	min_data_in_leaf: 20
	num_iterations: 314
	num_leaves: 9
2022-07-11 20:36:40 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04266771377116052 --max_bin=28 --max_depth=27 --min_data_in_leaf=20 --num_iterations=314 --num_leaves=9
2022-07-11 20:36:45 INFO Running runs: ['a27ri7nm']
2022-07-11 20:36:45 INFO Cleaning up finished run: a27ri7nm
2022-07-11 20:36:45 INFO Agent received command: run
2022-07-11 20:36:45 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.943366011986588
	max_bin: 29
	max_depth: 27
	min_data_in_leaf: 30
	num_iterations: 471
	num_leaves: 6
2022-07-11 20:36:45 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.943366011986588 --max_bin=29 --max_depth=27 --min_data_in_leaf=30 --num_iterations=471 --num_leaves=6
2022-07-11 20:36:50 INFO Running runs: ['uyr4wg5m']
2022-07-11 20:36:50 INFO Cleaning up finished run: uyr4wg5m
2022-07-11 20:36:51 INFO Agent received command: run
2022-07-11 20:36:51 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8300611105518338
	max_bin: 7
	max_depth: 30
	min_data_in_leaf: 14
	num_iterations: 939
	num_leaves: 15
2022-07-11 20:36:51 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8300611105518338 --max_bin=7 --max_depth=30 --min_data_in_leaf=14 --num_iterations=939 --num_leaves=15
2022-07-11 20:36:56 INFO Running runs: ['mdwhoq3t']
2022-07-11 20:36:56 INFO Cleaning up finished run: mdwhoq3t
2022-07-11 20:36:57 INFO Agent received command: run
2022-07-11 20:36:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.01847709209949322
	max_bin: 54
	max_depth: 22
	min_data_in_leaf: 21
	num_iterations: 398
	num_leaves: 9
2022-07-11 20:36:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.01847709209949322 --max_bin=54 --max_depth=22 --min_data_in_leaf=21 --num_iterations=398 --num_leaves=9
2022-07-11 20:37:02 INFO Running runs: ['x6h6garw']
2022-07-11 20:37:02 INFO Cleaning up finished run: x6h6garw
2022-07-11 20:37:03 INFO Agent received command: run
2022-07-11 20:37:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06536446554544106
	max_bin: 13
	max_depth: 24
	min_data_in_leaf: 21
	num_iterations: 247
	num_leaves: 5
2022-07-11 20:37:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06536446554544106 --max_bin=13 --max_depth=24 --min_data_in_leaf=21 --num_iterations=247 --num_leaves=5
2022-07-11 20:37:08 INFO Running runs: ['003nmu9k']
2022-07-11 20:37:08 INFO Cleaning up finished run: 003nmu9k
2022-07-11 20:37:09 INFO Agent received command: run
2022-07-11 20:37:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.10773047147749291
	max_bin: 61
	max_depth: 26
	min_data_in_leaf: 25
	num_iterations: 393
	num_leaves: 6
2022-07-11 20:37:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.10773047147749291 --max_bin=61 --max_depth=26 --min_data_in_leaf=25 --num_iterations=393 --num_leaves=6
2022-07-11 20:37:14 INFO Running runs: ['lcoo84ce']
2022-07-11 20:37:14 INFO Cleaning up finished run: lcoo84ce
2022-07-11 20:37:14 INFO Agent received command: run
2022-07-11 20:37:14 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.025982301436802024
	max_bin: 82
	max_depth: 25
	min_data_in_leaf: 19
	num_iterations: 483
	num_leaves: 5
2022-07-11 20:37:14 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.025982301436802024 --max_bin=82 --max_depth=25 --min_data_in_leaf=19 --num_iterations=483 --num_leaves=5
2022-07-11 20:37:19 INFO Running runs: ['rriu9ns5']
2022-07-11 20:37:19 INFO Cleaning up finished run: rriu9ns5
2022-07-11 20:37:20 INFO Agent received command: run
2022-07-11 20:37:20 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.008177928630637932
	max_bin: 23
	max_depth: 25
	min_data_in_leaf: 23
	num_iterations: 369
	num_leaves: 11
2022-07-11 20:37:20 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.008177928630637932 --max_bin=23 --max_depth=25 --min_data_in_leaf=23 --num_iterations=369 --num_leaves=11
2022-07-11 20:37:25 INFO Running runs: ['ktymza5r']
2022-07-11 20:37:25 INFO Cleaning up finished run: ktymza5r
2022-07-11 20:38:01 INFO Running runs: []
2022-07-11 20:38:01 INFO Agent received command: run
2022-07-11 20:38:01 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.1136515531208212
	max_bin: 16
	max_depth: 25
	min_data_in_leaf: 21
	num_iterations: 345
	num_leaves: 6
2022-07-11 20:38:01 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.1136515531208212 --max_bin=16 --max_depth=25 --min_data_in_leaf=21 --num_iterations=345 --num_leaves=6
2022-07-11 20:38:06 INFO Running runs: ['khtw18hy']
2022-07-11 20:38:06 INFO Cleaning up finished run: khtw18hy
2022-07-11 20:38:07 INFO Agent received command: run
2022-07-11 20:38:07 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.004139137975189056
	max_bin: 27
	max_depth: 32
	min_data_in_leaf: 10
	num_iterations: 913
	num_leaves: 12
2022-07-11 20:38:07 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.004139137975189056 --max_bin=27 --max_depth=32 --min_data_in_leaf=10 --num_iterations=913 --num_leaves=12
2022-07-11 20:38:12 INFO Running runs: ['4q1e5yf6']
2022-07-11 20:38:12 INFO Cleaning up finished run: 4q1e5yf6
2022-07-11 20:38:13 INFO Agent received command: run
2022-07-11 20:38:13 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.016453175396938247
	max_bin: 25
	max_depth: 27
	min_data_in_leaf: 24
	num_iterations: 457
	num_leaves: 8
2022-07-11 20:38:13 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.016453175396938247 --max_bin=25 --max_depth=27 --min_data_in_leaf=24 --num_iterations=457 --num_leaves=8
2022-07-11 20:38:18 INFO Running runs: ['zjhh3fuh']
2022-07-11 20:38:18 INFO Cleaning up finished run: zjhh3fuh
2022-07-11 20:38:18 INFO Agent received command: run
2022-07-11 20:38:18 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9749611724762284
	max_bin: 251
	max_depth: 31
	min_data_in_leaf: 24
	num_iterations: 157
	num_leaves: 7
2022-07-11 20:38:18 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9749611724762284 --max_bin=251 --max_depth=31 --min_data_in_leaf=24 --num_iterations=157 --num_leaves=7
2022-07-11 20:38:23 INFO Running runs: ['z1mztjrp']
2022-07-11 20:38:23 INFO Cleaning up finished run: z1mztjrp
2022-07-11 20:38:24 INFO Agent received command: run
2022-07-11 20:38:24 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0035263401753187207
	max_bin: 255
	max_depth: 29
	min_data_in_leaf: 16
	num_iterations: 131
	num_leaves: 5
2022-07-11 20:38:24 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0035263401753187207 --max_bin=255 --max_depth=29 --min_data_in_leaf=16 --num_iterations=131 --num_leaves=5
2022-07-11 20:38:29 INFO Running runs: ['0qo7nx4n']
2022-07-11 20:38:29 INFO Cleaning up finished run: 0qo7nx4n
2022-07-11 20:38:29 INFO Agent received command: run
2022-07-11 20:38:29 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08091578980669789
	max_bin: 22
	max_depth: 27
	min_data_in_leaf: 28
	num_iterations: 960
	num_leaves: 12
2022-07-11 20:38:29 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08091578980669789 --max_bin=22 --max_depth=27 --min_data_in_leaf=28 --num_iterations=960 --num_leaves=12
2022-07-11 20:38:34 INFO Running runs: ['jlpq16j0']
2022-07-11 20:38:34 INFO Cleaning up finished run: jlpq16j0
2022-07-11 20:38:35 INFO Agent received command: run
2022-07-11 20:38:35 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.047084413805688285
	max_bin: 13
	max_depth: 23
	min_data_in_leaf: 13
	num_iterations: 581
	num_leaves: 5
2022-07-11 20:38:35 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.047084413805688285 --max_bin=13 --max_depth=23 --min_data_in_leaf=13 --num_iterations=581 --num_leaves=5
2022-07-11 20:38:40 INFO Running runs: ['hcfs72bv']
2022-07-11 20:38:40 INFO Cleaning up finished run: hcfs72bv
2022-07-11 20:38:41 INFO Agent received command: run
2022-07-11 20:38:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.740254855686065
	max_bin: 15
	max_depth: 27
	min_data_in_leaf: 30
	num_iterations: 910
	num_leaves: 40
2022-07-11 20:38:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.740254855686065 --max_bin=15 --max_depth=27 --min_data_in_leaf=30 --num_iterations=910 --num_leaves=40
2022-07-11 20:38:46 INFO Running runs: ['w4y6m666']
2022-07-11 20:38:46 INFO Cleaning up finished run: w4y6m666
2022-07-11 20:38:54 INFO Running runs: []
2022-07-11 20:38:54 INFO Agent received command: run
2022-07-11 20:38:54 INFO Agent starting run with config:
	batch_size: 8
	d_model: 84
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.04502182962172918
	embedding_layers: 3
	embedding_size: 21
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.001
	max_steps: 1929
	net_layers: 2
	net_size: 43
	noise_std: 1.216580863796244
2022-07-11 20:38:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=84 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.04502182962172918 --embedding_layers=3 --embedding_size=21 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.001 --max_steps=1929 --net_layers=2 --net_size=43 --noise_std=1.216580863796244
2022-07-11 20:38:59 INFO Running runs: ['9ouvfumo']
2022-07-11 20:38:59 INFO Cleaning up finished run: 9ouvfumo
2022-07-11 20:39:02 INFO Agent received command: run
2022-07-11 20:39:02 INFO Agent starting run with config:
	batch_size: 64
	d_model: 90
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.6125239254232839
	embedding_layers: 3
	embedding_size: 74
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 1420
	net_layers: 3
	net_size: 119
	noise_std: 0.19038733555716
2022-07-11 20:39:02 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=90 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.6125239254232839 --embedding_layers=3 --embedding_size=74 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.0005 --max_steps=1420 --net_layers=3 --net_size=119 --noise_std=0.19038733555716
2022-07-11 20:39:07 INFO Running runs: ['k2wwsqtt']
2022-07-11 20:39:07 INFO Cleaning up finished run: k2wwsqtt
2022-07-11 20:39:08 INFO Agent received command: run
2022-07-11 20:39:08 INFO Agent starting run with config:
	batch_size: 128
	d_model: 17
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.1334611450646093
	embedding_layers: 1
	embedding_size: 41
	encoder_heads: 1
	encoder_layers: 7
	learning_rate: 0.001
	max_steps: 2175
	net_layers: 2
	net_size: 79
	noise_std: 0.09776340122457576
2022-07-11 20:39:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=17 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.1334611450646093 --embedding_layers=1 --embedding_size=41 --encoder_heads=1 --encoder_layers=7 --learning_rate=0.001 --max_steps=2175 --net_layers=2 --net_size=79 --noise_std=0.09776340122457576
2022-07-11 20:39:13 INFO Running runs: ['0a34xat6']
2022-07-11 20:39:13 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-11 20:39:13 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-11 20:39:20 INFO Running runs: []
2022-07-11 20:39:21 INFO Agent received command: run
2022-07-11 20:39:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2727098631450361
	max_bin: 202
	max_depth: 28
	min_data_in_leaf: 19
	num_iterations: 515
	num_leaves: 33
2022-07-11 20:39:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2727098631450361 --max_bin=202 --max_depth=28 --min_data_in_leaf=19 --num_iterations=515 --num_leaves=33
2022-07-11 20:39:26 INFO Running runs: ['rw7p6te6']
2022-07-11 20:39:26 INFO Cleaning up finished run: rw7p6te6
2022-07-11 20:39:26 INFO Agent received command: run
2022-07-11 20:39:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.31988584610444826
	max_bin: 166
	max_depth: 19
	min_data_in_leaf: 25
	num_iterations: 460
	num_leaves: 35
2022-07-11 20:39:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.31988584610444826 --max_bin=166 --max_depth=19 --min_data_in_leaf=25 --num_iterations=460 --num_leaves=35
2022-07-11 20:39:31 INFO Running runs: ['9gvexyjd']
2022-07-11 20:39:31 INFO Cleaning up finished run: 9gvexyjd
2022-07-11 20:39:32 INFO Agent received command: run
2022-07-11 20:39:32 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.021487952111223008
	max_bin: 172
	max_depth: 11
	min_data_in_leaf: 10
	num_iterations: 117
	num_leaves: 21
2022-07-11 20:39:32 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.021487952111223008 --max_bin=172 --max_depth=11 --min_data_in_leaf=10 --num_iterations=117 --num_leaves=21
2022-07-11 20:39:37 INFO Running runs: ['5f2fl6v6']
2022-07-11 20:39:53 INFO Cleaning up finished run: 5f2fl6v6
2022-07-11 20:39:54 INFO Agent received command: run
2022-07-11 20:39:54 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03543286881885488
	max_bin: 205
	max_depth: 9
	min_data_in_leaf: 18
	num_iterations: 187
	num_leaves: 8
2022-07-11 20:39:54 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03543286881885488 --max_bin=205 --max_depth=9 --min_data_in_leaf=18 --num_iterations=187 --num_leaves=8
2022-07-11 20:39:59 INFO Running runs: ['v2bb0utf']
2022-07-11 20:40:15 INFO Cleaning up finished run: v2bb0utf
2022-07-11 20:40:15 INFO Agent received command: run
2022-07-11 20:40:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4189818696614911
	max_bin: 207
	max_depth: 30
	min_data_in_leaf: 16
	num_iterations: 588
	num_leaves: 23
2022-07-11 20:40:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4189818696614911 --max_bin=207 --max_depth=30 --min_data_in_leaf=16 --num_iterations=588 --num_leaves=23
2022-07-11 20:40:20 INFO Running runs: ['v2x9tifk']
2022-07-11 20:40:36 INFO Cleaning up finished run: v2x9tifk
2022-07-11 20:40:37 INFO Agent received command: run
2022-07-11 20:40:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.16609285655927308
	max_bin: 248
	max_depth: 6
	min_data_in_leaf: 14
	num_iterations: 100
	num_leaves: 16
2022-07-11 20:40:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.16609285655927308 --max_bin=248 --max_depth=6 --min_data_in_leaf=14 --num_iterations=100 --num_leaves=16
2022-07-11 20:40:42 INFO Running runs: ['2bbgzbp0']
2022-07-11 20:40:58 INFO Cleaning up finished run: 2bbgzbp0
2022-07-11 20:40:59 INFO Agent received command: run
2022-07-11 20:40:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.976212305204151
	max_bin: 12
	max_depth: 14
	min_data_in_leaf: 29
	num_iterations: 354
	num_leaves: 16
2022-07-11 20:40:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.976212305204151 --max_bin=12 --max_depth=14 --min_data_in_leaf=29 --num_iterations=354 --num_leaves=16
2022-07-11 20:41:04 INFO Running runs: ['loz72px2']
2022-07-11 20:41:21 INFO Cleaning up finished run: loz72px2
2022-07-11 20:41:22 INFO Agent received command: run
2022-07-11 20:41:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06770924427932401
	max_bin: 117
	max_depth: 8
	min_data_in_leaf: 11
	num_iterations: 256
	num_leaves: 8
2022-07-11 20:41:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06770924427932401 --max_bin=117 --max_depth=8 --min_data_in_leaf=11 --num_iterations=256 --num_leaves=8
2022-07-11 20:41:27 INFO Running runs: ['o93hrf5m']
2022-07-11 20:41:43 INFO Cleaning up finished run: o93hrf5m
2022-07-11 20:41:44 INFO Agent received command: run
2022-07-11 20:41:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.01085160959426823
	max_bin: 233
	max_depth: 5
	min_data_in_leaf: 10
	num_iterations: 675
	num_leaves: 5
2022-07-11 20:41:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.01085160959426823 --max_bin=233 --max_depth=5 --min_data_in_leaf=10 --num_iterations=675 --num_leaves=5
2022-07-11 20:41:49 INFO Running runs: ['zth626a6']
2022-07-11 20:42:05 INFO Cleaning up finished run: zth626a6
2022-07-11 20:42:06 INFO Agent received command: run
2022-07-11 20:42:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06669110936424005
	max_bin: 45
	max_depth: 4
	min_data_in_leaf: 15
	num_iterations: 128
	num_leaves: 13
2022-07-11 20:42:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06669110936424005 --max_bin=45 --max_depth=4 --min_data_in_leaf=15 --num_iterations=128 --num_leaves=13
2022-07-11 20:42:11 INFO Running runs: ['21f1koy0']
2022-07-11 20:42:27 INFO Cleaning up finished run: 21f1koy0
2022-07-11 20:42:28 INFO Agent received command: run
2022-07-11 20:42:28 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0743949411681587
	max_bin: 117
	max_depth: 13
	min_data_in_leaf: 10
	num_iterations: 598
	num_leaves: 10
2022-07-11 20:42:28 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0743949411681587 --max_bin=117 --max_depth=13 --min_data_in_leaf=10 --num_iterations=598 --num_leaves=10
2022-07-11 20:45:03 INFO Running runs: []
2022-07-11 20:45:03 INFO Agent received command: run
2022-07-11 20:45:03 INFO Agent starting run with config:
	batch_size: 16
	d_model: 62
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.44050951086592594
	embedding_layers: 3
	embedding_size: 49
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 1728
	net_layers: 1
	net_size: 84
	noise_std: 0.8632206055666078
2022-07-11 20:45:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=62 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.44050951086592594 --embedding_layers=3 --embedding_size=49 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.0005 --max_steps=1728 --net_layers=1 --net_size=84 --noise_std=0.8632206055666078
2022-07-11 20:45:08 INFO Running runs: ['xvv0dzen']
2022-07-11 20:47:57 INFO Cleaning up finished run: xvv0dzen
2022-07-11 20:47:57 INFO Agent received command: run
2022-07-11 20:47:57 INFO Agent starting run with config:
	batch_size: 64
	d_model: 101
	decoder_heads: 4
	decoder_layers: 6
	early_stopping: 0.9985173792035876
	embedding_layers: 1
	embedding_size: 119
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.0005
	max_steps: 3363
	net_layers: 1
	net_size: 70
	noise_std: 0.2303855815806414
2022-07-11 20:47:57 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=101 --decoder_heads=4 --decoder_layers=6 --early_stopping=0.9985173792035876 --embedding_layers=1 --embedding_size=119 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.0005 --max_steps=3363 --net_layers=1 --net_size=70 --noise_std=0.2303855815806414
2022-07-11 20:48:02 INFO Running runs: ['ugthlbdt']
2022-07-11 20:54:02 INFO Cleaning up finished run: ugthlbdt
2022-07-11 20:54:03 INFO Agent received command: run
2022-07-11 20:54:03 INFO Agent starting run with config:
	batch_size: 4
	d_model: 64
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.40626887917268795
	embedding_layers: 4
	embedding_size: 76
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 4875
	net_layers: 3
	net_size: 33
	noise_std: 0.6454087665479784
2022-07-11 20:54:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=64 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.40626887917268795 --embedding_layers=4 --embedding_size=76 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.001 --max_steps=4875 --net_layers=3 --net_size=33 --noise_std=0.6454087665479784
2022-07-11 20:54:08 INFO Running runs: ['4fkm2lu2']
2022-07-11 20:58:40 INFO Cleaning up finished run: 4fkm2lu2
2022-07-11 20:58:41 INFO Agent received command: run
2022-07-11 20:58:41 INFO Agent starting run with config:
	batch_size: 128
	d_model: 51
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.4103095229014655
	embedding_layers: 4
	embedding_size: 53
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 1062
	net_layers: 2
	net_size: 81
	noise_std: 0.7061348497398879
2022-07-11 20:58:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=51 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.4103095229014655 --embedding_layers=4 --embedding_size=53 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0005 --max_steps=1062 --net_layers=2 --net_size=81 --noise_std=0.7061348497398879
2022-07-11 20:58:46 INFO Running runs: ['t354qqsy']
2022-07-11 21:01:30 INFO Cleaning up finished run: t354qqsy
2022-07-11 21:01:31 INFO Agent received command: run
2022-07-11 21:01:31 INFO Agent starting run with config:
	batch_size: 128
	d_model: 6
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.2806263611829509
	embedding_layers: 4
	embedding_size: 43
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 2025
	net_layers: 2
	net_size: 106
	noise_std: 0.6474175844781365
2022-07-11 21:01:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=6 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.2806263611829509 --embedding_layers=4 --embedding_size=43 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.0005 --max_steps=2025 --net_layers=2 --net_size=106 --noise_std=0.6474175844781365
2022-07-11 21:01:36 INFO Running runs: ['8b9udt0m']
2022-07-11 21:04:40 INFO Cleaning up finished run: 8b9udt0m
2022-07-11 21:04:41 INFO Agent received command: run
2022-07-11 21:04:41 INFO Agent starting run with config:
	batch_size: 32
	d_model: 79
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.17158788014900206
	embedding_layers: 4
	embedding_size: 60
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 2015
	net_layers: 4
	net_size: 56
	noise_std: 1.1447355383771765
2022-07-11 21:04:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=79 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.17158788014900206 --embedding_layers=4 --embedding_size=60 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.0001 --max_steps=2015 --net_layers=4 --net_size=56 --noise_std=1.1447355383771765
2022-07-11 21:04:46 INFO Running runs: ['lhykjscz']
2022-07-11 21:07:23 INFO Cleaning up finished run: lhykjscz
2022-07-11 21:07:24 INFO Agent received command: run
2022-07-11 21:07:24 INFO Agent starting run with config:
	batch_size: 32
	d_model: 105
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.06948739594940434
	embedding_layers: 4
	embedding_size: 13
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 1787
	net_layers: 2
	net_size: 69
	noise_std: 0.6761056368549201
2022-07-11 21:07:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=105 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.06948739594940434 --embedding_layers=4 --embedding_size=13 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.001 --max_steps=1787 --net_layers=2 --net_size=69 --noise_std=0.6761056368549201
2022-07-11 21:07:29 INFO Running runs: ['98bpakm1']
2022-07-11 21:09:34 INFO Cleaning up finished run: 98bpakm1
2022-07-11 21:09:35 INFO Agent received command: run
2022-07-11 21:09:35 INFO Agent starting run with config:
	batch_size: 4
	d_model: 8
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.07551506287752119
	embedding_layers: 4
	embedding_size: 13
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 2552
	net_layers: 3
	net_size: 39
	noise_std: 1.3466562382571314
2022-07-11 21:09:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=8 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.07551506287752119 --embedding_layers=4 --embedding_size=13 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.0001 --max_steps=2552 --net_layers=3 --net_size=39 --noise_std=1.3466562382571314
2022-07-11 21:09:40 INFO Running runs: ['v5vrx67l']
2022-07-11 21:12:17 INFO Cleaning up finished run: v5vrx67l
2022-07-11 21:12:18 INFO Agent received command: run
2022-07-11 21:12:18 INFO Agent starting run with config:
	batch_size: 4
	d_model: 21
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.02857762364618721
	embedding_layers: 3
	embedding_size: 119
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1482
	net_layers: 4
	net_size: 70
	noise_std: 0.9384311756036232
2022-07-11 21:12:18 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=21 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.02857762364618721 --embedding_layers=3 --embedding_size=119 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1482 --net_layers=4 --net_size=70 --noise_std=0.9384311756036232
2022-07-11 21:12:23 INFO Running runs: ['vjdg6qio']
2022-07-11 21:14:17 INFO Cleaning up finished run: vjdg6qio
2022-07-11 21:14:18 INFO Agent received command: run
2022-07-11 21:14:18 INFO Agent starting run with config:
	batch_size: 8
	d_model: 16
	decoder_heads: 4
	decoder_layers: 6
	early_stopping: 0.001719663006850114
	embedding_layers: 3
	embedding_size: 46
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 2609
	net_layers: 3
	net_size: 54
	noise_std: 1.0101129895082166
2022-07-11 21:14:18 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=16 --decoder_heads=4 --decoder_layers=6 --early_stopping=0.001719663006850114 --embedding_layers=3 --embedding_size=46 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.001 --max_steps=2609 --net_layers=3 --net_size=54 --noise_std=1.0101129895082166
2022-07-11 21:14:23 INFO Running runs: ['84k1zbfp']
2022-07-11 21:16:39 INFO Cleaning up finished run: 84k1zbfp
2022-07-11 21:16:39 INFO Agent received command: run
2022-07-11 21:16:39 INFO Agent starting run with config:
	batch_size: 64
	d_model: 22
	decoder_heads: 4
	decoder_layers: 7
	early_stopping: 0.05867818755802068
	embedding_layers: 4
	embedding_size: 26
	encoder_heads: 5
	encoder_layers: 7
	learning_rate: 0.001
	max_steps: 1645
	net_layers: 1
	net_size: 15
	noise_std: 1.224595828265857
2022-07-11 21:16:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=22 --decoder_heads=4 --decoder_layers=7 --early_stopping=0.05867818755802068 --embedding_layers=4 --embedding_size=26 --encoder_heads=5 --encoder_layers=7 --learning_rate=0.001 --max_steps=1645 --net_layers=1 --net_size=15 --noise_std=1.224595828265857
2022-07-11 21:16:44 INFO Running runs: ['qzzy1yub']
2022-07-11 21:18:44 INFO Cleaning up finished run: qzzy1yub
2022-07-11 21:18:44 INFO Agent received command: run
2022-07-11 21:18:44 INFO Agent starting run with config:
	batch_size: 8
	d_model: 87
	decoder_heads: 5
	decoder_layers: 8
	early_stopping: 0.4743247484785702
	embedding_layers: 4
	embedding_size: 53
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1303
	net_layers: 3
	net_size: 85
	noise_std: 1.4843422471915433
2022-07-11 21:18:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=87 --decoder_heads=5 --decoder_layers=8 --early_stopping=0.4743247484785702 --embedding_layers=4 --embedding_size=53 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1303 --net_layers=3 --net_size=85 --noise_std=1.4843422471915433
2022-07-11 21:18:49 INFO Running runs: ['t60vxgly']
2022-07-11 21:21:38 INFO Cleaning up finished run: t60vxgly
2022-07-11 21:21:39 INFO Agent received command: run
2022-07-11 21:21:39 INFO Agent starting run with config:
	batch_size: 4
	d_model: 39
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.15565897651817096
	embedding_layers: 4
	embedding_size: 41
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 1540
	net_layers: 4
	net_size: 94
	noise_std: 1.3945548430222694
2022-07-11 21:21:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=39 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.15565897651817096 --embedding_layers=4 --embedding_size=41 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.001 --max_steps=1540 --net_layers=4 --net_size=94 --noise_std=1.3945548430222694
2022-07-11 21:21:44 INFO Running runs: ['hxvnz0f3']
2022-07-11 21:23:55 INFO Cleaning up finished run: hxvnz0f3
2022-07-11 21:23:56 INFO Agent received command: run
2022-07-11 21:23:56 INFO Agent starting run with config:
	batch_size: 8
	d_model: 23
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.4511461970284387
	embedding_layers: 4
	embedding_size: 12
	encoder_heads: 4
	encoder_layers: 7
	learning_rate: 0.0005
	max_steps: 3479
	net_layers: 4
	net_size: 25
	noise_std: 0.40917777348340745
2022-07-11 21:23:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=23 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.4511461970284387 --embedding_layers=4 --embedding_size=12 --encoder_heads=4 --encoder_layers=7 --learning_rate=0.0005 --max_steps=3479 --net_layers=4 --net_size=25 --noise_std=0.40917777348340745
2022-07-11 21:24:01 INFO Running runs: ['krupv8zh']
2022-07-11 21:28:12 INFO Cleaning up finished run: krupv8zh
2022-07-11 21:28:13 INFO Agent received command: run
2022-07-11 21:28:13 INFO Agent starting run with config:
	batch_size: 128
	d_model: 25
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.15873410776972052
	embedding_layers: 4
	embedding_size: 33
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 1138
	net_layers: 2
	net_size: 76
	noise_std: 0.7285039652359381
2022-07-11 21:28:13 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=25 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.15873410776972052 --embedding_layers=4 --embedding_size=33 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.001 --max_steps=1138 --net_layers=2 --net_size=76 --noise_std=0.7285039652359381
2022-07-11 21:28:18 INFO Running runs: ['jmuloqph']
2022-07-11 21:30:34 INFO Cleaning up finished run: jmuloqph
2022-07-11 21:30:35 INFO Agent received command: run
2022-07-11 21:30:35 INFO Agent starting run with config:
	batch_size: 8
	d_model: 4
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.47210317431565296
	embedding_layers: 4
	embedding_size: 15
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 3061
	net_layers: 2
	net_size: 43
	noise_std: 0.8574586244500086
2022-07-11 21:30:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=4 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.47210317431565296 --embedding_layers=4 --embedding_size=15 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0005 --max_steps=3061 --net_layers=2 --net_size=43 --noise_std=0.8574586244500086
2022-07-11 21:30:40 INFO Running runs: ['pdkjsy2r']
2022-07-11 21:34:45 INFO Cleaning up finished run: pdkjsy2r
2022-07-11 21:34:46 INFO Agent received command: run
2022-07-11 21:34:46 INFO Agent starting run with config:
	batch_size: 8
	d_model: 108
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.44639806951416616
	embedding_layers: 4
	embedding_size: 9
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 3887
	net_layers: 4
	net_size: 25
	noise_std: 1.4808615254127169
2022-07-11 21:34:46 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=108 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.44639806951416616 --embedding_layers=4 --embedding_size=9 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0005 --max_steps=3887 --net_layers=4 --net_size=25 --noise_std=1.4808615254127169
2022-07-11 21:34:51 INFO Running runs: ['e5stpki5']
2022-07-11 21:40:49 INFO Cleaning up finished run: e5stpki5
2022-07-11 21:40:50 INFO Agent received command: run
2022-07-11 21:40:50 INFO Agent starting run with config:
	batch_size: 4
	d_model: 100
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.3642254573575642
	embedding_layers: 4
	embedding_size: 10
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 4269
	net_layers: 3
	net_size: 15
	noise_std: 0.6221429941960624
2022-07-11 21:40:50 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=100 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.3642254573575642 --embedding_layers=4 --embedding_size=10 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.001 --max_steps=4269 --net_layers=3 --net_size=15 --noise_std=0.6221429941960624
2022-07-11 21:40:55 INFO Running runs: ['yoyvu9ss']
2022-07-11 21:45:56 INFO Cleaning up finished run: yoyvu9ss
2022-07-11 21:45:57 INFO Agent received command: run
2022-07-11 21:45:57 INFO Agent starting run with config:
	batch_size: 8
	d_model: 13
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.00727320505637552
	embedding_layers: 3
	embedding_size: 14
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 2560
	net_layers: 4
	net_size: 26
	noise_std: 1.4340260307663688
2022-07-11 21:45:57 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=13 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.00727320505637552 --embedding_layers=3 --embedding_size=14 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0001 --max_steps=2560 --net_layers=4 --net_size=26 --noise_std=1.4340260307663688
2022-07-11 21:46:02 INFO Running runs: ['t6fy9gkx']
2022-07-11 21:47:51 INFO Cleaning up finished run: t6fy9gkx
2022-07-11 21:47:52 INFO Agent received command: run
2022-07-11 21:47:52 INFO Agent starting run with config:
	batch_size: 32
	d_model: 38
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.2408477028942866
	embedding_layers: 4
	embedding_size: 10
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 4700
	net_layers: 4
	net_size: 53
	noise_std: 1.0405975127369764
2022-07-11 21:47:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=38 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.2408477028942866 --embedding_layers=4 --embedding_size=10 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.001 --max_steps=4700 --net_layers=4 --net_size=53 --noise_std=1.0405975127369764
2022-07-11 21:47:57 INFO Running runs: ['b83mbgr2']
2022-07-11 21:52:30 INFO Cleaning up finished run: b83mbgr2
2022-07-11 21:52:31 INFO Agent received command: run
2022-07-11 21:52:31 INFO Agent starting run with config:
	batch_size: 4
	d_model: 17
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.013753486876541989
	embedding_layers: 3
	embedding_size: 40
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 3465
	net_layers: 1
	net_size: 25
	noise_std: 0.994676877403852
2022-07-11 21:52:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=17 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.013753486876541989 --embedding_layers=3 --embedding_size=40 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.0001 --max_steps=3465 --net_layers=1 --net_size=25 --noise_std=0.994676877403852
2022-07-11 21:52:36 INFO Running runs: ['bsh8n396']
2022-07-11 21:55:08 INFO Cleaning up finished run: bsh8n396
2022-07-11 21:55:10 INFO Agent received command: run
2022-07-11 21:55:10 INFO Agent starting run with config:
	batch_size: 64
	d_model: 11
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.7530342432310352
	embedding_layers: 4
	embedding_size: 32
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1832
	net_layers: 4
	net_size: 73
	noise_std: 1.4204451977962675
2022-07-11 21:55:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=11 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.7530342432310352 --embedding_layers=4 --embedding_size=32 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1832 --net_layers=4 --net_size=73 --noise_std=1.4204451977962675
2022-07-11 21:55:15 INFO Running runs: ['lx4lz0pd']
2022-07-11 21:59:19 INFO Cleaning up finished run: lx4lz0pd
2022-07-11 21:59:20 INFO Agent received command: run
2022-07-11 21:59:20 INFO Agent starting run with config:
	batch_size: 16
	d_model: 10
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.06566382758721023
	embedding_layers: 3
	embedding_size: 26
	encoder_heads: 2
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 3021
	net_layers: 4
	net_size: 16
	noise_std: 0.9765533349175344
2022-07-11 21:59:20 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=10 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.06566382758721023 --embedding_layers=3 --embedding_size=26 --encoder_heads=2 --encoder_layers=7 --learning_rate=0.0001 --max_steps=3021 --net_layers=4 --net_size=16 --noise_std=0.9765533349175344
2022-07-11 21:59:25 INFO Running runs: ['z1jvt5a9']
2022-07-11 22:02:08 INFO Cleaning up finished run: z1jvt5a9
2022-07-11 22:02:09 INFO Agent received command: run
2022-07-11 22:02:09 INFO Agent starting run with config:
	batch_size: 16
	d_model: 32
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.7807785221838068
	embedding_layers: 4
	embedding_size: 52
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 3820
	net_layers: 3
	net_size: 39
	noise_std: 1.3984005827591834
2022-07-11 22:02:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=32 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.7807785221838068 --embedding_layers=4 --embedding_size=52 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0001 --max_steps=3820 --net_layers=3 --net_size=39 --noise_std=1.3984005827591834
2022-07-11 22:02:14 INFO Running runs: ['c3710t6c']
2022-07-11 22:08:57 INFO Cleaning up finished run: c3710t6c
2022-07-11 22:08:58 INFO Agent received command: run
2022-07-11 22:08:58 INFO Agent starting run with config:
	batch_size: 4
	d_model: 42
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.2686941569319985
	embedding_layers: 4
	embedding_size: 14
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 1178
	net_layers: 3
	net_size: 48
	noise_std: 1.4385543955190991
2022-07-11 22:08:58 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=42 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.2686941569319985 --embedding_layers=4 --embedding_size=14 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.0001 --max_steps=1178 --net_layers=3 --net_size=48 --noise_std=1.4385543955190991
2022-07-11 22:09:03 INFO Running runs: ['z02yflc6']
2022-07-11 22:11:02 INFO Cleaning up finished run: z02yflc6
2022-07-11 22:11:03 INFO Agent received command: run
2022-07-11 22:11:03 INFO Agent starting run with config:
	batch_size: 16
	d_model: 25
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.2887998003366995
	embedding_layers: 4
	embedding_size: 25
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 3043
	net_layers: 4
	net_size: 57
	noise_std: 0.38746682677386907
2022-07-11 22:11:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=25 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.2887998003366995 --embedding_layers=4 --embedding_size=25 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.0001 --max_steps=3043 --net_layers=4 --net_size=57 --noise_std=0.38746682677386907
2022-07-11 22:11:08 INFO Running runs: ['se8sjono']
2022-07-11 22:14:25 INFO Cleaning up finished run: se8sjono
2022-07-11 22:14:26 INFO Agent received command: run
2022-07-11 22:14:26 INFO Agent starting run with config:
	batch_size: 32
	d_model: 35
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.0019248837554973752
	embedding_layers: 3
	embedding_size: 42
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1426
	net_layers: 4
	net_size: 82
	noise_std: 1.239296135803877
2022-07-11 22:14:26 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=35 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.0019248837554973752 --embedding_layers=3 --embedding_size=42 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1426 --net_layers=4 --net_size=82 --noise_std=1.239296135803877
2022-07-11 22:14:31 INFO Running runs: ['q2sk7ncp']
2022-07-11 22:16:15 INFO Cleaning up finished run: q2sk7ncp
2022-07-11 22:16:44 INFO Agent received command: run
2022-07-11 22:16:44 INFO Agent starting run with config:
	batch_size: 8
	d_model: 12
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.05604480814423218
	embedding_layers: 3
	embedding_size: 17
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 4637
	net_layers: 2
	net_size: 121
	noise_std: 1.3520148346373058
2022-07-11 22:16:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=12 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.05604480814423218 --embedding_layers=3 --embedding_size=17 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0005 --max_steps=4637 --net_layers=2 --net_size=121 --noise_std=1.3520148346373058
2022-07-11 22:16:49 INFO Running runs: ['gnnwygb6']
2022-07-11 22:19:32 INFO Cleaning up finished run: gnnwygb6
2022-07-11 22:20:07 INFO Agent received command: run
2022-07-11 22:20:07 INFO Agent starting run with config:
	batch_size: 8
	d_model: 37
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.008816778605389541
	embedding_layers: 3
	embedding_size: 28
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 4608
	net_layers: 4
	net_size: 72
	noise_std: 0.11173492070705938
2022-07-11 22:20:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=37 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.008816778605389541 --embedding_layers=3 --embedding_size=28 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.001 --max_steps=4608 --net_layers=4 --net_size=72 --noise_std=0.11173492070705938
2022-07-11 22:20:12 INFO Running runs: ['31qe8pyp']
2022-07-11 22:22:33 INFO Cleaning up finished run: 31qe8pyp
2022-07-11 22:22:34 INFO Agent received command: run
2022-07-11 22:22:34 INFO Agent starting run with config:
	batch_size: 64
	d_model: 29
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.366978040679772
	embedding_layers: 2
	embedding_size: 15
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1170
	net_layers: 4
	net_size: 124
	noise_std: 0.8203349813800649
2022-07-11 22:22:34 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=29 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.366978040679772 --embedding_layers=2 --embedding_size=15 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1170 --net_layers=4 --net_size=124 --noise_std=0.8203349813800649
2022-07-11 22:22:39 INFO Running runs: ['fcac1twn']
2022-07-11 22:25:12 INFO Cleaning up finished run: fcac1twn
2022-07-11 22:25:20 INFO Running runs: []
2022-07-11 22:25:20 INFO Agent received command: run
2022-07-11 22:25:20 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.016185887122415976
	max_bin: 237
	max_depth: 4
	min_data_in_leaf: 24
	num_iterations: 434
	num_leaves: 15
2022-07-11 22:25:20 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.016185887122415976 --max_bin=237 --max_depth=4 --min_data_in_leaf=24 --num_iterations=434 --num_leaves=15
2022-07-11 22:25:25 INFO Running runs: ['vbux7jb2']
2022-07-11 22:25:41 INFO Cleaning up finished run: vbux7jb2
2022-07-11 22:25:42 INFO Agent received command: run
2022-07-11 22:25:42 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.591306940036239
	max_bin: 116
	max_depth: 10
	min_data_in_leaf: 27
	num_iterations: 693
	num_leaves: 36
2022-07-11 22:25:42 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.591306940036239 --max_bin=116 --max_depth=10 --min_data_in_leaf=27 --num_iterations=693 --num_leaves=36
2022-07-11 22:25:47 INFO Running runs: ['u4gu3t9z']
2022-07-11 22:26:03 INFO Cleaning up finished run: u4gu3t9z
2022-07-11 22:26:04 INFO Agent received command: run
2022-07-11 22:26:04 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2024733054447071
	max_bin: 115
	max_depth: 4
	min_data_in_leaf: 15
	num_iterations: 121
	num_leaves: 16
2022-07-11 22:26:04 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2024733054447071 --max_bin=115 --max_depth=4 --min_data_in_leaf=15 --num_iterations=121 --num_leaves=16
2022-07-11 22:26:09 INFO Running runs: ['fb45kstk']
2022-07-11 22:26:25 INFO Cleaning up finished run: fb45kstk
2022-07-11 22:26:25 INFO Agent received command: run
2022-07-11 22:26:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.16048878039622372
	max_bin: 201
	max_depth: 5
	min_data_in_leaf: 23
	num_iterations: 440
	num_leaves: 14
2022-07-11 22:26:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.16048878039622372 --max_bin=201 --max_depth=5 --min_data_in_leaf=23 --num_iterations=440 --num_leaves=14
2022-07-11 22:26:30 INFO Running runs: ['rcb94qpg']
2022-07-11 22:26:57 INFO Cleaning up finished run: rcb94qpg
2022-07-11 22:26:58 INFO Agent received command: run
2022-07-11 22:26:58 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.29480238318484053
	max_bin: 159
	max_depth: 14
	min_data_in_leaf: 26
	num_iterations: 860
	num_leaves: 5
2022-07-11 22:26:58 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.29480238318484053 --max_bin=159 --max_depth=14 --min_data_in_leaf=26 --num_iterations=860 --num_leaves=5
2022-07-11 22:27:03 INFO Running runs: ['9uhziaei']
2022-07-11 22:27:19 INFO Cleaning up finished run: 9uhziaei
2022-07-11 22:27:19 INFO Agent received command: run
2022-07-11 22:27:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9861522660533852
	max_bin: 190
	max_depth: 26
	min_data_in_leaf: 30
	num_iterations: 733
	num_leaves: 5
2022-07-11 22:27:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9861522660533852 --max_bin=190 --max_depth=26 --min_data_in_leaf=30 --num_iterations=733 --num_leaves=5
2022-07-11 22:27:24 INFO Running runs: ['s00v07zw']
2022-07-11 22:28:02 INFO Cleaning up finished run: s00v07zw
2022-07-11 22:28:03 INFO Agent received command: run
2022-07-11 22:28:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.12869536829377437
	max_bin: 119
	max_depth: 30
	min_data_in_leaf: 11
	num_iterations: 729
	num_leaves: 21
2022-07-11 22:28:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.12869536829377437 --max_bin=119 --max_depth=30 --min_data_in_leaf=11 --num_iterations=729 --num_leaves=21
2022-07-11 22:28:08 INFO Running runs: ['dnihejt5']
2022-07-11 22:28:25 INFO Cleaning up finished run: dnihejt5
2022-07-11 22:28:25 INFO Agent received command: run
2022-07-11 22:28:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.7838454105098868
	max_bin: 8
	max_depth: 29
	min_data_in_leaf: 29
	num_iterations: 378
	num_leaves: 20
2022-07-11 22:28:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.7838454105098868 --max_bin=8 --max_depth=29 --min_data_in_leaf=29 --num_iterations=378 --num_leaves=20
2022-07-11 22:28:30 INFO Running runs: ['6go1u74q']
2022-07-11 22:28:46 INFO Cleaning up finished run: 6go1u74q
2022-07-11 22:28:47 INFO Agent received command: run
2022-07-11 22:28:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.7640818350117891
	max_bin: 62
	max_depth: 30
	min_data_in_leaf: 22
	num_iterations: 815
	num_leaves: 35
2022-07-11 22:28:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.7640818350117891 --max_bin=62 --max_depth=30 --min_data_in_leaf=22 --num_iterations=815 --num_leaves=35
2022-07-11 22:28:52 INFO Running runs: ['i3mu2eoa']
2022-07-11 22:29:08 INFO Cleaning up finished run: i3mu2eoa
2022-07-11 22:29:09 INFO Agent received command: run
2022-07-11 22:29:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6319200014733272
	max_bin: 191
	max_depth: 10
	min_data_in_leaf: 25
	num_iterations: 798
	num_leaves: 40
2022-07-11 22:29:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6319200014733272 --max_bin=191 --max_depth=10 --min_data_in_leaf=25 --num_iterations=798 --num_leaves=40
2022-07-11 22:29:14 INFO Running runs: ['0hxfgbmu']
2022-07-11 22:29:30 INFO Cleaning up finished run: 0hxfgbmu
2022-07-11 22:29:31 INFO Agent received command: run
2022-07-11 22:29:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6385662720915614
	max_bin: 146
	max_depth: 24
	min_data_in_leaf: 15
	num_iterations: 829
	num_leaves: 18
2022-07-11 22:29:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6385662720915614 --max_bin=146 --max_depth=24 --min_data_in_leaf=15 --num_iterations=829 --num_leaves=18
2022-07-11 22:29:36 INFO Running runs: ['etlh11lv']
2022-07-11 22:29:52 INFO Cleaning up finished run: etlh11lv
2022-07-11 22:29:53 INFO Agent received command: run
2022-07-11 22:29:53 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.36731609599298576
	max_bin: 168
	max_depth: 18
	min_data_in_leaf: 21
	num_iterations: 919
	num_leaves: 16
2022-07-11 22:29:53 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.36731609599298576 --max_bin=168 --max_depth=18 --min_data_in_leaf=21 --num_iterations=919 --num_leaves=16
2022-07-11 22:29:58 INFO Running runs: ['7qwzxr9k']
2022-07-11 22:30:14 INFO Cleaning up finished run: 7qwzxr9k
2022-07-11 22:30:14 INFO Agent received command: run
2022-07-11 22:30:14 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9116356895350406
	max_bin: 167
	max_depth: 28
	min_data_in_leaf: 17
	num_iterations: 795
	num_leaves: 28
2022-07-11 22:30:14 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9116356895350406 --max_bin=167 --max_depth=28 --min_data_in_leaf=17 --num_iterations=795 --num_leaves=28
2022-07-11 22:30:19 INFO Running runs: ['ejsser1r']
2022-07-11 22:30:35 INFO Cleaning up finished run: ejsser1r
2022-07-11 22:30:36 INFO Agent received command: run
2022-07-11 22:30:36 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.21799699641773684
	max_bin: 90
	max_depth: 31
	min_data_in_leaf: 27
	num_iterations: 292
	num_leaves: 20
2022-07-11 22:30:36 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.21799699641773684 --max_bin=90 --max_depth=31 --min_data_in_leaf=27 --num_iterations=292 --num_leaves=20
2022-07-11 22:30:41 INFO Running runs: ['mmtliv3a']
2022-07-11 22:30:57 INFO Cleaning up finished run: mmtliv3a
2022-07-11 22:30:58 INFO Agent received command: run
2022-07-11 22:30:58 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.10453717483885372
	max_bin: 187
	max_depth: 15
	min_data_in_leaf: 23
	num_iterations: 684
	num_leaves: 16
2022-07-11 22:30:58 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.10453717483885372 --max_bin=187 --max_depth=15 --min_data_in_leaf=23 --num_iterations=684 --num_leaves=16
2022-07-11 22:31:03 INFO Running runs: ['96cj5sgk']
2022-07-11 22:31:19 INFO Cleaning up finished run: 96cj5sgk
2022-07-11 22:31:20 INFO Agent received command: run
2022-07-11 22:31:20 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06655502525215684
	max_bin: 184
	max_depth: 28
	min_data_in_leaf: 13
	num_iterations: 691
	num_leaves: 34
2022-07-11 22:31:20 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06655502525215684 --max_bin=184 --max_depth=28 --min_data_in_leaf=13 --num_iterations=691 --num_leaves=34
2022-07-11 22:31:25 INFO Running runs: ['9bg80o0o']
2022-07-11 22:31:41 INFO Cleaning up finished run: 9bg80o0o
2022-07-11 22:31:42 INFO Agent received command: run
2022-07-11 22:31:42 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.22809592692009129
	max_bin: 206
	max_depth: 31
	min_data_in_leaf: 13
	num_iterations: 433
	num_leaves: 28
2022-07-11 22:31:42 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.22809592692009129 --max_bin=206 --max_depth=31 --min_data_in_leaf=13 --num_iterations=433 --num_leaves=28
2022-07-11 22:31:47 INFO Running runs: ['j3d43k2d']
2022-07-11 22:32:04 INFO Cleaning up finished run: j3d43k2d
2022-07-11 22:32:04 INFO Agent received command: run
2022-07-11 22:32:04 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.18013053622253172
	max_bin: 196
	max_depth: 17
	min_data_in_leaf: 23
	num_iterations: 946
	num_leaves: 35
2022-07-11 22:32:04 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.18013053622253172 --max_bin=196 --max_depth=17 --min_data_in_leaf=23 --num_iterations=946 --num_leaves=35
2022-07-11 22:32:09 INFO Running runs: ['51dkt53s']
2022-07-11 22:32:25 INFO Cleaning up finished run: 51dkt53s
2022-07-11 22:32:26 INFO Agent received command: run
2022-07-11 22:32:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6138874174789257
	max_bin: 110
	max_depth: 10
	min_data_in_leaf: 11
	num_iterations: 468
	num_leaves: 23
2022-07-11 22:32:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6138874174789257 --max_bin=110 --max_depth=10 --min_data_in_leaf=11 --num_iterations=468 --num_leaves=23
2022-07-11 22:32:31 INFO Running runs: ['44mzoq8g']
2022-07-11 22:32:48 INFO Cleaning up finished run: 44mzoq8g
2022-07-11 22:32:48 INFO Agent received command: run
2022-07-11 22:32:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2863677040953122
	max_bin: 236
	max_depth: 24
	min_data_in_leaf: 22
	num_iterations: 374
	num_leaves: 14
2022-07-11 22:32:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2863677040953122 --max_bin=236 --max_depth=24 --min_data_in_leaf=22 --num_iterations=374 --num_leaves=14
2022-07-11 22:32:53 INFO Running runs: ['45udi1nm']
2022-07-11 22:33:10 INFO Cleaning up finished run: 45udi1nm
2022-07-11 22:33:11 INFO Agent received command: run
2022-07-11 22:33:11 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6837439655381202
	max_bin: 185
	max_depth: 8
	min_data_in_leaf: 22
	num_iterations: 556
	num_leaves: 32
2022-07-11 22:33:11 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6837439655381202 --max_bin=185 --max_depth=8 --min_data_in_leaf=22 --num_iterations=556 --num_leaves=32
2022-07-11 22:33:16 INFO Running runs: ['wi05rras']
2022-07-11 22:33:32 INFO Cleaning up finished run: wi05rras
2022-07-11 22:33:33 INFO Agent received command: run
2022-07-11 22:33:33 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5587724067215524
	max_bin: 232
	max_depth: 8
	min_data_in_leaf: 25
	num_iterations: 258
	num_leaves: 21
2022-07-11 22:33:33 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.5587724067215524 --max_bin=232 --max_depth=8 --min_data_in_leaf=25 --num_iterations=258 --num_leaves=21
2022-07-11 22:33:38 INFO Running runs: ['v0nt962h']
2022-07-11 22:33:50 INFO Cleaning up finished run: v0nt962h
2022-07-11 22:33:51 INFO Agent received command: run
2022-07-11 22:33:51 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5908031633650485
	max_bin: 169
	max_depth: 24
	min_data_in_leaf: 28
	num_iterations: 621
	num_leaves: 8
2022-07-11 22:33:51 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.5908031633650485 --max_bin=169 --max_depth=24 --min_data_in_leaf=28 --num_iterations=621 --num_leaves=8
2022-07-11 22:33:56 INFO Running runs: ['39eco0aw']
2022-07-11 22:34:12 INFO Cleaning up finished run: 39eco0aw
2022-07-11 22:34:13 INFO Agent received command: run
2022-07-11 22:34:13 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.35412959751973094
	max_bin: 51
	max_depth: 7
	min_data_in_leaf: 13
	num_iterations: 591
	num_leaves: 23
2022-07-11 22:34:13 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.35412959751973094 --max_bin=51 --max_depth=7 --min_data_in_leaf=13 --num_iterations=591 --num_leaves=23
2022-07-11 22:34:18 INFO Running runs: ['vn38fpuf']
2022-07-11 22:34:34 INFO Cleaning up finished run: vn38fpuf
2022-07-11 22:34:35 INFO Agent received command: run
2022-07-11 22:34:35 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05143281747202299
	max_bin: 118
	max_depth: 17
	min_data_in_leaf: 28
	num_iterations: 777
	num_leaves: 9
2022-07-11 22:34:35 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05143281747202299 --max_bin=118 --max_depth=17 --min_data_in_leaf=28 --num_iterations=777 --num_leaves=9
2022-07-11 22:34:40 INFO Running runs: ['n5oxk2tw']
2022-07-11 22:34:56 INFO Cleaning up finished run: n5oxk2tw
2022-07-11 22:34:57 INFO Agent received command: run
2022-07-11 22:34:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8179126024427184
	max_bin: 66
	max_depth: 7
	min_data_in_leaf: 20
	num_iterations: 834
	num_leaves: 37
2022-07-11 22:34:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8179126024427184 --max_bin=66 --max_depth=7 --min_data_in_leaf=20 --num_iterations=834 --num_leaves=37
2022-07-11 22:35:02 INFO Running runs: ['n2lot433']
2022-07-11 22:35:18 INFO Cleaning up finished run: n2lot433
2022-07-11 22:35:19 INFO Agent received command: run
2022-07-11 22:35:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3759228701596318
	max_bin: 9
	max_depth: 21
	min_data_in_leaf: 19
	num_iterations: 843
	num_leaves: 16
2022-07-11 22:35:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3759228701596318 --max_bin=9 --max_depth=21 --min_data_in_leaf=19 --num_iterations=843 --num_leaves=16
2022-07-11 22:35:24 INFO Running runs: ['guwsb09b']
2022-07-11 22:35:40 INFO Cleaning up finished run: guwsb09b
2022-07-11 22:35:40 INFO Agent received command: run
2022-07-11 22:35:40 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.36326695048372937
	max_bin: 50
	max_depth: 22
	min_data_in_leaf: 17
	num_iterations: 381
	num_leaves: 12
2022-07-11 22:35:40 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.36326695048372937 --max_bin=50 --max_depth=22 --min_data_in_leaf=17 --num_iterations=381 --num_leaves=12
2022-07-11 22:35:45 INFO Running runs: ['2ocl5vgk']
2022-07-11 22:36:02 INFO Cleaning up finished run: 2ocl5vgk
2022-07-11 22:36:03 INFO Agent received command: run
2022-07-11 22:36:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8737083318775207
	max_bin: 99
	max_depth: 20
	min_data_in_leaf: 23
	num_iterations: 638
	num_leaves: 24
2022-07-11 22:36:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8737083318775207 --max_bin=99 --max_depth=20 --min_data_in_leaf=23 --num_iterations=638 --num_leaves=24
2022-07-11 22:36:08 INFO Running runs: ['7lpibn3v']
2022-07-11 22:36:24 INFO Cleaning up finished run: 7lpibn3v
2022-07-11 22:36:25 INFO Agent received command: run
2022-07-11 22:36:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03840956368637671
	max_bin: 214
	max_depth: 14
	min_data_in_leaf: 14
	num_iterations: 463
	num_leaves: 28
2022-07-11 22:36:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03840956368637671 --max_bin=214 --max_depth=14 --min_data_in_leaf=14 --num_iterations=463 --num_leaves=28
2022-07-11 22:36:30 INFO Running runs: ['oaez9bu3']
2022-07-11 22:36:46 INFO Cleaning up finished run: oaez9bu3
2022-07-11 22:36:53 INFO Running runs: []
2022-07-11 22:36:54 INFO Agent received command: run
2022-07-11 22:36:54 INFO Agent starting run with config:
	batch_size: 8
	d_model: 73
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.38219740675830993
	embedding_layers: 1
	embedding_size: 104
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.0005
	max_steps: 1547
	net_layers: 2
	net_size: 23
	noise_std: 0.3193949500717697
2022-07-11 22:36:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=73 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.38219740675830993 --embedding_layers=1 --embedding_size=104 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.0005 --max_steps=1547 --net_layers=2 --net_size=23 --noise_std=0.3193949500717697
2022-07-11 22:36:59 INFO Running runs: ['jktlvq3b']
2022-07-11 22:39:32 INFO Cleaning up finished run: jktlvq3b
2022-07-11 22:39:33 INFO Agent received command: run
2022-07-11 22:39:33 INFO Agent starting run with config:
	batch_size: 8
	d_model: 27
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.4391910455345184
	embedding_layers: 4
	embedding_size: 27
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 3727
	net_layers: 1
	net_size: 114
	noise_std: 0.7642747842836001
2022-07-11 22:39:33 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=27 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.4391910455345184 --embedding_layers=4 --embedding_size=27 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.0005 --max_steps=3727 --net_layers=1 --net_size=114 --noise_std=0.7642747842836001
2022-07-11 22:39:38 INFO Running runs: ['blaaevo4']
2022-07-11 22:43:06 INFO Cleaning up finished run: blaaevo4
2022-07-11 22:43:06 INFO Agent received command: run
2022-07-11 22:43:06 INFO Agent starting run with config:
	batch_size: 4
	d_model: 39
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.34367053162946104
	embedding_layers: 3
	embedding_size: 112
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 4993
	net_layers: 2
	net_size: 49
	noise_std: 0.5417709284241929
2022-07-11 22:43:06 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=39 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.34367053162946104 --embedding_layers=3 --embedding_size=112 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0005 --max_steps=4993 --net_layers=2 --net_size=49 --noise_std=0.5417709284241929
2022-07-11 22:43:11 INFO Running runs: ['bcsj1w8c']
2022-07-11 22:47:13 INFO Cleaning up finished run: bcsj1w8c
2022-07-11 22:47:14 INFO Agent received command: run
2022-07-11 22:47:14 INFO Agent starting run with config:
	batch_size: 8
	d_model: 24
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.41322500546533825
	embedding_layers: 4
	embedding_size: 104
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.001
	max_steps: 3678
	net_layers: 2
	net_size: 72
	noise_std: 0.4083932951926205
2022-07-11 22:47:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=24 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.41322500546533825 --embedding_layers=4 --embedding_size=104 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.001 --max_steps=3678 --net_layers=2 --net_size=72 --noise_std=0.4083932951926205
2022-07-11 22:47:19 INFO Running runs: ['qt3z5qxl']
2022-07-11 22:51:50 INFO Cleaning up finished run: qt3z5qxl
2022-07-11 22:51:50 INFO Agent received command: run
2022-07-11 22:51:50 INFO Agent starting run with config:
	batch_size: 4
	d_model: 21
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.1520302930258829
	embedding_layers: 4
	embedding_size: 90
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 3868
	net_layers: 1
	net_size: 80
	noise_std: 0.2645346565150667
2022-07-11 22:51:50 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=21 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.1520302930258829 --embedding_layers=4 --embedding_size=90 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0005 --max_steps=3868 --net_layers=1 --net_size=80 --noise_std=0.2645346565150667
2022-07-11 22:51:55 INFO Running runs: ['q78f7vxw']
2022-07-11 22:55:14 INFO Cleaning up finished run: q78f7vxw
2022-07-11 22:55:15 INFO Agent received command: run
2022-07-11 22:55:15 INFO Agent starting run with config:
	batch_size: 64
	d_model: 94
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.07231054129891057
	embedding_layers: 1
	embedding_size: 127
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.0005
	max_steps: 2202
	net_layers: 4
	net_size: 35
	noise_std: 0.3779676932640301
2022-07-11 22:55:15 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=94 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.07231054129891057 --embedding_layers=1 --embedding_size=127 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.0005 --max_steps=2202 --net_layers=4 --net_size=35 --noise_std=0.3779676932640301
2022-07-11 22:55:20 INFO Running runs: ['h2qmi2wg']
2022-07-11 22:57:42 INFO Cleaning up finished run: h2qmi2wg
2022-07-11 22:57:43 INFO Agent received command: run
2022-07-11 22:57:43 INFO Agent starting run with config:
	batch_size: 4
	d_model: 38
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.5615467971366855
	embedding_layers: 4
	embedding_size: 77
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.001
	max_steps: 4269
	net_layers: 3
	net_size: 87
	noise_std: 0.9803949110116816
2022-07-11 22:57:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=38 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.5615467971366855 --embedding_layers=4 --embedding_size=77 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.001 --max_steps=4269 --net_layers=3 --net_size=87 --noise_std=0.9803949110116816
2022-07-11 22:57:48 INFO Running runs: ['cf62k4e3']
2022-07-11 23:03:36 INFO Cleaning up finished run: cf62k4e3
2022-07-11 23:03:37 INFO Agent received command: run
2022-07-11 23:03:37 INFO Agent starting run with config:
	batch_size: 8
	d_model: 97
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.7222929232750732
	embedding_layers: 4
	embedding_size: 120
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 3811
	net_layers: 4
	net_size: 120
	noise_std: 0.5475357392594498
2022-07-11 23:03:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=97 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.7222929232750732 --embedding_layers=4 --embedding_size=120 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0005 --max_steps=3811 --net_layers=4 --net_size=120 --noise_std=0.5475357392594498
2022-07-11 23:03:42 INFO Running runs: ['alr423dh']
2022-07-11 23:10:08 INFO Cleaning up finished run: alr423dh
2022-07-11 23:10:10 INFO Agent received command: run
2022-07-11 23:10:10 INFO Agent starting run with config:
	batch_size: 4
	d_model: 67
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.4847005788844587
	embedding_layers: 4
	embedding_size: 72
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 1647
	net_layers: 3
	net_size: 117
	noise_std: 0.6714129980458036
2022-07-11 23:10:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=67 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.4847005788844587 --embedding_layers=4 --embedding_size=72 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.001 --max_steps=1647 --net_layers=3 --net_size=117 --noise_std=0.6714129980458036
2022-07-11 23:10:15 INFO Running runs: ['nhmimnp0']
2022-07-11 23:12:47 INFO Cleaning up finished run: nhmimnp0
2022-07-11 23:12:48 INFO Agent received command: run
2022-07-11 23:12:48 INFO Agent starting run with config:
	batch_size: 16
	d_model: 20
	decoder_heads: 1
	decoder_layers: 6
	early_stopping: 0.1136740188613875
	embedding_layers: 4
	embedding_size: 123
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 4140
	net_layers: 2
	net_size: 69
	noise_std: 0.6047874335720789
2022-07-11 23:12:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=20 --decoder_heads=1 --decoder_layers=6 --early_stopping=0.1136740188613875 --embedding_layers=4 --embedding_size=123 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.001 --max_steps=4140 --net_layers=2 --net_size=69 --noise_std=0.6047874335720789
2022-07-11 23:12:53 INFO Running runs: ['f6e5irux']
2022-07-11 23:17:08 INFO Cleaning up finished run: f6e5irux
2022-07-11 23:17:09 INFO Agent received command: run
2022-07-11 23:17:09 INFO Agent starting run with config:
	batch_size: 16
	d_model: 116
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.5350011769620953
	embedding_layers: 4
	embedding_size: 90
	encoder_heads: 5
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 1682
	net_layers: 3
	net_size: 121
	noise_std: 0.23529856332419763
2022-07-11 23:17:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=116 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.5350011769620953 --embedding_layers=4 --embedding_size=90 --encoder_heads=5 --encoder_layers=2 --learning_rate=0.0001 --max_steps=1682 --net_layers=3 --net_size=121 --noise_std=0.23529856332419763
2022-07-11 23:17:14 INFO Running runs: ['znl2d1x0']
2022-07-11 23:20:47 INFO Cleaning up finished run: znl2d1x0
2022-07-11 23:20:47 INFO Agent received command: run
2022-07-11 23:20:47 INFO Agent starting run with config:
	batch_size: 32
	d_model: 71
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.730127164775513
	embedding_layers: 3
	embedding_size: 109
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 3481
	net_layers: 3
	net_size: 58
	noise_std: 0.868647536130824
2022-07-11 23:20:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=71 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.730127164775513 --embedding_layers=3 --embedding_size=109 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.001 --max_steps=3481 --net_layers=3 --net_size=58 --noise_std=0.868647536130824
2022-07-11 23:20:52 INFO Running runs: ['xekq3aho']
2022-07-11 23:26:57 INFO Cleaning up finished run: xekq3aho
2022-07-11 23:26:58 INFO Agent received command: run
2022-07-11 23:26:58 INFO Agent starting run with config:
	batch_size: 16
	d_model: 69
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.06633822132841138
	embedding_layers: 2
	embedding_size: 49
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 3129
	net_layers: 3
	net_size: 104
	noise_std: 1.0853870740752638
2022-07-11 23:26:58 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=69 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.06633822132841138 --embedding_layers=2 --embedding_size=49 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.0001 --max_steps=3129 --net_layers=3 --net_size=104 --noise_std=1.0853870740752638
2022-07-11 23:27:03 INFO Running runs: ['olm2m9je']
2022-07-11 23:30:20 INFO Cleaning up finished run: olm2m9je
2022-07-11 23:30:21 INFO Agent received command: run
2022-07-11 23:30:21 INFO Agent starting run with config:
	batch_size: 4
	d_model: 43
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.7122868628906893
	embedding_layers: 3
	embedding_size: 30
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 4936
	net_layers: 1
	net_size: 21
	noise_std: 0.7136295426220184
2022-07-11 23:30:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=43 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.7122868628906893 --embedding_layers=3 --embedding_size=30 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.0001 --max_steps=4936 --net_layers=1 --net_size=21 --noise_std=0.7136295426220184
2022-07-11 23:30:26 INFO Running runs: ['lsp2b8e5']
2022-07-11 23:38:36 INFO Cleaning up finished run: lsp2b8e5
2022-07-11 23:38:37 INFO Agent received command: run
2022-07-11 23:38:37 INFO Agent starting run with config:
	batch_size: 64
	d_model: 98
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.7559434612660195
	embedding_layers: 3
	embedding_size: 22
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 4108
	net_layers: 3
	net_size: 55
	noise_std: 0.5478693950726499
2022-07-11 23:38:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=98 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.7559434612660195 --embedding_layers=3 --embedding_size=22 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=4108 --net_layers=3 --net_size=55 --noise_std=0.5478693950726499
2022-07-11 23:38:42 INFO Running runs: ['qjh8e1eo']
2022-07-11 23:48:34 INFO Cleaning up finished run: qjh8e1eo
2022-07-11 23:48:35 INFO Agent received command: run
2022-07-11 23:48:35 INFO Agent starting run with config:
	batch_size: 4
	d_model: 17
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.1559290320272364
	embedding_layers: 1
	embedding_size: 100
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 4991
	net_layers: 2
	net_size: 10
	noise_std: 1.333629413909881
2022-07-11 23:48:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=17 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.1559290320272364 --embedding_layers=1 --embedding_size=100 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.001 --max_steps=4991 --net_layers=2 --net_size=10 --noise_std=1.333629413909881
2022-07-11 23:48:40 INFO Running runs: ['m7tfgodg']
2022-07-11 23:52:28 INFO Cleaning up finished run: m7tfgodg
2022-07-11 23:52:29 INFO Agent received command: run
2022-07-11 23:52:29 INFO Agent starting run with config:
	batch_size: 16
	d_model: 102
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.7135758701712009
	embedding_layers: 1
	embedding_size: 68
	encoder_heads: 3
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 2847
	net_layers: 1
	net_size: 121
	noise_std: 1.192128581245082
2022-07-11 23:52:29 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=102 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.7135758701712009 --embedding_layers=1 --embedding_size=68 --encoder_heads=3 --encoder_layers=3 --learning_rate=0.0001 --max_steps=2847 --net_layers=1 --net_size=121 --noise_std=1.192128581245082
2022-07-11 23:52:34 INFO Running runs: ['cifa0686']
2022-07-11 23:57:25 INFO Cleaning up finished run: cifa0686
2022-07-11 23:57:26 INFO Agent received command: run
2022-07-11 23:57:26 INFO Agent starting run with config:
	batch_size: 8
	d_model: 74
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.6298639226365583
	embedding_layers: 4
	embedding_size: 107
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 1527
	net_layers: 3
	net_size: 94
	noise_std: 0.3469962011618304
2022-07-11 23:57:26 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=74 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.6298639226365583 --embedding_layers=4 --embedding_size=107 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0001 --max_steps=1527 --net_layers=3 --net_size=94 --noise_std=0.3469962011618304
2022-07-11 23:57:31 INFO Running runs: ['yemq9kwu']
2022-07-12 00:01:20 INFO Cleaning up finished run: yemq9kwu
2022-07-12 00:01:21 INFO Agent received command: run
2022-07-12 00:01:21 INFO Agent starting run with config:
	batch_size: 4
	d_model: 10
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.08724171929174096
	embedding_layers: 1
	embedding_size: 83
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 3120
	net_layers: 1
	net_size: 80
	noise_std: 1.00889887265519
2022-07-12 00:01:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=10 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.08724171929174096 --embedding_layers=1 --embedding_size=83 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.001 --max_steps=3120 --net_layers=1 --net_size=80 --noise_std=1.00889887265519
2022-07-12 00:01:26 INFO Running runs: ['nu8fwfev']
2022-07-12 00:03:42 INFO Cleaning up finished run: nu8fwfev
2022-07-12 00:03:42 INFO Agent received command: run
2022-07-12 00:03:42 INFO Agent starting run with config:
	batch_size: 32
	d_model: 93
	decoder_heads: 3
	decoder_layers: 3
	early_stopping: 0.7512468169902998
	embedding_layers: 1
	embedding_size: 19
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 2692
	net_layers: 3
	net_size: 90
	noise_std: 0.0252700327717928
2022-07-12 00:03:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=93 --decoder_heads=3 --decoder_layers=3 --early_stopping=0.7512468169902998 --embedding_layers=1 --embedding_size=19 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.0001 --max_steps=2692 --net_layers=3 --net_size=90 --noise_std=0.0252700327717928
2022-07-12 00:03:48 INFO Running runs: ['n2rwipqj']
2022-07-12 00:09:15 INFO Cleaning up finished run: n2rwipqj
2022-07-12 00:09:16 INFO Agent received command: run
2022-07-12 00:09:16 INFO Agent starting run with config:
	batch_size: 128
	d_model: 106
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.567306748615253
	embedding_layers: 4
	embedding_size: 104
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 3174
	net_layers: 2
	net_size: 51
	noise_std: 0.1412814193115992
2022-07-12 00:09:16 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=106 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.567306748615253 --embedding_layers=4 --embedding_size=104 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.001 --max_steps=3174 --net_layers=2 --net_size=51 --noise_std=0.1412814193115992
2022-07-12 00:09:21 INFO Running runs: ['57kshnjy']
2022-07-12 00:19:21 INFO Cleaning up finished run: 57kshnjy
2022-07-12 00:19:21 INFO Agent received command: run
2022-07-12 00:19:21 INFO Agent starting run with config:
	batch_size: 4
	d_model: 54
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.3127311497246905
	embedding_layers: 2
	embedding_size: 98
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 4532
	net_layers: 4
	net_size: 17
	noise_std: 0.3749137372583081
2022-07-12 00:19:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=54 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.3127311497246905 --embedding_layers=2 --embedding_size=98 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.0005 --max_steps=4532 --net_layers=4 --net_size=17 --noise_std=0.3749137372583081
2022-07-12 00:19:26 INFO Running runs: ['amw98t84']
2022-07-12 00:23:33 INFO Cleaning up finished run: amw98t84
2022-07-12 00:23:34 INFO Agent received command: run
2022-07-12 00:23:34 INFO Agent starting run with config:
	batch_size: 32
	d_model: 28
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.56827914108293
	embedding_layers: 4
	embedding_size: 73
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0005
	max_steps: 4884
	net_layers: 3
	net_size: 100
	noise_std: 0.5505001518322317
2022-07-12 00:23:34 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=28 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.56827914108293 --embedding_layers=4 --embedding_size=73 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0005 --max_steps=4884 --net_layers=3 --net_size=100 --noise_std=0.5505001518322317
2022-07-12 00:23:39 INFO Running runs: ['n9vood4z']
2022-07-12 00:30:50 INFO Cleaning up finished run: n9vood4z
2022-07-12 00:30:51 INFO Agent received command: run
2022-07-12 00:30:51 INFO Agent starting run with config:
	batch_size: 8
	d_model: 8
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.5920348860133874
	embedding_layers: 4
	embedding_size: 80
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 4388
	net_layers: 1
	net_size: 64
	noise_std: 0.7270610223103343
2022-07-12 00:30:51 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=8 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.5920348860133874 --embedding_layers=4 --embedding_size=80 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.001 --max_steps=4388 --net_layers=1 --net_size=64 --noise_std=0.7270610223103343
2022-07-12 00:30:56 INFO Running runs: ['ij0rwm9s']
2022-07-12 00:36:07 INFO Cleaning up finished run: ij0rwm9s
2022-07-12 00:36:08 INFO Agent received command: run
2022-07-12 00:36:08 INFO Agent starting run with config:
	batch_size: 32
	d_model: 51
	decoder_heads: 2
	decoder_layers: 7
	early_stopping: 0.2567191153310099
	embedding_layers: 4
	embedding_size: 125
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 4340
	net_layers: 4
	net_size: 112
	noise_std: 0.3193253398029427
2022-07-12 00:36:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=51 --decoder_heads=2 --decoder_layers=7 --early_stopping=0.2567191153310099 --embedding_layers=4 --embedding_size=125 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.0005 --max_steps=4340 --net_layers=4 --net_size=112 --noise_std=0.3193253398029427
2022-07-12 00:36:13 INFO Running runs: ['fg0oc5b6']
2022-07-12 00:40:48 INFO Cleaning up finished run: fg0oc5b6
2022-07-12 00:40:48 INFO Agent received command: run
2022-07-12 00:40:48 INFO Agent starting run with config:
	batch_size: 16
	d_model: 14
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.5445314576627948
	embedding_layers: 4
	embedding_size: 47
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0005
	max_steps: 3757
	net_layers: 3
	net_size: 128
	noise_std: 0.2779403094205861
2022-07-12 00:40:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=14 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.5445314576627948 --embedding_layers=4 --embedding_size=47 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0005 --max_steps=3757 --net_layers=3 --net_size=128 --noise_std=0.2779403094205861
2022-07-12 00:40:53 INFO Running runs: ['d6rrcqzi']
2022-07-12 00:45:19 INFO Cleaning up finished run: d6rrcqzi
2022-07-12 00:45:20 INFO Agent received command: run
2022-07-12 00:45:20 INFO Agent starting run with config:
	batch_size: 32
	d_model: 114
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.5744203266366898
	embedding_layers: 4
	embedding_size: 67
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 3894
	net_layers: 2
	net_size: 114
	noise_std: 0.06823450086588621
2022-07-12 00:45:20 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=114 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.5744203266366898 --embedding_layers=4 --embedding_size=67 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.0001 --max_steps=3894 --net_layers=2 --net_size=114 --noise_std=0.06823450086588621
2022-07-12 00:45:25 INFO Running runs: ['x9j8umw4']
2022-07-12 00:51:18 INFO Cleaning up finished run: x9j8umw4
2022-07-12 00:51:19 INFO Agent received command: run
2022-07-12 00:51:19 INFO Agent starting run with config:
	batch_size: 128
	d_model: 28
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.6923288530916554
	embedding_layers: 4
	embedding_size: 41
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 4500
	net_layers: 2
	net_size: 127
	noise_std: 0.7354677814381531
2022-07-12 00:51:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=28 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.6923288530916554 --embedding_layers=4 --embedding_size=41 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001 --max_steps=4500 --net_layers=2 --net_size=127 --noise_std=0.7354677814381531
2022-07-12 00:51:24 INFO Running runs: ['c5cglmh1']
2022-07-12 01:00:12 INFO Cleaning up finished run: c5cglmh1
2022-07-12 01:00:13 INFO Agent received command: run
2022-07-12 01:00:13 INFO Agent starting run with config:
	batch_size: 16
	d_model: 40
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.5422710152982652
	embedding_layers: 4
	embedding_size: 21
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.0005
	max_steps: 3674
	net_layers: 3
	net_size: 91
	noise_std: 0.2905473395193913
2022-07-12 01:00:13 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=40 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.5422710152982652 --embedding_layers=4 --embedding_size=21 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.0005 --max_steps=3674 --net_layers=3 --net_size=91 --noise_std=0.2905473395193913
2022-07-12 01:00:18 INFO Running runs: ['d3k34qjx']
2022-07-12 01:05:08 INFO Cleaning up finished run: d3k34qjx
2022-07-12 01:05:08 INFO Agent received command: run
2022-07-12 01:05:08 INFO Agent starting run with config:
	batch_size: 64
	d_model: 5
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.9732987132957466
	embedding_layers: 4
	embedding_size: 78
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 4626
	net_layers: 3
	net_size: 99
	noise_std: 0.7623078924918304
2022-07-12 01:05:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=5 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.9732987132957466 --embedding_layers=4 --embedding_size=78 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0001 --max_steps=4626 --net_layers=3 --net_size=99 --noise_std=0.7623078924918304
2022-07-12 01:05:13 INFO Running runs: ['dqfxd9l6']
2022-07-12 01:12:57 INFO Cleaning up finished run: dqfxd9l6
2022-07-12 01:13:04 INFO Running runs: []
2022-07-12 01:13:05 INFO Agent received command: run
2022-07-12 01:13:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8160840233053691
	max_bin: 230
	max_depth: 6
	min_data_in_leaf: 25
	num_iterations: 752
	num_leaves: 39
2022-07-12 01:13:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8160840233053691 --max_bin=230 --max_depth=6 --min_data_in_leaf=25 --num_iterations=752 --num_leaves=39
2022-07-12 01:13:10 INFO Running runs: ['7v3lfjko']
2022-07-12 01:13:26 INFO Cleaning up finished run: 7v3lfjko
2022-07-12 01:13:27 INFO Agent received command: run
2022-07-12 01:13:27 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3692322189155953
	max_bin: 149
	max_depth: 9
	min_data_in_leaf: 17
	num_iterations: 123
	num_leaves: 20
2022-07-12 01:13:27 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3692322189155953 --max_bin=149 --max_depth=9 --min_data_in_leaf=17 --num_iterations=123 --num_leaves=20
2022-07-12 01:13:32 INFO Running runs: ['q8o1lc6c']
2022-07-12 01:13:48 INFO Cleaning up finished run: q8o1lc6c
2022-07-12 01:13:49 INFO Agent received command: run
2022-07-12 01:13:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5723166748714433
	max_bin: 204
	max_depth: 22
	min_data_in_leaf: 19
	num_iterations: 223
	num_leaves: 30
2022-07-12 01:13:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.5723166748714433 --max_bin=204 --max_depth=22 --min_data_in_leaf=19 --num_iterations=223 --num_leaves=30
2022-07-12 01:13:54 INFO Running runs: ['31gksfi9']
2022-07-12 01:14:10 INFO Cleaning up finished run: 31gksfi9
2022-07-12 01:14:11 INFO Agent received command: run
2022-07-12 01:14:11 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06925118070271652
	max_bin: 224
	max_depth: 6
	min_data_in_leaf: 21
	num_iterations: 715
	num_leaves: 9
2022-07-12 01:14:11 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06925118070271652 --max_bin=224 --max_depth=6 --min_data_in_leaf=21 --num_iterations=715 --num_leaves=9
2022-07-12 01:14:16 INFO Running runs: ['gw0k4lwb']
2022-07-12 01:14:32 INFO Cleaning up finished run: gw0k4lwb
2022-07-12 01:14:33 INFO Agent received command: run
2022-07-12 01:14:33 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2792754258156609
	max_bin: 242
	max_depth: 22
	min_data_in_leaf: 28
	num_iterations: 944
	num_leaves: 22
2022-07-12 01:14:33 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2792754258156609 --max_bin=242 --max_depth=22 --min_data_in_leaf=28 --num_iterations=944 --num_leaves=22
2022-07-12 01:14:38 INFO Running runs: ['wwgdqaxx']
2022-07-12 01:14:54 INFO Cleaning up finished run: wwgdqaxx
2022-07-12 01:14:55 INFO Agent received command: run
2022-07-12 01:14:55 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4053141954876691
	max_bin: 125
	max_depth: 9
	min_data_in_leaf: 20
	num_iterations: 213
	num_leaves: 21
2022-07-12 01:14:55 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4053141954876691 --max_bin=125 --max_depth=9 --min_data_in_leaf=20 --num_iterations=213 --num_leaves=21
2022-07-12 01:15:00 INFO Running runs: ['u6tq43y2']
2022-07-12 01:15:21 INFO Cleaning up finished run: u6tq43y2
2022-07-12 01:15:22 INFO Agent received command: run
2022-07-12 01:15:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.17866972791099778
	max_bin: 128
	max_depth: 7
	min_data_in_leaf: 22
	num_iterations: 370
	num_leaves: 21
2022-07-12 01:15:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.17866972791099778 --max_bin=128 --max_depth=7 --min_data_in_leaf=22 --num_iterations=370 --num_leaves=21
2022-07-12 01:15:27 INFO Running runs: ['3eydos62']
2022-07-12 01:15:43 INFO Cleaning up finished run: 3eydos62
2022-07-12 01:15:44 INFO Agent received command: run
2022-07-12 01:15:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.20592365448193428
	max_bin: 22
	max_depth: 6
	min_data_in_leaf: 23
	num_iterations: 115
	num_leaves: 20
2022-07-12 01:15:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.20592365448193428 --max_bin=22 --max_depth=6 --min_data_in_leaf=23 --num_iterations=115 --num_leaves=20
2022-07-12 01:15:49 INFO Running runs: ['g6r1qxru']
2022-07-12 01:16:05 INFO Cleaning up finished run: g6r1qxru
2022-07-12 01:16:06 INFO Agent received command: run
2022-07-12 01:16:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4373943817940119
	max_bin: 21
	max_depth: 12
	min_data_in_leaf: 23
	num_iterations: 112
	num_leaves: 11
2022-07-12 01:16:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4373943817940119 --max_bin=21 --max_depth=12 --min_data_in_leaf=23 --num_iterations=112 --num_leaves=11
2022-07-12 01:16:11 INFO Running runs: ['nbo7gdkm']
2022-07-12 01:16:27 INFO Cleaning up finished run: nbo7gdkm
2022-07-12 01:16:27 INFO Agent received command: run
2022-07-12 01:16:27 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.018074734332734543
	max_bin: 69
	max_depth: 6
	min_data_in_leaf: 21
	num_iterations: 249
	num_leaves: 18
2022-07-12 01:16:27 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.018074734332734543 --max_bin=69 --max_depth=6 --min_data_in_leaf=21 --num_iterations=249 --num_leaves=18
2022-07-12 01:16:32 INFO Running runs: ['t083g8k7']
2022-07-12 01:16:49 INFO Cleaning up finished run: t083g8k7
2022-07-12 01:16:49 INFO Agent received command: run
2022-07-12 01:16:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.044798082209942414
	max_bin: 42
	max_depth: 9
	min_data_in_leaf: 23
	num_iterations: 124
	num_leaves: 37
2022-07-12 01:16:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.044798082209942414 --max_bin=42 --max_depth=9 --min_data_in_leaf=23 --num_iterations=124 --num_leaves=37
2022-07-12 01:16:54 INFO Running runs: ['gj7m62l5']
2022-07-12 01:17:11 INFO Cleaning up finished run: gj7m62l5
2022-07-12 01:17:11 INFO Agent received command: run
2022-07-12 01:17:11 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.022692203864491
	max_bin: 73
	max_depth: 4
	min_data_in_leaf: 16
	num_iterations: 329
	num_leaves: 28
2022-07-12 01:17:11 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.022692203864491 --max_bin=73 --max_depth=4 --min_data_in_leaf=16 --num_iterations=329 --num_leaves=28
2022-07-12 01:17:16 INFO Running runs: ['am0j04qp']
2022-07-12 01:17:32 INFO Cleaning up finished run: am0j04qp
2022-07-12 01:17:34 INFO Agent received command: run
2022-07-12 01:17:34 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0931491832375878
	max_bin: 66
	max_depth: 7
	min_data_in_leaf: 19
	num_iterations: 178
	num_leaves: 29
2022-07-12 01:17:34 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0931491832375878 --max_bin=66 --max_depth=7 --min_data_in_leaf=19 --num_iterations=178 --num_leaves=29
2022-07-12 01:17:39 INFO Running runs: ['0ry7l9pd']
2022-07-12 01:17:55 INFO Cleaning up finished run: 0ry7l9pd
2022-07-12 01:17:56 INFO Agent received command: run
2022-07-12 01:17:56 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.025092028488889695
	max_bin: 47
	max_depth: 5
	min_data_in_leaf: 24
	num_iterations: 236
	num_leaves: 19
2022-07-12 01:17:56 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.025092028488889695 --max_bin=47 --max_depth=5 --min_data_in_leaf=24 --num_iterations=236 --num_leaves=19
2022-07-12 01:18:01 INFO Running runs: ['o9ufv4z6']
2022-07-12 01:18:18 INFO Cleaning up finished run: o9ufv4z6
2022-07-12 01:18:19 INFO Agent received command: run
2022-07-12 01:18:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.18836774335632733
	max_bin: 6
	max_depth: 4
	min_data_in_leaf: 15
	num_iterations: 421
	num_leaves: 31
2022-07-12 01:18:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.18836774335632733 --max_bin=6 --max_depth=4 --min_data_in_leaf=15 --num_iterations=421 --num_leaves=31
2022-07-12 01:18:24 INFO Running runs: ['hpaq40w1']
2022-07-12 01:18:40 INFO Cleaning up finished run: hpaq40w1
2022-07-12 01:18:40 INFO Agent received command: run
2022-07-12 01:18:40 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.033748583025986933
	max_bin: 109
	max_depth: 4
	min_data_in_leaf: 16
	num_iterations: 371
	num_leaves: 17
2022-07-12 01:18:40 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.033748583025986933 --max_bin=109 --max_depth=4 --min_data_in_leaf=16 --num_iterations=371 --num_leaves=17
2022-07-12 01:18:45 INFO Running runs: ['jq3hlyn1']
2022-07-12 01:19:01 INFO Cleaning up finished run: jq3hlyn1
2022-07-12 01:19:02 INFO Agent received command: run
2022-07-12 01:19:02 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.21226585509166507
	max_bin: 72
	max_depth: 5
	min_data_in_leaf: 13
	num_iterations: 329
	num_leaves: 21
2022-07-12 01:19:02 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.21226585509166507 --max_bin=72 --max_depth=5 --min_data_in_leaf=13 --num_iterations=329 --num_leaves=21
2022-07-12 01:19:07 INFO Running runs: ['29y2ut5m']
2022-07-12 01:19:24 INFO Cleaning up finished run: 29y2ut5m
2022-07-12 01:19:24 INFO Agent received command: run
2022-07-12 01:19:24 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.14485973508680894
	max_bin: 86
	max_depth: 4
	min_data_in_leaf: 13
	num_iterations: 567
	num_leaves: 15
2022-07-12 01:19:24 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.14485973508680894 --max_bin=86 --max_depth=4 --min_data_in_leaf=13 --num_iterations=567 --num_leaves=15
2022-07-12 01:19:29 INFO Running runs: ['fdqtmipg']
2022-07-12 01:19:45 INFO Cleaning up finished run: fdqtmipg
2022-07-12 01:19:46 INFO Agent received command: run
2022-07-12 01:19:46 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03266841048054914
	max_bin: 29
	max_depth: 4
	min_data_in_leaf: 14
	num_iterations: 652
	num_leaves: 23
2022-07-12 01:19:46 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03266841048054914 --max_bin=29 --max_depth=4 --min_data_in_leaf=14 --num_iterations=652 --num_leaves=23
2022-07-12 01:19:51 INFO Running runs: ['22ibjxk9']
2022-07-12 01:20:07 INFO Cleaning up finished run: 22ibjxk9
2022-07-12 01:20:08 INFO Agent received command: run
2022-07-12 01:20:08 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2900136617439647
	max_bin: 8
	max_depth: 13
	min_data_in_leaf: 30
	num_iterations: 423
	num_leaves: 36
2022-07-12 01:20:08 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2900136617439647 --max_bin=8 --max_depth=13 --min_data_in_leaf=30 --num_iterations=423 --num_leaves=36
2022-07-12 01:20:13 INFO Running runs: ['5l0yyzzx']
2022-07-12 01:20:29 INFO Cleaning up finished run: 5l0yyzzx
2022-07-12 01:20:30 INFO Agent received command: run
2022-07-12 01:20:30 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03785666756656525
	max_bin: 137
	max_depth: 4
	min_data_in_leaf: 13
	num_iterations: 234
	num_leaves: 19
2022-07-12 01:20:30 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03785666756656525 --max_bin=137 --max_depth=4 --min_data_in_leaf=13 --num_iterations=234 --num_leaves=19
2022-07-12 01:20:35 INFO Running runs: ['pnzt1v0x']
2022-07-12 01:20:51 INFO Cleaning up finished run: pnzt1v0x
2022-07-12 01:20:52 INFO Agent received command: run
2022-07-12 01:20:52 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06713214670088952
	max_bin: 9
	max_depth: 6
	min_data_in_leaf: 30
	num_iterations: 179
	num_leaves: 35
2022-07-12 01:20:52 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06713214670088952 --max_bin=9 --max_depth=6 --min_data_in_leaf=30 --num_iterations=179 --num_leaves=35
2022-07-12 01:20:57 INFO Running runs: ['l01pf6fx']
2022-07-12 01:21:13 INFO Cleaning up finished run: l01pf6fx
2022-07-12 01:21:14 INFO Agent received command: run
2022-07-12 01:21:14 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.005727478496735716
	max_bin: 57
	max_depth: 5
	min_data_in_leaf: 28
	num_iterations: 434
	num_leaves: 31
2022-07-12 01:21:14 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.005727478496735716 --max_bin=57 --max_depth=5 --min_data_in_leaf=28 --num_iterations=434 --num_leaves=31
2022-07-12 01:21:19 INFO Running runs: ['8vczr89t']
2022-07-12 01:21:41 INFO Cleaning up finished run: 8vczr89t
2022-07-12 01:21:41 INFO Agent received command: run
2022-07-12 01:21:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.054657487107342195
	max_bin: 127
	max_depth: 6
	min_data_in_leaf: 20
	num_iterations: 250
	num_leaves: 6
2022-07-12 01:21:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.054657487107342195 --max_bin=127 --max_depth=6 --min_data_in_leaf=20 --num_iterations=250 --num_leaves=6
2022-07-12 01:21:46 INFO Running runs: ['qikgasln']
2022-07-12 01:22:02 INFO Cleaning up finished run: qikgasln
2022-07-12 01:22:03 INFO Agent received command: run
2022-07-12 01:22:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03024726692161861
	max_bin: 20
	max_depth: 4
	min_data_in_leaf: 24
	num_iterations: 284
	num_leaves: 8
2022-07-12 01:22:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03024726692161861 --max_bin=20 --max_depth=4 --min_data_in_leaf=24 --num_iterations=284 --num_leaves=8
2022-07-12 01:22:08 INFO Running runs: ['e1oyx1e4']
2022-07-12 01:22:24 INFO Cleaning up finished run: e1oyx1e4
2022-07-12 01:22:25 INFO Agent received command: run
2022-07-12 01:22:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.008783751027998998
	max_bin: 88
	max_depth: 11
	min_data_in_leaf: 14
	num_iterations: 288
	num_leaves: 13
2022-07-12 01:22:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.008783751027998998 --max_bin=88 --max_depth=11 --min_data_in_leaf=14 --num_iterations=288 --num_leaves=13
2022-07-12 01:22:30 INFO Running runs: ['51mskv1y']
2022-07-12 01:22:46 INFO Cleaning up finished run: 51mskv1y
2022-07-12 01:22:47 INFO Agent received command: run
2022-07-12 01:22:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0013208439544386552
	max_bin: 101
	max_depth: 4
	min_data_in_leaf: 14
	num_iterations: 619
	num_leaves: 35
2022-07-12 01:22:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0013208439544386552 --max_bin=101 --max_depth=4 --min_data_in_leaf=14 --num_iterations=619 --num_leaves=35
2022-07-12 01:22:52 INFO Running runs: ['11roh469']
2022-07-12 01:23:13 INFO Cleaning up finished run: 11roh469
2022-07-12 01:23:14 INFO Agent received command: run
2022-07-12 01:23:14 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04664519491836505
	max_bin: 6
	max_depth: 24
	min_data_in_leaf: 28
	num_iterations: 209
	num_leaves: 36
2022-07-12 01:23:14 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04664519491836505 --max_bin=6 --max_depth=24 --min_data_in_leaf=28 --num_iterations=209 --num_leaves=36
2022-07-12 01:23:19 INFO Running runs: ['ys2ecfp4']
2022-07-12 01:23:41 INFO Cleaning up finished run: ys2ecfp4
2022-07-12 01:23:41 INFO Agent received command: run
2022-07-12 01:23:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.26788501600225234
	max_bin: 11
	max_depth: 7
	min_data_in_leaf: 29
	num_iterations: 120
	num_leaves: 36
2022-07-12 01:23:42 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.26788501600225234 --max_bin=11 --max_depth=7 --min_data_in_leaf=29 --num_iterations=120 --num_leaves=36
2022-07-12 01:23:47 INFO Running runs: ['os3fjtmz']
2022-07-12 01:24:03 INFO Cleaning up finished run: os3fjtmz
2022-07-12 01:24:03 INFO Agent received command: run
2022-07-12 01:24:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0770096876250399
	max_bin: 44
	max_depth: 14
	min_data_in_leaf: 28
	num_iterations: 128
	num_leaves: 25
2022-07-12 01:24:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0770096876250399 --max_bin=44 --max_depth=14 --min_data_in_leaf=28 --num_iterations=128 --num_leaves=25
2022-07-12 01:24:08 INFO Running runs: ['ditkgf5a']
2022-07-12 01:24:24 INFO Cleaning up finished run: ditkgf5a
2022-07-12 01:24:32 INFO Running runs: []
2022-07-12 01:24:33 INFO Agent received command: run
2022-07-12 01:24:33 INFO Agent starting run with config:
	batch_size: 32
	d_model: 19
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.5506901593810598
	embedding_layers: 4
	embedding_size: 43
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 4271
	net_layers: 4
	net_size: 48
	noise_std: 1.1455870190339317
2022-07-12 01:24:33 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=19 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.5506901593810598 --embedding_layers=4 --embedding_size=43 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.001 --max_steps=4271 --net_layers=4 --net_size=48 --noise_std=1.1455870190339317
2022-07-12 01:24:38 INFO Running runs: ['uooi7ywg']
2022-07-12 01:30:57 INFO Cleaning up finished run: uooi7ywg
2022-07-12 01:30:57 INFO Agent received command: run
2022-07-12 01:30:57 INFO Agent starting run with config:
	batch_size: 8
	d_model: 122
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.6510810112790263
	embedding_layers: 1
	embedding_size: 84
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 4128
	net_layers: 2
	net_size: 119
	noise_std: 0.7846586183029046
2022-07-12 01:30:57 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=122 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.6510810112790263 --embedding_layers=1 --embedding_size=84 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.0005 --max_steps=4128 --net_layers=2 --net_size=119 --noise_std=0.7846586183029046
2022-07-12 01:31:02 INFO Running runs: ['us9ogd46']
2022-07-12 01:37:57 INFO Cleaning up finished run: us9ogd46
2022-07-12 01:37:58 INFO Agent received command: run
2022-07-12 01:37:58 INFO Agent starting run with config:
	batch_size: 64
	d_model: 55
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.008956861453202403
	embedding_layers: 2
	embedding_size: 23
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 4970
	net_layers: 4
	net_size: 76
	noise_std: 0.8483323404465625
2022-07-12 01:37:58 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=55 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.008956861453202403 --embedding_layers=2 --embedding_size=23 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0001 --max_steps=4970 --net_layers=4 --net_size=76 --noise_std=0.8483323404465625
2022-07-12 01:38:03 INFO Running runs: ['8qkv4xhi']
2022-07-12 01:41:46 INFO Cleaning up finished run: 8qkv4xhi
2022-07-12 01:41:47 INFO Agent received command: run
2022-07-12 01:41:47 INFO Agent starting run with config:
	batch_size: 64
	d_model: 6
	decoder_heads: 2
	decoder_layers: 7
	early_stopping: 0.8420184807898634
	embedding_layers: 4
	embedding_size: 40
	encoder_heads: 3
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 4399
	net_layers: 3
	net_size: 93
	noise_std: 1.306106483939014
2022-07-12 01:41:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=6 --decoder_heads=2 --decoder_layers=7 --early_stopping=0.8420184807898634 --embedding_layers=4 --embedding_size=40 --encoder_heads=3 --encoder_layers=3 --learning_rate=0.0005 --max_steps=4399 --net_layers=3 --net_size=93 --noise_std=1.306106483939014
2022-07-12 01:41:52 INFO Running runs: ['i85rknnv']
2022-07-12 01:49:27 INFO Cleaning up finished run: i85rknnv
2022-07-12 01:49:28 INFO Agent received command: run
2022-07-12 01:49:28 INFO Agent starting run with config:
	batch_size: 16
	d_model: 10
	decoder_heads: 5
	decoder_layers: 8
	early_stopping: 0.8125778129665414
	embedding_layers: 2
	embedding_size: 121
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 1266
	net_layers: 2
	net_size: 100
	noise_std: 0.7264189940416147
2022-07-12 01:49:28 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=10 --decoder_heads=5 --decoder_layers=8 --early_stopping=0.8125778129665414 --embedding_layers=2 --embedding_size=121 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.001 --max_steps=1266 --net_layers=2 --net_size=100 --noise_std=0.7264189940416147
2022-07-12 01:49:33 INFO Running runs: ['xdbpdfyk']
2022-07-12 01:52:49 INFO Cleaning up finished run: xdbpdfyk
2022-07-12 01:52:50 INFO Agent received command: run
2022-07-12 01:52:50 INFO Agent starting run with config:
	batch_size: 128
	d_model: 107
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.7977005030958102
	embedding_layers: 1
	embedding_size: 14
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 3321
	net_layers: 1
	net_size: 112
	noise_std: 1.3747502077628515
2022-07-12 01:52:50 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=107 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.7977005030958102 --embedding_layers=1 --embedding_size=14 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.0005 --max_steps=3321 --net_layers=1 --net_size=112 --noise_std=1.3747502077628515
2022-07-12 01:52:55 INFO Running runs: ['tkje7uq8']
2022-07-12 02:01:41 INFO Cleaning up finished run: tkje7uq8
2022-07-12 02:01:42 INFO Agent received command: run
2022-07-12 02:01:42 INFO Agent starting run with config:
	batch_size: 16
	d_model: 115
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.9577909734316296
	embedding_layers: 2
	embedding_size: 10
	encoder_heads: 3
	encoder_layers: 3
	learning_rate: 0.001
	max_steps: 1149
	net_layers: 3
	net_size: 55
	noise_std: 0.26521907914099485
2022-07-12 02:01:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=115 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.9577909734316296 --embedding_layers=2 --embedding_size=10 --encoder_heads=3 --encoder_layers=3 --learning_rate=0.001 --max_steps=1149 --net_layers=3 --net_size=55 --noise_std=0.26521907914099485
2022-07-12 02:01:47 INFO Running runs: ['vljrdw3y']
2022-07-12 02:04:15 INFO Cleaning up finished run: vljrdw3y
2022-07-12 02:04:15 INFO Agent received command: run
2022-07-12 02:04:15 INFO Agent starting run with config:
	batch_size: 128
	d_model: 99
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.15941512026155658
	embedding_layers: 4
	embedding_size: 109
	encoder_heads: 3
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 3132
	net_layers: 4
	net_size: 126
	noise_std: 1.1141175433477344
2022-07-12 02:04:15 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=99 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.15941512026155658 --embedding_layers=4 --embedding_size=109 --encoder_heads=3 --encoder_layers=6 --learning_rate=0.0001 --max_steps=3132 --net_layers=4 --net_size=126 --noise_std=1.1141175433477344
2022-07-12 02:04:20 INFO Running runs: ['te1uz72y']
2022-07-12 02:10:26 INFO Cleaning up finished run: te1uz72y
2022-07-12 02:10:26 INFO Agent received command: run
2022-07-12 02:10:26 INFO Agent starting run with config:
	batch_size: 64
	d_model: 125
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.4005098610963034
	embedding_layers: 4
	embedding_size: 73
	encoder_heads: 3
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 2873
	net_layers: 3
	net_size: 93
	noise_std: 1.0600732968248026
2022-07-12 02:10:26 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=125 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.4005098610963034 --embedding_layers=4 --embedding_size=73 --encoder_heads=3 --encoder_layers=7 --learning_rate=0.0001 --max_steps=2873 --net_layers=3 --net_size=93 --noise_std=1.0600732968248026
2022-07-12 02:10:31 INFO Running runs: ['foktjh3z']
2022-07-12 02:16:31 INFO Cleaning up finished run: foktjh3z
2022-07-12 02:16:32 INFO Agent received command: run
2022-07-12 02:16:32 INFO Agent starting run with config:
	batch_size: 64
	d_model: 77
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.27193424040024994
	embedding_layers: 4
	embedding_size: 86
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 3578
	net_layers: 3
	net_size: 121
	noise_std: 0.907176481219851
2022-07-12 02:16:32 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=77 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.27193424040024994 --embedding_layers=4 --embedding_size=86 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.0001 --max_steps=3578 --net_layers=3 --net_size=121 --noise_std=0.907176481219851
2022-07-12 02:16:37 INFO Running runs: ['3t0gommi']
2022-07-12 02:21:42 INFO Cleaning up finished run: 3t0gommi
2022-07-12 02:21:47 INFO Agent received command: run
2022-07-12 02:21:47 INFO Agent starting run with config:
	batch_size: 64
	d_model: 14
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.10654518078859077
	embedding_layers: 3
	embedding_size: 110
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 2150
	net_layers: 2
	net_size: 111
	noise_std: 1.1440075023007574
2022-07-12 02:21:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=14 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.10654518078859077 --embedding_layers=3 --embedding_size=110 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001 --max_steps=2150 --net_layers=2 --net_size=111 --noise_std=1.1440075023007574
2022-07-12 02:21:52 INFO Running runs: ['ppx6jpsy']
2022-07-12 02:25:02 INFO Cleaning up finished run: ppx6jpsy
2022-07-12 02:25:03 INFO Agent received command: run
2022-07-12 02:25:03 INFO Agent starting run with config:
	batch_size: 128
	d_model: 115
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.021707934336015366
	embedding_layers: 4
	embedding_size: 92
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 3511
	net_layers: 4
	net_size: 60
	noise_std: 1.45433557770689
2022-07-12 02:25:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=115 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.021707934336015366 --embedding_layers=4 --embedding_size=92 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0001 --max_steps=3511 --net_layers=4 --net_size=60 --noise_std=1.45433557770689
2022-07-12 02:25:08 INFO Running runs: ['0lww5brn']
2022-07-12 02:29:52 INFO Cleaning up finished run: 0lww5brn
2022-07-12 02:29:52 INFO Agent received command: run
2022-07-12 02:29:52 INFO Agent starting run with config:
	batch_size: 64
	d_model: 96
	decoder_heads: 2
	decoder_layers: 7
	early_stopping: 0.5358171383370895
	embedding_layers: 3
	embedding_size: 122
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 3348
	net_layers: 4
	net_size: 124
	noise_std: 0.9425567702452136
2022-07-12 02:29:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=96 --decoder_heads=2 --decoder_layers=7 --early_stopping=0.5358171383370895 --embedding_layers=3 --embedding_size=122 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.0001 --max_steps=3348 --net_layers=4 --net_size=124 --noise_std=0.9425567702452136
2022-07-12 02:29:57 INFO Running runs: ['hif3cc7u']
2022-07-12 02:36:14 INFO Cleaning up finished run: hif3cc7u
2022-07-12 02:36:15 INFO Agent received command: run
2022-07-12 02:36:15 INFO Agent starting run with config:
	batch_size: 128
	d_model: 72
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.5548954169766133
	embedding_layers: 2
	embedding_size: 105
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 3040
	net_layers: 4
	net_size: 120
	noise_std: 1.191413860737134
2022-07-12 02:36:15 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=72 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.5548954169766133 --embedding_layers=2 --embedding_size=105 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.0001 --max_steps=3040 --net_layers=4 --net_size=120 --noise_std=1.191413860737134
2022-07-12 02:36:20 INFO Running runs: ['fl790yol']
2022-07-12 02:41:52 INFO Cleaning up finished run: fl790yol
2022-07-12 02:41:53 INFO Agent received command: run
2022-07-12 02:41:53 INFO Agent starting run with config:
	batch_size: 128
	d_model: 111
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.5665390817921724
	embedding_layers: 3
	embedding_size: 114
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 4271
	net_layers: 4
	net_size: 91
	noise_std: 0.6398475121874245
2022-07-12 02:41:53 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=111 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.5665390817921724 --embedding_layers=3 --embedding_size=114 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.0001 --max_steps=4271 --net_layers=4 --net_size=91 --noise_std=0.6398475121874245
2022-07-12 02:41:58 INFO Running runs: ['ydnnq1pd']
2022-07-12 02:50:21 INFO Cleaning up finished run: ydnnq1pd
2022-07-12 02:50:22 INFO Agent received command: run
2022-07-12 02:50:22 INFO Agent starting run with config:
	batch_size: 128
	d_model: 64
	decoder_heads: 5
	decoder_layers: 8
	early_stopping: 0.5085536741459744
	embedding_layers: 4
	embedding_size: 106
	encoder_heads: 3
	encoder_layers: 4
	learning_rate: 0.0005
	max_steps: 3450
	net_layers: 4
	net_size: 118
	noise_std: 0.28028670380148246
2022-07-12 02:50:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=64 --decoder_heads=5 --decoder_layers=8 --early_stopping=0.5085536741459744 --embedding_layers=4 --embedding_size=106 --encoder_heads=3 --encoder_layers=4 --learning_rate=0.0005 --max_steps=3450 --net_layers=4 --net_size=118 --noise_std=0.28028670380148246
2022-07-12 02:50:27 INFO Running runs: ['fd9pyhvj']
2022-07-12 02:56:16 INFO Cleaning up finished run: fd9pyhvj
2022-07-12 02:56:17 INFO Agent received command: run
2022-07-12 02:56:17 INFO Agent starting run with config:
	batch_size: 128
	d_model: 72
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 0.47628305765332024
	embedding_layers: 3
	embedding_size: 125
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 3149
	net_layers: 3
	net_size: 122
	noise_std: 0.7980103131593008
2022-07-12 02:56:17 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=72 --decoder_heads=3 --decoder_layers=8 --early_stopping=0.47628305765332024 --embedding_layers=3 --embedding_size=125 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.001 --max_steps=3149 --net_layers=3 --net_size=122 --noise_std=0.7980103131593008
2022-07-12 02:56:22 INFO Running runs: ['k1wirzjm']
2022-07-12 03:00:48 INFO Cleaning up finished run: k1wirzjm
2022-07-12 03:00:49 INFO Agent received command: run
2022-07-12 03:00:49 INFO Agent starting run with config:
	batch_size: 128
	d_model: 89
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.21011343312945008
	embedding_layers: 3
	embedding_size: 111
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 2816
	net_layers: 4
	net_size: 93
	noise_std: 0.11557614825170535
2022-07-12 03:00:49 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=89 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.21011343312945008 --embedding_layers=3 --embedding_size=111 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.0001 --max_steps=2816 --net_layers=4 --net_size=93 --noise_std=0.11557614825170535
2022-07-12 03:00:54 INFO Running runs: ['z2b0xqba']
2022-07-12 03:06:05 INFO Cleaning up finished run: z2b0xqba
2022-07-12 03:06:05 INFO Agent received command: run
2022-07-12 03:06:05 INFO Agent starting run with config:
	batch_size: 32
	d_model: 110
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.6072293619038834
	embedding_layers: 3
	embedding_size: 124
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 4902
	net_layers: 3
	net_size: 102
	noise_std: 0.098621442575526
2022-07-12 03:06:05 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=110 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.6072293619038834 --embedding_layers=3 --embedding_size=124 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.0001 --max_steps=4902 --net_layers=3 --net_size=102 --noise_std=0.098621442575526
2022-07-12 03:06:10 INFO Running runs: ['g648gmon']
2022-07-12 03:14:43 INFO Cleaning up finished run: g648gmon
2022-07-12 03:14:44 INFO Agent received command: run
2022-07-12 03:14:44 INFO Agent starting run with config:
	batch_size: 8
	d_model: 112
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.08071611033670434
	embedding_layers: 4
	embedding_size: 121
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 4418
	net_layers: 3
	net_size: 111
	noise_std: 1.4488926780976603
2022-07-12 03:14:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=112 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.08071611033670434 --embedding_layers=4 --embedding_size=121 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.0001 --max_steps=4418 --net_layers=3 --net_size=111 --noise_std=1.4488926780976603
2022-07-12 03:14:49 INFO Running runs: ['1xk3llpx']
2022-07-12 03:19:53 INFO Cleaning up finished run: 1xk3llpx
2022-07-12 03:19:54 INFO Agent received command: run
2022-07-12 03:19:54 INFO Agent starting run with config:
	batch_size: 16
	d_model: 124
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.7530927113303959
	embedding_layers: 4
	embedding_size: 120
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 2731
	net_layers: 4
	net_size: 116
	noise_std: 0.24393670549013033
2022-07-12 03:19:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=124 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.7530927113303959 --embedding_layers=4 --embedding_size=120 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.0001 --max_steps=2731 --net_layers=4 --net_size=116 --noise_std=0.24393670549013033
2022-07-12 03:19:59 INFO Running runs: ['lsfrv795']
2022-07-12 03:25:28 INFO Cleaning up finished run: lsfrv795
2022-07-12 03:25:29 INFO Agent received command: run
2022-07-12 03:25:29 INFO Agent starting run with config:
	batch_size: 128
	d_model: 96
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.7309492076249956
	embedding_layers: 2
	embedding_size: 62
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.0005
	max_steps: 3658
	net_layers: 4
	net_size: 125
	noise_std: 0.1496092613118561
2022-07-12 03:25:29 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=96 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.7309492076249956 --embedding_layers=2 --embedding_size=62 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.0005 --max_steps=3658 --net_layers=4 --net_size=125 --noise_std=0.1496092613118561
2022-07-12 03:25:34 INFO Running runs: ['3nknwiuc']
2022-07-12 03:32:13 INFO Cleaning up finished run: 3nknwiuc
2022-07-12 03:32:13 INFO Agent received command: run
2022-07-12 03:32:13 INFO Agent starting run with config:
	batch_size: 32
	d_model: 69
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.5894282644884884
	embedding_layers: 4
	embedding_size: 115
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 1528
	net_layers: 4
	net_size: 71
	noise_std: 1.16075268840205
2022-07-12 03:32:13 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=69 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.5894282644884884 --embedding_layers=4 --embedding_size=115 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0001 --max_steps=1528 --net_layers=4 --net_size=71 --noise_std=1.16075268840205
2022-07-12 03:32:18 INFO Running runs: ['gqeaasic']
2022-07-12 03:35:40 INFO Cleaning up finished run: gqeaasic
2022-07-12 03:35:41 INFO Agent received command: run
2022-07-12 03:35:41 INFO Agent starting run with config:
	batch_size: 64
	d_model: 104
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.2607699920741592
	embedding_layers: 3
	embedding_size: 123
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 2700
	net_layers: 4
	net_size: 76
	noise_std: 1.203742137351971
2022-07-12 03:35:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=104 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.2607699920741592 --embedding_layers=3 --embedding_size=123 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.0001 --max_steps=2700 --net_layers=4 --net_size=76 --noise_std=1.203742137351971
2022-07-12 03:35:46 INFO Running runs: ['sm0sfxd9']
2022-07-12 03:40:02 INFO Cleaning up finished run: sm0sfxd9
2022-07-12 03:40:03 INFO Agent received command: run
2022-07-12 03:40:03 INFO Agent starting run with config:
	batch_size: 4
	d_model: 115
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.8665338845586303
	embedding_layers: 4
	embedding_size: 115
	encoder_heads: 5
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 1697
	net_layers: 2
	net_size: 128
	noise_std: 0.6612818807752506
2022-07-12 03:40:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=115 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.8665338845586303 --embedding_layers=4 --embedding_size=115 --encoder_heads=5 --encoder_layers=2 --learning_rate=0.0001 --max_steps=1697 --net_layers=2 --net_size=128 --noise_std=0.6612818807752506
2022-07-12 03:40:08 INFO Running runs: ['c2y1rfjp']
2022-07-12 03:44:06 INFO Cleaning up finished run: c2y1rfjp
2022-07-12 03:44:07 INFO Agent received command: run
2022-07-12 03:44:07 INFO Agent starting run with config:
	batch_size: 128
	d_model: 98
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.2632234669494069
	embedding_layers: 4
	embedding_size: 109
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 1801
	net_layers: 4
	net_size: 95
	noise_std: 0.40347698800273246
2022-07-12 03:44:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=98 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.2632234669494069 --embedding_layers=4 --embedding_size=109 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.0001 --max_steps=1801 --net_layers=4 --net_size=95 --noise_std=0.40347698800273246
2022-07-12 03:44:12 INFO Running runs: ['8w0jl9u3']
2022-07-12 03:47:17 INFO Cleaning up finished run: 8w0jl9u3
2022-07-12 03:47:18 INFO Agent received command: run
2022-07-12 03:47:18 INFO Agent starting run with config:
	batch_size: 64
	d_model: 120
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.5518067265723948
	embedding_layers: 4
	embedding_size: 111
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 2546
	net_layers: 4
	net_size: 84
	noise_std: 0.6004221539992649
2022-07-12 03:47:18 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=120 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.5518067265723948 --embedding_layers=4 --embedding_size=111 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001 --max_steps=2546 --net_layers=4 --net_size=84 --noise_std=0.6004221539992649
2022-07-12 03:47:23 INFO Running runs: ['41rdjh4t']
2022-07-12 03:52:08 INFO Cleaning up finished run: 41rdjh4t
2022-07-12 03:52:09 INFO Agent received command: run
2022-07-12 03:52:09 INFO Agent starting run with config:
	batch_size: 128
	d_model: 71
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.3887066795252519
	embedding_layers: 1
	embedding_size: 126
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 2059
	net_layers: 3
	net_size: 57
	noise_std: 0.6698358018659967
2022-07-12 03:52:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=71 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.3887066795252519 --embedding_layers=1 --embedding_size=126 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.0001 --max_steps=2059 --net_layers=3 --net_size=57 --noise_std=0.6698358018659967
2022-07-12 03:52:14 INFO Running runs: ['05xh093b']
2022-07-12 03:55:18 INFO Cleaning up finished run: 05xh093b
2022-07-12 03:55:19 INFO Agent received command: run
2022-07-12 03:55:19 INFO Agent starting run with config:
	batch_size: 128
	d_model: 127
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.7244994811230243
	embedding_layers: 4
	embedding_size: 109
	encoder_heads: 5
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 1266
	net_layers: 3
	net_size: 102
	noise_std: 0.22265544371777057
2022-07-12 03:55:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=127 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.7244994811230243 --embedding_layers=4 --embedding_size=109 --encoder_heads=5 --encoder_layers=2 --learning_rate=0.0001 --max_steps=1266 --net_layers=3 --net_size=102 --noise_std=0.22265544371777057
2022-07-12 03:55:24 INFO Running runs: ['b4fwzi5j']
2022-07-12 03:58:34 INFO Cleaning up finished run: b4fwzi5j
2022-07-12 03:58:35 INFO Agent received command: run
2022-07-12 03:58:35 INFO Agent starting run with config:
	batch_size: 128
	d_model: 77
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.6421445489263597
	embedding_layers: 3
	embedding_size: 122
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 1788
	net_layers: 2
	net_size: 111
	noise_std: 0.269157165978616
2022-07-12 03:58:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=77 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.6421445489263597 --embedding_layers=3 --embedding_size=122 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.0001 --max_steps=1788 --net_layers=2 --net_size=111 --noise_std=0.269157165978616
2022-07-12 03:58:40 INFO Running runs: ['b4vu07f8']
2022-07-12 04:02:45 INFO Cleaning up finished run: b4vu07f8
2022-07-12 04:02:53 INFO Running runs: []
2022-07-12 04:02:54 INFO Agent received command: run
2022-07-12 04:02:54 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9177522071304992
	max_bin: 251
	max_depth: 21
	min_data_in_leaf: 14
	num_iterations: 288
	num_leaves: 30
2022-07-12 04:02:54 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9177522071304992 --max_bin=251 --max_depth=21 --min_data_in_leaf=14 --num_iterations=288 --num_leaves=30
2022-07-12 04:02:59 INFO Running runs: ['vhsylnzk']
2022-07-12 04:03:15 INFO Cleaning up finished run: vhsylnzk
2022-07-12 04:03:16 INFO Agent received command: run
2022-07-12 04:03:16 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2070492115104764
	max_bin: 208
	max_depth: 21
	min_data_in_leaf: 13
	num_iterations: 838
	num_leaves: 5
2022-07-12 04:03:16 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2070492115104764 --max_bin=208 --max_depth=21 --min_data_in_leaf=13 --num_iterations=838 --num_leaves=5
2022-07-12 04:03:21 INFO Running runs: ['b17ywvq5']
2022-07-12 04:03:37 INFO Cleaning up finished run: b17ywvq5
2022-07-12 04:03:37 INFO Agent received command: run
2022-07-12 04:03:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8557455062097392
	max_bin: 202
	max_depth: 9
	min_data_in_leaf: 22
	num_iterations: 274
	num_leaves: 20
2022-07-12 04:03:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8557455062097392 --max_bin=202 --max_depth=9 --min_data_in_leaf=22 --num_iterations=274 --num_leaves=20
2022-07-12 04:03:42 INFO Running runs: ['aqdmwm4y']
2022-07-12 04:03:58 INFO Cleaning up finished run: aqdmwm4y
2022-07-12 04:03:59 INFO Agent received command: run
2022-07-12 04:03:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.24132097628016047
	max_bin: 203
	max_depth: 18
	min_data_in_leaf: 12
	num_iterations: 911
	num_leaves: 7
2022-07-12 04:03:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.24132097628016047 --max_bin=203 --max_depth=18 --min_data_in_leaf=12 --num_iterations=911 --num_leaves=7
2022-07-12 04:04:04 INFO Running runs: ['jmk3gr6a']
2022-07-12 04:04:20 INFO Cleaning up finished run: jmk3gr6a
2022-07-12 04:04:21 INFO Agent received command: run
2022-07-12 04:04:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04137181056243499
	max_bin: 105
	max_depth: 20
	min_data_in_leaf: 23
	num_iterations: 986
	num_leaves: 5
2022-07-12 04:04:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04137181056243499 --max_bin=105 --max_depth=20 --min_data_in_leaf=23 --num_iterations=986 --num_leaves=5
2022-07-12 04:04:26 INFO Running runs: ['bxsexku6']
2022-07-12 04:04:42 INFO Cleaning up finished run: bxsexku6
2022-07-12 04:04:43 INFO Agent received command: run
2022-07-12 04:04:43 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.12618489315057935
	max_bin: 110
	max_depth: 11
	min_data_in_leaf: 11
	num_iterations: 982
	num_leaves: 8
2022-07-12 04:04:43 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.12618489315057935 --max_bin=110 --max_depth=11 --min_data_in_leaf=11 --num_iterations=982 --num_leaves=8
2022-07-12 04:04:48 INFO Running runs: ['vqf4cusr']
2022-07-12 04:05:04 INFO Cleaning up finished run: vqf4cusr
2022-07-12 04:05:05 INFO Agent received command: run
2022-07-12 04:05:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08223041836084932
	max_bin: 255
	max_depth: 15
	min_data_in_leaf: 17
	num_iterations: 821
	num_leaves: 5
2022-07-12 04:05:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08223041836084932 --max_bin=255 --max_depth=15 --min_data_in_leaf=17 --num_iterations=821 --num_leaves=5
2022-07-12 04:05:10 INFO Running runs: ['ej5fvxay']
2022-07-12 04:05:26 INFO Cleaning up finished run: ej5fvxay
2022-07-12 04:05:26 INFO Agent received command: run
2022-07-12 04:05:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.26280681304462605
	max_bin: 255
	max_depth: 20
	min_data_in_leaf: 28
	num_iterations: 961
	num_leaves: 5
2022-07-12 04:05:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.26280681304462605 --max_bin=255 --max_depth=20 --min_data_in_leaf=28 --num_iterations=961 --num_leaves=5
2022-07-12 04:05:31 INFO Running runs: ['q4cmpxdo']
2022-07-12 04:05:48 INFO Cleaning up finished run: q4cmpxdo
2022-07-12 04:05:49 INFO Agent received command: run
2022-07-12 04:05:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2254424167683592
	max_bin: 223
	max_depth: 9
	min_data_in_leaf: 23
	num_iterations: 994
	num_leaves: 12
2022-07-12 04:05:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2254424167683592 --max_bin=223 --max_depth=9 --min_data_in_leaf=23 --num_iterations=994 --num_leaves=12
2022-07-12 04:05:54 INFO Running runs: ['yzqps3pv']
2022-07-12 04:06:10 INFO Cleaning up finished run: yzqps3pv
2022-07-12 04:06:12 INFO Agent received command: run
2022-07-12 04:06:12 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2559490702492464
	max_bin: 207
	max_depth: 31
	min_data_in_leaf: 24
	num_iterations: 968
	num_leaves: 14
2022-07-12 04:06:12 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2559490702492464 --max_bin=207 --max_depth=31 --min_data_in_leaf=24 --num_iterations=968 --num_leaves=14
2022-07-12 04:06:17 INFO Running runs: ['cuyecvy4']
2022-07-12 04:06:33 INFO Cleaning up finished run: cuyecvy4
2022-07-12 04:06:34 INFO Agent received command: run
2022-07-12 04:06:34 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08512271173176766
	max_bin: 213
	max_depth: 18
	min_data_in_leaf: 29
	num_iterations: 584
	num_leaves: 6
2022-07-12 04:06:34 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08512271173176766 --max_bin=213 --max_depth=18 --min_data_in_leaf=29 --num_iterations=584 --num_leaves=6
2022-07-12 04:06:39 INFO Running runs: ['docc65u7']
2022-07-12 04:06:56 INFO Cleaning up finished run: docc65u7
2022-07-12 04:06:57 INFO Agent received command: run
2022-07-12 04:06:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.008376902474949266
	max_bin: 17
	max_depth: 19
	min_data_in_leaf: 14
	num_iterations: 224
	num_leaves: 5
2022-07-12 04:06:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.008376902474949266 --max_bin=17 --max_depth=19 --min_data_in_leaf=14 --num_iterations=224 --num_leaves=5
2022-07-12 04:07:02 INFO Running runs: ['2wro27kx']
2022-07-12 04:07:18 INFO Cleaning up finished run: 2wro27kx
2022-07-12 04:07:18 INFO Agent received command: run
2022-07-12 04:07:18 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0011787269428018554
	max_bin: 189
	max_depth: 15
	min_data_in_leaf: 11
	num_iterations: 545
	num_leaves: 9
2022-07-12 04:07:18 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0011787269428018554 --max_bin=189 --max_depth=15 --min_data_in_leaf=11 --num_iterations=545 --num_leaves=9
2022-07-12 04:07:23 INFO Running runs: ['kxts3s8o']
2022-07-12 04:07:45 INFO Cleaning up finished run: kxts3s8o
2022-07-12 04:07:47 INFO Agent received command: run
2022-07-12 04:07:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5061843057868751
	max_bin: 37
	max_depth: 19
	min_data_in_leaf: 12
	num_iterations: 997
	num_leaves: 5
2022-07-12 04:07:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.5061843057868751 --max_bin=37 --max_depth=19 --min_data_in_leaf=12 --num_iterations=997 --num_leaves=5
2022-07-12 04:07:52 INFO Running runs: ['7ywpsws4']
2022-07-12 04:08:08 INFO Cleaning up finished run: 7ywpsws4
2022-07-12 04:08:09 INFO Agent received command: run
2022-07-12 04:08:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3495696281401077
	max_bin: 189
	max_depth: 14
	min_data_in_leaf: 16
	num_iterations: 943
	num_leaves: 6
2022-07-12 04:08:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3495696281401077 --max_bin=189 --max_depth=14 --min_data_in_leaf=16 --num_iterations=943 --num_leaves=6
2022-07-12 04:08:14 INFO Running runs: ['ucgccuiw']
2022-07-12 04:08:30 INFO Cleaning up finished run: ucgccuiw
2022-07-12 04:08:31 INFO Agent received command: run
2022-07-12 04:08:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.23505495948094035
	max_bin: 27
	max_depth: 15
	min_data_in_leaf: 30
	num_iterations: 528
	num_leaves: 8
2022-07-12 04:08:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.23505495948094035 --max_bin=27 --max_depth=15 --min_data_in_leaf=30 --num_iterations=528 --num_leaves=8
2022-07-12 04:08:36 INFO Running runs: ['q6xhgwtn']
2022-07-12 04:08:53 INFO Cleaning up finished run: q6xhgwtn
2022-07-12 04:08:54 INFO Agent received command: run
2022-07-12 04:08:54 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.31106478649447455
	max_bin: 19
	max_depth: 28
	min_data_in_leaf: 23
	num_iterations: 168
	num_leaves: 5
2022-07-12 04:08:54 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.31106478649447455 --max_bin=19 --max_depth=28 --min_data_in_leaf=23 --num_iterations=168 --num_leaves=5
2022-07-12 04:08:59 INFO Running runs: ['244gm495']
2022-07-12 04:09:15 INFO Cleaning up finished run: 244gm495
2022-07-12 04:09:16 INFO Agent received command: run
2022-07-12 04:09:16 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.1087320540902057
	max_bin: 52
	max_depth: 32
	min_data_in_leaf: 29
	num_iterations: 318
	num_leaves: 6
2022-07-12 04:09:16 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.1087320540902057 --max_bin=52 --max_depth=32 --min_data_in_leaf=29 --num_iterations=318 --num_leaves=6
2022-07-12 04:09:21 INFO Running runs: ['xp79o420']
2022-07-12 04:09:37 INFO Cleaning up finished run: xp79o420
2022-07-12 04:09:39 INFO Agent received command: run
2022-07-12 04:09:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.022830430215246555
	max_bin: 10
	max_depth: 30
	min_data_in_leaf: 25
	num_iterations: 157
	num_leaves: 20
2022-07-12 04:09:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.022830430215246555 --max_bin=10 --max_depth=30 --min_data_in_leaf=25 --num_iterations=157 --num_leaves=20
2022-07-12 04:09:44 INFO Running runs: ['o9qz4awu']
2022-07-12 04:10:00 INFO Cleaning up finished run: o9qz4awu
2022-07-12 04:10:01 INFO Agent received command: run
2022-07-12 04:10:01 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6935161895994528
	max_bin: 14
	max_depth: 23
	min_data_in_leaf: 28
	num_iterations: 142
	num_leaves: 6
2022-07-12 04:10:01 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6935161895994528 --max_bin=14 --max_depth=23 --min_data_in_leaf=28 --num_iterations=142 --num_leaves=6
2022-07-12 04:10:06 INFO Running runs: ['u0x1pp3s']
2022-07-12 04:10:22 INFO Cleaning up finished run: u0x1pp3s
2022-07-12 04:10:23 INFO Agent received command: run
2022-07-12 04:10:23 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04877414154237447
	max_bin: 6
	max_depth: 24
	min_data_in_leaf: 28
	num_iterations: 786
	num_leaves: 7
2022-07-12 04:10:23 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04877414154237447 --max_bin=6 --max_depth=24 --min_data_in_leaf=28 --num_iterations=786 --num_leaves=7
2022-07-12 04:10:28 INFO Running runs: ['lj80kht7']
2022-07-12 04:10:44 INFO Cleaning up finished run: lj80kht7
2022-07-12 04:10:44 INFO Agent received command: run
2022-07-12 04:10:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.32332876836863356
	max_bin: 47
	max_depth: 26
	min_data_in_leaf: 23
	num_iterations: 267
	num_leaves: 7
2022-07-12 04:10:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.32332876836863356 --max_bin=47 --max_depth=26 --min_data_in_leaf=23 --num_iterations=267 --num_leaves=7
2022-07-12 04:10:49 INFO Running runs: ['00udblk0']
2022-07-12 04:11:05 INFO Cleaning up finished run: 00udblk0
2022-07-12 04:11:06 INFO Agent received command: run
2022-07-12 04:11:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.18236530721211688
	max_bin: 60
	max_depth: 29
	min_data_in_leaf: 27
	num_iterations: 136
	num_leaves: 5
2022-07-12 04:11:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.18236530721211688 --max_bin=60 --max_depth=29 --min_data_in_leaf=27 --num_iterations=136 --num_leaves=5
2022-07-12 04:11:11 INFO Running runs: ['018s57we']
2022-07-12 04:11:27 INFO Cleaning up finished run: 018s57we
2022-07-12 04:11:28 INFO Agent received command: run
2022-07-12 04:11:28 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2516743267245869
	max_bin: 185
	max_depth: 18
	min_data_in_leaf: 24
	num_iterations: 960
	num_leaves: 5
2022-07-12 04:11:28 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2516743267245869 --max_bin=185 --max_depth=18 --min_data_in_leaf=24 --num_iterations=960 --num_leaves=5
2022-07-12 04:11:33 INFO Running runs: ['pnpchzpr']
2022-07-12 04:11:49 INFO Cleaning up finished run: pnpchzpr
2022-07-12 04:11:50 INFO Agent received command: run
2022-07-12 04:11:50 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.15834471530872196
	max_bin: 44
	max_depth: 6
	min_data_in_leaf: 28
	num_iterations: 459
	num_leaves: 15
2022-07-12 04:11:50 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.15834471530872196 --max_bin=44 --max_depth=6 --min_data_in_leaf=28 --num_iterations=459 --num_leaves=15
2022-07-12 04:11:55 INFO Running runs: ['423ir5s5']
2022-07-12 04:12:11 INFO Cleaning up finished run: 423ir5s5
2022-07-12 04:12:12 INFO Agent received command: run
2022-07-12 04:12:12 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.36030879758299694
	max_bin: 28
	max_depth: 31
	min_data_in_leaf: 21
	num_iterations: 170
	num_leaves: 9
2022-07-12 04:12:12 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.36030879758299694 --max_bin=28 --max_depth=31 --min_data_in_leaf=21 --num_iterations=170 --num_leaves=9
2022-07-12 04:12:17 INFO Running runs: ['pbbhoqyn']
2022-07-12 04:12:33 INFO Cleaning up finished run: pbbhoqyn
2022-07-12 04:12:34 INFO Agent received command: run
2022-07-12 04:12:34 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.19943575616076592
	max_bin: 30
	max_depth: 14
	min_data_in_leaf: 30
	num_iterations: 243
	num_leaves: 6
2022-07-12 04:12:34 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.19943575616076592 --max_bin=30 --max_depth=14 --min_data_in_leaf=30 --num_iterations=243 --num_leaves=6
2022-07-12 04:12:39 INFO Running runs: ['0qtnstgo']
2022-07-12 04:12:55 INFO Cleaning up finished run: 0qtnstgo
2022-07-12 04:12:56 INFO Agent received command: run
2022-07-12 04:12:56 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06373903379490198
	max_bin: 17
	max_depth: 28
	min_data_in_leaf: 30
	num_iterations: 170
	num_leaves: 6
2022-07-12 04:12:56 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06373903379490198 --max_bin=17 --max_depth=28 --min_data_in_leaf=30 --num_iterations=170 --num_leaves=6
2022-07-12 04:13:01 INFO Running runs: ['rdj1xife']
2022-07-12 04:13:17 INFO Cleaning up finished run: rdj1xife
2022-07-12 04:13:18 INFO Agent received command: run
2022-07-12 04:13:18 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.20393803859845008
	max_bin: 254
	max_depth: 22
	min_data_in_leaf: 17
	num_iterations: 877
	num_leaves: 11
2022-07-12 04:13:18 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.20393803859845008 --max_bin=254 --max_depth=22 --min_data_in_leaf=17 --num_iterations=877 --num_leaves=11
2022-07-12 04:13:23 INFO Running runs: ['kdl7l69e']
2022-07-12 04:13:39 INFO Cleaning up finished run: kdl7l69e
2022-07-12 04:13:40 INFO Agent received command: run
2022-07-12 04:13:40 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.1290777080246398
	max_bin: 219
	max_depth: 23
	min_data_in_leaf: 18
	num_iterations: 982
	num_leaves: 13
2022-07-12 04:13:40 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.1290777080246398 --max_bin=219 --max_depth=23 --min_data_in_leaf=18 --num_iterations=982 --num_leaves=13
2022-07-12 04:13:45 INFO Running runs: ['vooozh7f']
2022-07-12 04:14:01 INFO Cleaning up finished run: vooozh7f
2022-07-12 04:14:09 INFO Running runs: []
2022-07-12 04:14:09 INFO Agent received command: run
2022-07-12 04:14:09 INFO Agent starting run with config:
	batch_size: 4
	d_model: 72
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.9037716291213448
	embedding_layers: 2
	embedding_size: 42
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 1563
	net_layers: 1
	net_size: 10
	noise_std: 1.275563388034982
2022-07-12 04:14:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=72 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.9037716291213448 --embedding_layers=2 --embedding_size=42 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.001 --max_steps=1563 --net_layers=1 --net_size=10 --noise_std=1.275563388034982
2022-07-12 04:14:14 INFO Running runs: ['n9cmv4g0']
2022-07-12 04:17:24 INFO Cleaning up finished run: n9cmv4g0
2022-07-12 04:17:25 INFO Agent received command: run
2022-07-12 04:17:25 INFO Agent starting run with config:
	batch_size: 32
	d_model: 106
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.7763057770585204
	embedding_layers: 1
	embedding_size: 74
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 3235
	net_layers: 1
	net_size: 51
	noise_std: 1.3048811524456545
2022-07-12 04:17:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=106 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.7763057770585204 --embedding_layers=1 --embedding_size=74 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0005 --max_steps=3235 --net_layers=1 --net_size=51 --noise_std=1.3048811524456545
2022-07-12 04:17:30 INFO Running runs: ['o03fj9oc']
2022-07-12 04:23:48 INFO Cleaning up finished run: o03fj9oc
2022-07-12 04:23:48 INFO Agent received command: run
2022-07-12 04:23:48 INFO Agent starting run with config:
	batch_size: 64
	d_model: 54
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.8116331198914578
	embedding_layers: 2
	embedding_size: 104
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 1405
	net_layers: 4
	net_size: 117
	noise_std: 0.5367531010378377
2022-07-12 04:23:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=54 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.8116331198914578 --embedding_layers=2 --embedding_size=104 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001 --max_steps=1405 --net_layers=4 --net_size=117 --noise_std=0.5367531010378377
2022-07-12 04:23:53 INFO Running runs: ['moont45m']
2022-07-12 04:27:26 INFO Cleaning up finished run: moont45m
2022-07-12 04:27:27 INFO Agent received command: run
2022-07-12 04:27:27 INFO Agent starting run with config:
	batch_size: 128
	d_model: 14
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.9771565257640452
	embedding_layers: 3
	embedding_size: 69
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 1052
	net_layers: 3
	net_size: 127
	noise_std: 0.4762922771837405
2022-07-12 04:27:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=14 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.9771565257640452 --embedding_layers=3 --embedding_size=69 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001 --max_steps=1052 --net_layers=3 --net_size=127 --noise_std=0.4762922771837405
2022-07-12 04:27:32 INFO Running runs: ['yzbaticm']
2022-07-12 04:30:42 INFO Cleaning up finished run: yzbaticm
2022-07-12 04:30:43 INFO Agent received command: run
2022-07-12 04:30:43 INFO Agent starting run with config:
	batch_size: 32
	d_model: 44
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.4905848899444385
	embedding_layers: 1
	embedding_size: 96
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.001
	max_steps: 2030
	net_layers: 4
	net_size: 113
	noise_std: 1.3123490219713698
2022-07-12 04:30:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=44 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.4905848899444385 --embedding_layers=1 --embedding_size=96 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.001 --max_steps=2030 --net_layers=4 --net_size=113 --noise_std=1.3123490219713698
2022-07-12 04:30:48 INFO Running runs: ['hn397gl1']
2022-07-12 04:34:31 INFO Cleaning up finished run: hn397gl1
2022-07-12 04:34:32 INFO Agent received command: run
2022-07-12 04:34:32 INFO Agent starting run with config:
	batch_size: 64
	d_model: 33
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.10569162338883752
	embedding_layers: 2
	embedding_size: 84
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 4347
	net_layers: 3
	net_size: 60
	noise_std: 0.16144966046578757
2022-07-12 04:34:32 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=33 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.10569162338883752 --embedding_layers=2 --embedding_size=84 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=4347 --net_layers=3 --net_size=60 --noise_std=0.16144966046578757
2022-07-12 04:34:37 INFO Running runs: ['nu1v0grl']
2022-07-12 04:41:33 INFO Cleaning up finished run: nu1v0grl
2022-07-12 04:41:34 INFO Agent received command: run
2022-07-12 04:41:34 INFO Agent starting run with config:
	batch_size: 8
	d_model: 59
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.23514212829787728
	embedding_layers: 3
	embedding_size: 78
	encoder_heads: 3
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 4173
	net_layers: 4
	net_size: 111
	noise_std: 0.464799682602782
2022-07-12 04:41:34 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=59 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.23514212829787728 --embedding_layers=3 --embedding_size=78 --encoder_heads=3 --encoder_layers=7 --learning_rate=0.0001 --max_steps=4173 --net_layers=4 --net_size=111 --noise_std=0.464799682602782
2022-07-12 04:41:39 INFO Running runs: ['ejjh3b33']
2022-07-12 04:47:35 INFO Cleaning up finished run: ejjh3b33
2022-07-12 04:47:36 INFO Agent received command: run
2022-07-12 04:47:36 INFO Agent starting run with config:
	batch_size: 128
	d_model: 108
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.844424507215543
	embedding_layers: 1
	embedding_size: 34
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.001
	max_steps: 3583
	net_layers: 3
	net_size: 121
	noise_std: 0.9225007022674164
2022-07-12 04:47:36 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=108 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.844424507215543 --embedding_layers=1 --embedding_size=34 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.001 --max_steps=3583 --net_layers=3 --net_size=121 --noise_std=0.9225007022674164
2022-07-12 04:47:41 INFO Running runs: ['2tviglre']
2022-07-12 04:58:07 INFO Cleaning up finished run: 2tviglre
2022-07-12 04:58:08 INFO Agent received command: run
2022-07-12 04:58:08 INFO Agent starting run with config:
	batch_size: 32
	d_model: 34
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.16860784923855354
	embedding_layers: 2
	embedding_size: 61
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.001
	max_steps: 1833
	net_layers: 4
	net_size: 78
	noise_std: 0.7725112039387257
2022-07-12 04:58:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=34 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.16860784923855354 --embedding_layers=2 --embedding_size=61 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.001 --max_steps=1833 --net_layers=4 --net_size=78 --noise_std=0.7725112039387257
2022-07-12 04:58:13 INFO Running runs: ['h3ivsyha']
2022-07-12 05:01:55 INFO Cleaning up finished run: h3ivsyha
2022-07-12 05:01:56 INFO Agent received command: run
2022-07-12 05:01:56 INFO Agent starting run with config:
	batch_size: 8
	d_model: 92
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.8379503878839267
	embedding_layers: 1
	embedding_size: 72
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.0005
	max_steps: 1000
	net_layers: 4
	net_size: 34
	noise_std: 0.391716685990858
2022-07-12 05:01:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=92 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.8379503878839267 --embedding_layers=1 --embedding_size=72 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.0005 --max_steps=1000 --net_layers=4 --net_size=34 --noise_std=0.391716685990858
2022-07-12 05:02:01 INFO Running runs: ['29m56qjy']
2022-07-12 05:04:57 INFO Cleaning up finished run: 29m56qjy
2022-07-12 05:04:58 INFO Agent received command: run
2022-07-12 05:04:58 INFO Agent starting run with config:
	batch_size: 64
	d_model: 53
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.8381493866151656
	embedding_layers: 2
	embedding_size: 48
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.001
	max_steps: 4673
	net_layers: 2
	net_size: 18
	noise_std: 0.5426782684344179
2022-07-12 05:04:58 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=53 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.8381493866151656 --embedding_layers=2 --embedding_size=48 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.001 --max_steps=4673 --net_layers=2 --net_size=18 --noise_std=0.5426782684344179
2022-07-12 05:05:03 INFO Running runs: ['76lo50os']
2022-07-12 05:15:08 INFO Cleaning up finished run: 76lo50os
2022-07-12 05:15:09 INFO Agent received command: run
2022-07-12 05:15:09 INFO Agent starting run with config:
	batch_size: 8
	d_model: 26
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.7328507117987922
	embedding_layers: 3
	embedding_size: 63
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 1319
	net_layers: 4
	net_size: 19
	noise_std: 1.1391423308304338
2022-07-12 05:15:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=26 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.7328507117987922 --embedding_layers=3 --embedding_size=63 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001 --max_steps=1319 --net_layers=4 --net_size=19 --noise_std=1.1391423308304338
2022-07-12 05:15:14 INFO Running runs: ['j5dv6r2z']
2022-07-12 05:18:09 INFO Cleaning up finished run: j5dv6r2z
2022-07-12 05:18:11 INFO Agent received command: run
2022-07-12 05:18:11 INFO Agent starting run with config:
	batch_size: 64
	d_model: 23
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.08689873283733118
	embedding_layers: 3
	embedding_size: 59
	encoder_heads: 1
	encoder_layers: 7
	learning_rate: 0.0005
	max_steps: 4723
	net_layers: 2
	net_size: 111
	noise_std: 0.05544797547989976
2022-07-12 05:18:11 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=23 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.08689873283733118 --embedding_layers=3 --embedding_size=59 --encoder_heads=1 --encoder_layers=7 --learning_rate=0.0005 --max_steps=4723 --net_layers=2 --net_size=111 --noise_std=0.05544797547989976
2022-07-12 05:18:16 INFO Running runs: ['60idlavs']
2022-07-12 05:26:40 INFO Cleaning up finished run: 60idlavs
2022-07-12 05:26:41 INFO Agent received command: run
2022-07-12 05:26:41 INFO Agent starting run with config:
	batch_size: 64
	d_model: 7
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.07976030792640121
	embedding_layers: 2
	embedding_size: 84
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 3177
	net_layers: 2
	net_size: 115
	noise_std: 0.35033482022536994
2022-07-12 05:26:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=7 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.07976030792640121 --embedding_layers=2 --embedding_size=84 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0001 --max_steps=3177 --net_layers=2 --net_size=115 --noise_std=0.35033482022536994
2022-07-12 05:26:46 INFO Running runs: ['hf8gaket']
2022-07-12 05:31:07 INFO Cleaning up finished run: hf8gaket
2022-07-12 05:31:08 INFO Agent received command: run
2022-07-12 05:31:08 INFO Agent starting run with config:
	batch_size: 128
	d_model: 102
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.15396062079537576
	embedding_layers: 3
	embedding_size: 125
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 3500
	net_layers: 4
	net_size: 125
	noise_std: 0.47670638004872223
2022-07-12 05:31:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=102 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.15396062079537576 --embedding_layers=3 --embedding_size=125 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=3500 --net_layers=4 --net_size=125 --noise_std=0.47670638004872223
2022-07-12 05:31:13 INFO Running runs: ['nt2dswnb']
2022-07-12 05:43:58 INFO Cleaning up finished run: nt2dswnb
2022-07-12 05:43:59 INFO Agent received command: run
2022-07-12 05:43:59 INFO Agent starting run with config:
	batch_size: 128
	d_model: 56
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.10136359579282704
	embedding_layers: 1
	embedding_size: 101
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 2091
	net_layers: 4
	net_size: 120
	noise_std: 0.026592878570407687
2022-07-12 05:43:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=56 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.10136359579282704 --embedding_layers=1 --embedding_size=101 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.0005 --max_steps=2091 --net_layers=4 --net_size=120 --noise_std=0.026592878570407687
2022-07-12 05:44:04 INFO Running runs: ['7s9euqlx']
2022-07-12 05:51:09 INFO Cleaning up finished run: 7s9euqlx
2022-07-12 05:51:09 INFO Agent received command: run
2022-07-12 05:51:09 INFO Agent starting run with config:
	batch_size: 64
	d_model: 67
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 0.23155019640830363
	embedding_layers: 2
	embedding_size: 116
	encoder_heads: 2
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 3365
	net_layers: 4
	net_size: 128
	noise_std: 0.907122287556938
2022-07-12 05:51:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=67 --decoder_heads=3 --decoder_layers=8 --early_stopping=0.23155019640830363 --embedding_layers=2 --embedding_size=116 --encoder_heads=2 --encoder_layers=7 --learning_rate=0.0001 --max_steps=3365 --net_layers=4 --net_size=128 --noise_std=0.907122287556938
2022-07-12 05:51:14 INFO Running runs: ['9c3a1rdv']
2022-07-12 06:00:40 INFO Cleaning up finished run: 9c3a1rdv
2022-07-12 06:00:41 INFO Agent received command: run
2022-07-12 06:00:41 INFO Agent starting run with config:
	batch_size: 32
	d_model: 12
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.06773821913094713
	embedding_layers: 3
	embedding_size: 89
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 3989
	net_layers: 4
	net_size: 69
	noise_std: 0.03488531362475689
2022-07-12 06:00:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=12 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.06773821913094713 --embedding_layers=3 --embedding_size=89 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.0001 --max_steps=3989 --net_layers=4 --net_size=69 --noise_std=0.03488531362475689
2022-07-12 06:00:46 INFO Running runs: ['ul0s2jjn']
2022-07-12 06:07:30 INFO Cleaning up finished run: ul0s2jjn
2022-07-12 06:07:31 INFO Agent received command: run
2022-07-12 06:07:31 INFO Agent starting run with config:
	batch_size: 16
	d_model: 46
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.08677673125022534
	embedding_layers: 2
	embedding_size: 111
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 1464
	net_layers: 3
	net_size: 89
	noise_std: 0.1973631120591523
2022-07-12 06:07:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=46 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.08677673125022534 --embedding_layers=2 --embedding_size=111 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.0005 --max_steps=1464 --net_layers=3 --net_size=89 --noise_std=0.1973631120591523
2022-07-12 06:07:36 INFO Running runs: ['2bzytsow']
2022-07-12 06:10:03 INFO Cleaning up finished run: 2bzytsow
2022-07-12 06:10:04 INFO Agent received command: run
2022-07-12 06:10:04 INFO Agent starting run with config:
	batch_size: 128
	d_model: 21
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.010956457921821428
	embedding_layers: 3
	embedding_size: 17
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 3436
	net_layers: 4
	net_size: 123
	noise_std: 0.2492862273738869
2022-07-12 06:10:04 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=21 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.010956457921821428 --embedding_layers=3 --embedding_size=17 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0001 --max_steps=3436 --net_layers=4 --net_size=123 --noise_std=0.2492862273738869
2022-07-12 06:10:09 INFO Running runs: ['u43tgm5s']
2022-07-12 06:13:35 INFO Cleaning up finished run: u43tgm5s
2022-07-12 06:13:35 INFO Agent received command: run
2022-07-12 06:13:35 INFO Agent starting run with config:
	batch_size: 128
	d_model: 102
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.386288449361846
	embedding_layers: 3
	embedding_size: 123
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 4613
	net_layers: 3
	net_size: 85
	noise_std: 0.3221517238725393
2022-07-12 06:13:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=102 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.386288449361846 --embedding_layers=3 --embedding_size=123 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.0001 --max_steps=4613 --net_layers=3 --net_size=85 --noise_std=0.3221517238725393
2022-07-12 06:13:40 INFO Running runs: ['g6531n5q']
2022-07-12 06:26:34 INFO Cleaning up finished run: g6531n5q
2022-07-12 06:26:35 INFO Agent received command: run
2022-07-12 06:26:35 INFO Agent starting run with config:
	batch_size: 128
	d_model: 112
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.3530888965176888
	embedding_layers: 4
	embedding_size: 127
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.001
	max_steps: 4544
	net_layers: 3
	net_size: 88
	noise_std: 0.3334238822495636
2022-07-12 06:26:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=112 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.3530888965176888 --embedding_layers=4 --embedding_size=127 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.001 --max_steps=4544 --net_layers=3 --net_size=88 --noise_std=0.3334238822495636
2022-07-12 06:26:40 INFO Running runs: ['ry5pgceq']
2022-07-12 06:41:57 INFO Cleaning up finished run: ry5pgceq
2022-07-12 06:41:58 INFO Agent received command: run
2022-07-12 06:41:58 INFO Agent starting run with config:
	batch_size: 32
	d_model: 114
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.09005759202196728
	embedding_layers: 3
	embedding_size: 122
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 4237
	net_layers: 1
	net_size: 113
	noise_std: 0.15504070220057775
2022-07-12 06:41:58 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=114 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.09005759202196728 --embedding_layers=3 --embedding_size=122 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=4237 --net_layers=1 --net_size=113 --noise_std=0.15504070220057775
2022-07-12 06:42:03 INFO Running runs: ['bzjpexyl']
2022-07-12 06:52:08 INFO Cleaning up finished run: bzjpexyl
2022-07-12 06:52:09 INFO Agent received command: run
2022-07-12 06:52:09 INFO Agent starting run with config:
	batch_size: 64
	d_model: 101
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 9.098421489961428e-05
	embedding_layers: 1
	embedding_size: 119
	encoder_heads: 3
	encoder_layers: 6
	learning_rate: 0.0005
	max_steps: 4939
	net_layers: 2
	net_size: 125
	noise_std: 0.23302770449796284
2022-07-12 06:52:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=101 --decoder_heads=3 --decoder_layers=8 --early_stopping=9.098421489961428e-05 --embedding_layers=1 --embedding_size=119 --encoder_heads=3 --encoder_layers=6 --learning_rate=0.0005 --max_steps=4939 --net_layers=2 --net_size=125 --noise_std=0.23302770449796284
2022-07-12 06:52:14 INFO Running runs: ['9ae33mck']
2022-07-12 07:05:42 INFO Cleaning up finished run: 9ae33mck
2022-07-12 07:05:43 INFO Agent received command: run
2022-07-12 07:05:43 INFO Agent starting run with config:
	batch_size: 128
	d_model: 50
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.5153284024760673
	embedding_layers: 2
	embedding_size: 119
	encoder_heads: 1
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 4647
	net_layers: 3
	net_size: 94
	noise_std: 0.2934398368466551
2022-07-12 07:05:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=50 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.5153284024760673 --embedding_layers=2 --embedding_size=119 --encoder_heads=1 --encoder_layers=7 --learning_rate=0.0001 --max_steps=4647 --net_layers=3 --net_size=94 --noise_std=0.2934398368466551
2022-07-12 07:05:48 INFO Running runs: ['zi2luo2q']
2022-07-12 07:16:39 INFO Cleaning up finished run: zi2luo2q
2022-07-12 07:16:40 INFO Agent received command: run
2022-07-12 07:16:40 INFO Agent starting run with config:
	batch_size: 128
	d_model: 34
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.04024228175669531
	embedding_layers: 3
	embedding_size: 118
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 4179
	net_layers: 4
	net_size: 83
	noise_std: 0.47089960376195256
2022-07-12 07:16:40 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=34 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.04024228175669531 --embedding_layers=3 --embedding_size=118 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.0001 --max_steps=4179 --net_layers=4 --net_size=83 --noise_std=0.47089960376195256
2022-07-12 07:16:45 INFO Running runs: ['nmjcdobi']
2022-07-12 07:25:19 INFO Cleaning up finished run: nmjcdobi
2022-07-12 07:25:19 INFO Agent received command: run
2022-07-12 07:25:19 INFO Agent starting run with config:
	batch_size: 128
	d_model: 118
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.16414983646521275
	embedding_layers: 1
	embedding_size: 77
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 2833
	net_layers: 4
	net_size: 81
	noise_std: 0.2338050764952342
2022-07-12 07:25:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=118 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.16414983646521275 --embedding_layers=1 --embedding_size=77 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.0001 --max_steps=2833 --net_layers=4 --net_size=81 --noise_std=0.2338050764952342
2022-07-12 07:25:24 INFO Running runs: ['bnxq8vhq']
2022-07-12 07:34:19 INFO Cleaning up finished run: bnxq8vhq
2022-07-12 07:34:20 INFO Agent received command: run
2022-07-12 07:34:20 INFO Agent starting run with config:
	batch_size: 128
	d_model: 8
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.18650659100252096
	embedding_layers: 1
	embedding_size: 125
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 2951
	net_layers: 4
	net_size: 119
	noise_std: 0.3964357033195999
2022-07-12 07:34:20 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=8 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.18650659100252096 --embedding_layers=1 --embedding_size=125 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0001 --max_steps=2951 --net_layers=4 --net_size=119 --noise_std=0.3964357033195999
2022-07-12 07:34:25 INFO Running runs: ['bbc5huk6']
2022-07-12 07:38:31 INFO Cleaning up finished run: bbc5huk6
2022-07-12 07:38:32 INFO Agent received command: run
2022-07-12 07:38:32 INFO Agent starting run with config:
	batch_size: 32
	d_model: 128
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.3847513646599112
	embedding_layers: 3
	embedding_size: 121
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 4470
	net_layers: 3
	net_size: 118
	noise_std: 0.5611356299937117
2022-07-12 07:38:32 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=128 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.3847513646599112 --embedding_layers=3 --embedding_size=121 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=4470 --net_layers=3 --net_size=118 --noise_std=0.5611356299937117
2022-07-12 07:38:37 INFO Running runs: ['mr0r7zk2']
2022-07-12 07:51:06 INFO Cleaning up finished run: mr0r7zk2
2022-07-12 07:51:06 INFO Agent received command: run
2022-07-12 07:51:06 INFO Agent starting run with config:
	batch_size: 128
	d_model: 102
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.23381150635593584
	embedding_layers: 3
	embedding_size: 126
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 4658
	net_layers: 1
	net_size: 93
	noise_std: 0.2072094054435922
2022-07-12 07:51:06 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=102 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.23381150635593584 --embedding_layers=3 --embedding_size=126 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0005 --max_steps=4658 --net_layers=1 --net_size=93 --noise_std=0.2072094054435922
2022-07-12 07:51:11 INFO Running runs: ['pwykvgqx']
2022-07-12 08:01:11 INFO Cleaning up finished run: pwykvgqx
2022-07-12 08:01:19 INFO Running runs: []
2022-07-12 08:01:19 INFO Agent received command: run
2022-07-12 08:01:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.935412082080296
	max_bin: 111
	max_depth: 5
	min_data_in_leaf: 25
	num_iterations: 118
	num_leaves: 11
2022-07-12 08:01:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.935412082080296 --max_bin=111 --max_depth=5 --min_data_in_leaf=25 --num_iterations=118 --num_leaves=11
2022-07-12 08:01:24 INFO Running runs: ['bs5oqqg1']
2022-07-12 08:01:40 INFO Cleaning up finished run: bs5oqqg1
2022-07-12 08:01:41 INFO Agent received command: run
2022-07-12 08:01:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.15411080815318567
	max_bin: 190
	max_depth: 22
	min_data_in_leaf: 18
	num_iterations: 314
	num_leaves: 10
2022-07-12 08:01:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.15411080815318567 --max_bin=190 --max_depth=22 --min_data_in_leaf=18 --num_iterations=314 --num_leaves=10
2022-07-12 08:01:46 INFO Running runs: ['osg873n6']
2022-07-12 08:02:02 INFO Cleaning up finished run: osg873n6
2022-07-12 08:02:03 INFO Agent received command: run
2022-07-12 08:02:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3520580122474568
	max_bin: 98
	max_depth: 20
	min_data_in_leaf: 10
	num_iterations: 399
	num_leaves: 18
2022-07-12 08:02:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3520580122474568 --max_bin=98 --max_depth=20 --min_data_in_leaf=10 --num_iterations=399 --num_leaves=18
2022-07-12 08:02:08 INFO Running runs: ['enf70fy5']
2022-07-12 08:02:24 INFO Cleaning up finished run: enf70fy5
2022-07-12 08:02:24 INFO Agent received command: run
2022-07-12 08:02:24 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.1582006340643326
	max_bin: 194
	max_depth: 21
	min_data_in_leaf: 14
	num_iterations: 324
	num_leaves: 9
2022-07-12 08:02:24 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.1582006340643326 --max_bin=194 --max_depth=21 --min_data_in_leaf=14 --num_iterations=324 --num_leaves=9
2022-07-12 08:02:29 INFO Running runs: ['bzr5mesa']
2022-07-12 08:02:45 INFO Cleaning up finished run: bzr5mesa
2022-07-12 08:02:46 INFO Agent received command: run
2022-07-12 08:02:46 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.008380627530153228
	max_bin: 252
	max_depth: 24
	min_data_in_leaf: 16
	num_iterations: 438
	num_leaves: 13
2022-07-12 08:02:46 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.008380627530153228 --max_bin=252 --max_depth=24 --min_data_in_leaf=16 --num_iterations=438 --num_leaves=13
2022-07-12 08:02:51 INFO Running runs: ['o0rhgz3s']
2022-07-12 08:03:18 INFO Cleaning up finished run: o0rhgz3s
2022-07-12 08:03:19 INFO Agent received command: run
2022-07-12 08:03:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06894945132631336
	max_bin: 193
	max_depth: 24
	min_data_in_leaf: 13
	num_iterations: 111
	num_leaves: 8
2022-07-12 08:03:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06894945132631336 --max_bin=193 --max_depth=24 --min_data_in_leaf=13 --num_iterations=111 --num_leaves=8
2022-07-12 08:03:24 INFO Running runs: ['51itb697']
2022-07-12 08:03:40 INFO Cleaning up finished run: 51itb697
2022-07-12 08:03:41 INFO Agent received command: run
2022-07-12 08:03:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.14673620765757422
	max_bin: 180
	max_depth: 17
	min_data_in_leaf: 16
	num_iterations: 461
	num_leaves: 5
2022-07-12 08:03:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.14673620765757422 --max_bin=180 --max_depth=17 --min_data_in_leaf=16 --num_iterations=461 --num_leaves=5
2022-07-12 08:03:46 INFO Running runs: ['azr7hx2o']
2022-07-12 08:04:02 INFO Cleaning up finished run: azr7hx2o
2022-07-12 08:04:03 INFO Agent received command: run
2022-07-12 08:04:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.32876458817578336
	max_bin: 194
	max_depth: 17
	min_data_in_leaf: 18
	num_iterations: 350
	num_leaves: 9
2022-07-12 08:04:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.32876458817578336 --max_bin=194 --max_depth=17 --min_data_in_leaf=18 --num_iterations=350 --num_leaves=9
2022-07-12 08:04:08 INFO Running runs: ['djpodi1n']
2022-07-12 08:04:24 INFO Cleaning up finished run: djpodi1n
2022-07-12 08:04:25 INFO Agent received command: run
2022-07-12 08:04:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4280013387287801
	max_bin: 243
	max_depth: 26
	min_data_in_leaf: 15
	num_iterations: 316
	num_leaves: 7
2022-07-12 08:04:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4280013387287801 --max_bin=243 --max_depth=26 --min_data_in_leaf=15 --num_iterations=316 --num_leaves=7
2022-07-12 08:04:30 INFO Running runs: ['f4xz6xcs']
2022-07-12 08:04:46 INFO Cleaning up finished run: f4xz6xcs
2022-07-12 08:04:47 INFO Agent received command: run
2022-07-12 08:04:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4482095282433394
	max_bin: 190
	max_depth: 27
	min_data_in_leaf: 12
	num_iterations: 359
	num_leaves: 6
2022-07-12 08:04:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4482095282433394 --max_bin=190 --max_depth=27 --min_data_in_leaf=12 --num_iterations=359 --num_leaves=6
2022-07-12 08:04:52 INFO Running runs: ['vwizs78g']
2022-07-12 08:05:08 INFO Cleaning up finished run: vwizs78g
2022-07-12 08:05:09 INFO Agent received command: run
2022-07-12 08:05:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3058324981133522
	max_bin: 206
	max_depth: 20
	min_data_in_leaf: 17
	num_iterations: 214
	num_leaves: 5
2022-07-12 08:05:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3058324981133522 --max_bin=206 --max_depth=20 --min_data_in_leaf=17 --num_iterations=214 --num_leaves=5
2022-07-12 08:05:14 INFO Running runs: ['t98u9qoc']
2022-07-12 08:05:31 INFO Cleaning up finished run: t98u9qoc
2022-07-12 08:05:31 INFO Agent received command: run
2022-07-12 08:05:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9230654230559646
	max_bin: 245
	max_depth: 32
	min_data_in_leaf: 23
	num_iterations: 495
	num_leaves: 8
2022-07-12 08:05:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9230654230559646 --max_bin=245 --max_depth=32 --min_data_in_leaf=23 --num_iterations=495 --num_leaves=8
2022-07-12 08:05:36 INFO Running runs: ['xo0dyggx']
2022-07-12 08:05:52 INFO Cleaning up finished run: xo0dyggx
2022-07-12 08:05:53 INFO Agent received command: run
2022-07-12 08:05:53 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3245166813582573
	max_bin: 234
	max_depth: 12
	min_data_in_leaf: 11
	num_iterations: 113
	num_leaves: 6
2022-07-12 08:05:53 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3245166813582573 --max_bin=234 --max_depth=12 --min_data_in_leaf=11 --num_iterations=113 --num_leaves=6
2022-07-12 08:05:58 INFO Running runs: ['1qmueswf']
2022-07-12 08:06:14 INFO Cleaning up finished run: 1qmueswf
2022-07-12 08:06:15 INFO Agent received command: run
2022-07-12 08:06:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.008961312175371772
	max_bin: 244
	max_depth: 4
	min_data_in_leaf: 14
	num_iterations: 201
	num_leaves: 36
2022-07-12 08:06:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.008961312175371772 --max_bin=244 --max_depth=4 --min_data_in_leaf=14 --num_iterations=201 --num_leaves=36
2022-07-12 08:06:20 INFO Running runs: ['f631qsw7']
2022-07-12 08:06:41 INFO Cleaning up finished run: f631qsw7
2022-07-12 08:06:42 INFO Agent received command: run
2022-07-12 08:06:42 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4607796850931316
	max_bin: 213
	max_depth: 20
	min_data_in_leaf: 10
	num_iterations: 142
	num_leaves: 11
2022-07-12 08:06:42 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4607796850931316 --max_bin=213 --max_depth=20 --min_data_in_leaf=10 --num_iterations=142 --num_leaves=11
2022-07-12 08:06:47 INFO Running runs: ['t26rezb2']
2022-07-12 08:07:03 INFO Cleaning up finished run: t26rezb2
2022-07-12 08:07:04 INFO Agent received command: run
2022-07-12 08:07:04 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.12344592665717158
	max_bin: 23
	max_depth: 6
	min_data_in_leaf: 10
	num_iterations: 956
	num_leaves: 13
2022-07-12 08:07:04 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.12344592665717158 --max_bin=23 --max_depth=6 --min_data_in_leaf=10 --num_iterations=956 --num_leaves=13
2022-07-12 08:07:09 INFO Running runs: ['5q5q7ma2']
2022-07-12 08:07:25 INFO Cleaning up finished run: 5q5q7ma2
2022-07-12 08:07:25 INFO Agent received command: run
2022-07-12 08:07:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3427765766772294
	max_bin: 125
	max_depth: 7
	min_data_in_leaf: 10
	num_iterations: 838
	num_leaves: 7
2022-07-12 08:07:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3427765766772294 --max_bin=125 --max_depth=7 --min_data_in_leaf=10 --num_iterations=838 --num_leaves=7
2022-07-12 08:07:30 INFO Running runs: ['8k6w6kmd']
2022-07-12 08:07:47 INFO Cleaning up finished run: 8k6w6kmd
2022-07-12 08:07:47 INFO Agent received command: run
2022-07-12 08:07:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05501369748808138
	max_bin: 32
	max_depth: 21
	min_data_in_leaf: 10
	num_iterations: 737
	num_leaves: 5
2022-07-12 08:07:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05501369748808138 --max_bin=32 --max_depth=21 --min_data_in_leaf=10 --num_iterations=737 --num_leaves=5
2022-07-12 08:07:52 INFO Running runs: ['kuahkepb']
2022-07-12 08:08:14 INFO Cleaning up finished run: kuahkepb
2022-07-12 08:08:15 INFO Agent received command: run
2022-07-12 08:08:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.15629552355126786
	max_bin: 44
	max_depth: 10
	min_data_in_leaf: 11
	num_iterations: 628
	num_leaves: 5
2022-07-12 08:08:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.15629552355126786 --max_bin=44 --max_depth=10 --min_data_in_leaf=11 --num_iterations=628 --num_leaves=5
2022-07-12 08:08:20 INFO Running runs: ['4n0pjzha']
2022-07-12 08:08:36 INFO Cleaning up finished run: 4n0pjzha
2022-07-12 08:08:37 INFO Agent received command: run
2022-07-12 08:08:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05405627302285121
	max_bin: 26
	max_depth: 20
	min_data_in_leaf: 19
	num_iterations: 644
	num_leaves: 5
2022-07-12 08:08:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05405627302285121 --max_bin=26 --max_depth=20 --min_data_in_leaf=19 --num_iterations=644 --num_leaves=5
2022-07-12 08:08:42 INFO Running runs: ['xl32viou']
2022-07-12 08:08:58 INFO Cleaning up finished run: xl32viou
2022-07-12 08:08:59 INFO Agent received command: run
2022-07-12 08:08:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05669953848057918
	max_bin: 17
	max_depth: 18
	min_data_in_leaf: 12
	num_iterations: 456
	num_leaves: 8
2022-07-12 08:08:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05669953848057918 --max_bin=17 --max_depth=18 --min_data_in_leaf=12 --num_iterations=456 --num_leaves=8
2022-07-12 08:09:04 INFO Running runs: ['47o9h9sz']
2022-07-12 08:09:25 INFO Cleaning up finished run: 47o9h9sz
2022-07-12 08:09:26 INFO Agent received command: run
2022-07-12 08:09:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.004281682016915145
	max_bin: 17
	max_depth: 7
	min_data_in_leaf: 21
	num_iterations: 338
	num_leaves: 6
2022-07-12 08:09:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.004281682016915145 --max_bin=17 --max_depth=7 --min_data_in_leaf=21 --num_iterations=338 --num_leaves=6
2022-07-12 08:09:31 INFO Running runs: ['0uog0d3c']
2022-07-12 08:09:47 INFO Cleaning up finished run: 0uog0d3c
2022-07-12 08:09:48 INFO Agent received command: run
2022-07-12 08:09:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.014375020388800563
	max_bin: 11
	max_depth: 29
	min_data_in_leaf: 16
	num_iterations: 437
	num_leaves: 8
2022-07-12 08:09:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.014375020388800563 --max_bin=11 --max_depth=29 --min_data_in_leaf=16 --num_iterations=437 --num_leaves=8
2022-07-12 08:09:53 INFO Running runs: ['4wlwwz4p']
2022-07-12 08:10:15 INFO Cleaning up finished run: 4wlwwz4p
2022-07-12 08:10:16 INFO Agent received command: run
2022-07-12 08:10:16 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4657885844464667
	max_bin: 9
	max_depth: 13
	min_data_in_leaf: 11
	num_iterations: 909
	num_leaves: 6
2022-07-12 08:10:16 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4657885844464667 --max_bin=9 --max_depth=13 --min_data_in_leaf=11 --num_iterations=909 --num_leaves=6
2022-07-12 08:10:21 INFO Running runs: ['scomesi7']
2022-07-12 08:10:37 INFO Cleaning up finished run: scomesi7
2022-07-12 08:10:38 INFO Agent received command: run
2022-07-12 08:10:38 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.004367383737713171
	max_bin: 16
	max_depth: 22
	min_data_in_leaf: 18
	num_iterations: 939
	num_leaves: 10
2022-07-12 08:10:38 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.004367383737713171 --max_bin=16 --max_depth=22 --min_data_in_leaf=18 --num_iterations=939 --num_leaves=10
2022-07-12 08:10:43 INFO Running runs: ['bat6f1ew']
2022-07-12 08:11:10 INFO Cleaning up finished run: bat6f1ew
2022-07-12 08:11:12 INFO Agent received command: run
2022-07-12 08:11:12 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.23648274657849055
	max_bin: 11
	max_depth: 28
	min_data_in_leaf: 14
	num_iterations: 581
	num_leaves: 7
2022-07-12 08:11:12 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.23648274657849055 --max_bin=11 --max_depth=28 --min_data_in_leaf=14 --num_iterations=581 --num_leaves=7
2022-07-12 08:11:17 INFO Running runs: ['cxupxl8t']
2022-07-12 08:11:33 INFO Cleaning up finished run: cxupxl8t
2022-07-12 08:11:33 INFO Agent received command: run
2022-07-12 08:11:33 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2118619530528573
	max_bin: 58
	max_depth: 18
	min_data_in_leaf: 15
	num_iterations: 717
	num_leaves: 8
2022-07-12 08:11:33 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2118619530528573 --max_bin=58 --max_depth=18 --min_data_in_leaf=15 --num_iterations=717 --num_leaves=8
2022-07-12 08:11:38 INFO Running runs: ['0kakr5he']
2022-07-12 08:11:54 INFO Cleaning up finished run: 0kakr5he
2022-07-12 08:11:55 INFO Agent received command: run
2022-07-12 08:11:55 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0475893784047724
	max_bin: 40
	max_depth: 23
	min_data_in_leaf: 15
	num_iterations: 444
	num_leaves: 6
2022-07-12 08:11:55 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0475893784047724 --max_bin=40 --max_depth=23 --min_data_in_leaf=15 --num_iterations=444 --num_leaves=6
2022-07-12 08:12:00 INFO Running runs: ['ehu49lq6']
2022-07-12 08:12:22 INFO Cleaning up finished run: ehu49lq6
2022-07-12 08:12:22 INFO Agent received command: run
2022-07-12 08:12:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.007265925310556476
	max_bin: 21
	max_depth: 19
	min_data_in_leaf: 13
	num_iterations: 632
	num_leaves: 6
2022-07-12 08:12:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.007265925310556476 --max_bin=21 --max_depth=19 --min_data_in_leaf=13 --num_iterations=632 --num_leaves=6
2022-07-12 08:12:27 INFO Running runs: ['lzyudcl2']
2022-07-12 08:12:49 INFO Cleaning up finished run: lzyudcl2
2022-07-12 08:12:50 INFO Agent received command: run
2022-07-12 08:12:50 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.1463125724984241
	max_bin: 94
	max_depth: 31
	min_data_in_leaf: 17
	num_iterations: 658
	num_leaves: 5
2022-07-12 08:12:50 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.1463125724984241 --max_bin=94 --max_depth=31 --min_data_in_leaf=17 --num_iterations=658 --num_leaves=5
2022-07-12 08:12:55 INFO Running runs: ['9lxzp6dd']
2022-07-12 08:13:11 INFO Cleaning up finished run: 9lxzp6dd
2022-07-12 08:13:19 INFO Running runs: []
2022-07-12 08:13:19 INFO Agent received command: run
2022-07-12 08:13:19 INFO Agent starting run with config:
	batch_size: 8
	d_model: 78
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.95048729069191
	embedding_layers: 1
	embedding_size: 82
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 2686
	net_layers: 3
	net_size: 125
	noise_std: 0.6200332220108327
2022-07-12 08:13:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=78 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.95048729069191 --embedding_layers=1 --embedding_size=82 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=2686 --net_layers=3 --net_size=125 --noise_std=0.6200332220108327
2022-07-12 08:13:24 INFO Running runs: ['526in2zw']
2022-07-12 08:15:13 INFO Cleaning up finished run: 526in2zw
2022-07-12 08:15:14 INFO Agent received command: run
2022-07-12 08:15:14 INFO Agent starting run with config:
	batch_size: 16
	d_model: 29
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.581889229034672
	embedding_layers: 4
	embedding_size: 8
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 3912
	net_layers: 4
	net_size: 123
	noise_std: 0.3925037017869435
2022-07-12 08:15:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=29 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.581889229034672 --embedding_layers=4 --embedding_size=8 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.001 --max_steps=3912 --net_layers=4 --net_size=123 --noise_std=0.3925037017869435
2022-07-12 08:15:19 INFO Running runs: ['0utkekop']
2022-07-12 08:17:29 INFO Cleaning up finished run: 0utkekop
2022-07-12 08:17:30 INFO Agent received command: run
2022-07-12 08:17:30 INFO Agent starting run with config:
	batch_size: 8
	d_model: 100
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.05257044661161081
	embedding_layers: 3
	embedding_size: 71
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 3635
	net_layers: 2
	net_size: 8
	noise_std: 0.09459418360782632
2022-07-12 08:17:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=100 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.05257044661161081 --embedding_layers=3 --embedding_size=71 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.001 --max_steps=3635 --net_layers=2 --net_size=8 --noise_std=0.09459418360782632
2022-07-12 08:17:35 INFO Running runs: ['8etfdalr']
2022-07-12 08:18:51 INFO Cleaning up finished run: 8etfdalr
2022-07-12 08:18:52 INFO Agent received command: run
2022-07-12 08:18:52 INFO Agent starting run with config:
	batch_size: 128
	d_model: 115
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.7283034331480184
	embedding_layers: 4
	embedding_size: 121
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 1998
	net_layers: 4
	net_size: 64
	noise_std: 0.2650612305003419
2022-07-12 08:18:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=115 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.7283034331480184 --embedding_layers=4 --embedding_size=121 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.0001 --max_steps=1998 --net_layers=4 --net_size=64 --noise_std=0.2650612305003419
2022-07-12 08:18:57 INFO Running runs: ['irggovje']
2022-07-12 08:20:02 INFO Cleaning up finished run: irggovje
2022-07-12 08:20:02 INFO Agent received command: run
2022-07-12 08:20:02 INFO Agent starting run with config:
	batch_size: 32
	d_model: 85
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.31031947804714444
	embedding_layers: 3
	embedding_size: 94
	encoder_heads: 5
	encoder_layers: 7
	learning_rate: 0.0005
	max_steps: 4014
	net_layers: 1
	net_size: 99
	noise_std: 1.1131181668780767
2022-07-12 08:20:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=85 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.31031947804714444 --embedding_layers=3 --embedding_size=94 --encoder_heads=5 --encoder_layers=7 --learning_rate=0.0005 --max_steps=4014 --net_layers=1 --net_size=99 --noise_std=1.1131181668780767
2022-07-12 08:20:08 INFO Running runs: ['168uvnq7']
2022-07-12 08:21:40 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 08:21:40 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 08:21:48 INFO Running runs: []
2022-07-12 08:21:48 INFO Agent received command: run
2022-07-12 08:21:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6894058821999084
	max_bin: 144
	max_depth: 22
	min_data_in_leaf: 16
	num_iterations: 761
	num_leaves: 26
2022-07-12 08:21:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6894058821999084 --max_bin=144 --max_depth=22 --min_data_in_leaf=16 --num_iterations=761 --num_leaves=26
2022-07-12 08:21:53 INFO Running runs: ['qje93d7y']
2022-07-12 08:22:04 INFO Cleaning up finished run: qje93d7y
2022-07-12 08:22:05 INFO Agent received command: run
2022-07-12 08:22:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8524411654354029
	max_bin: 36
	max_depth: 13
	min_data_in_leaf: 18
	num_iterations: 778
	num_leaves: 17
2022-07-12 08:22:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8524411654354029 --max_bin=36 --max_depth=13 --min_data_in_leaf=18 --num_iterations=778 --num_leaves=17
2022-07-12 08:22:10 INFO Running runs: ['618gow8x']
2022-07-12 08:22:21 INFO Cleaning up finished run: 618gow8x
2022-07-12 08:22:21 INFO Agent received command: run
2022-07-12 08:22:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.042003382878337936
	max_bin: 253
	max_depth: 13
	min_data_in_leaf: 14
	num_iterations: 244
	num_leaves: 40
2022-07-12 08:22:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.042003382878337936 --max_bin=253 --max_depth=13 --min_data_in_leaf=14 --num_iterations=244 --num_leaves=40
2022-07-12 08:22:26 INFO Running runs: ['rv5hzh69']
2022-07-12 08:22:42 INFO Cleaning up finished run: rv5hzh69
2022-07-12 08:22:43 INFO Agent received command: run
2022-07-12 08:22:43 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9798635566731866
	max_bin: 11
	max_depth: 4
	min_data_in_leaf: 23
	num_iterations: 904
	num_leaves: 8
2022-07-12 08:22:43 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9798635566731866 --max_bin=11 --max_depth=4 --min_data_in_leaf=23 --num_iterations=904 --num_leaves=8
2022-07-12 08:22:48 INFO Running runs: ['t8oq2l4u']
2022-07-12 08:22:59 INFO Cleaning up finished run: t8oq2l4u
2022-07-12 08:22:59 INFO Agent received command: run
2022-07-12 08:22:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.12659419236263925
	max_bin: 149
	max_depth: 4
	min_data_in_leaf: 27
	num_iterations: 601
	num_leaves: 11
2022-07-12 08:22:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.12659419236263925 --max_bin=149 --max_depth=4 --min_data_in_leaf=27 --num_iterations=601 --num_leaves=11
2022-07-12 08:23:04 INFO Running runs: ['c3aypj6o']
2022-07-12 08:23:15 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 08:23:15 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 08:23:22 INFO Running runs: []
2022-07-12 08:23:23 INFO Agent received command: run
2022-07-12 08:23:23 INFO Agent starting run with config:
	batch_size: 64
	d_model: 60
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.9296799688922476
	embedding_layers: 1
	embedding_size: 121
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 3838
	net_layers: 1
	net_size: 41
	noise_std: 1.1951928565066532
2022-07-12 08:23:23 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=60 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.9296799688922476 --embedding_layers=1 --embedding_size=121 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0001 --max_steps=3838 --net_layers=1 --net_size=41 --noise_std=1.1951928565066532
2022-07-12 08:23:28 INFO Running runs: ['wz81fv4d']
2022-07-12 08:25:28 INFO Cleaning up finished run: wz81fv4d
2022-07-12 08:25:29 INFO Agent received command: run
2022-07-12 08:25:29 INFO Agent starting run with config:
	batch_size: 8
	d_model: 87
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.7149211095740489
	embedding_layers: 4
	embedding_size: 72
	encoder_heads: 2
	encoder_layers: 7
	learning_rate: 0.001
	max_steps: 1322
	net_layers: 2
	net_size: 24
	noise_std: 0.8789897122793294
2022-07-12 08:25:29 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=87 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.7149211095740489 --embedding_layers=4 --embedding_size=72 --encoder_heads=2 --encoder_layers=7 --learning_rate=0.001 --max_steps=1322 --net_layers=2 --net_size=24 --noise_std=0.8789897122793294
2022-07-12 08:25:34 INFO Running runs: ['57quls07']
2022-07-12 08:26:50 INFO Cleaning up finished run: 57quls07
2022-07-12 08:26:51 INFO Agent received command: run
2022-07-12 08:26:51 INFO Agent starting run with config:
	batch_size: 16
	d_model: 27
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.21583057848490217
	embedding_layers: 4
	embedding_size: 9
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 2442
	net_layers: 4
	net_size: 26
	noise_std: 0.4114369559287576
2022-07-12 08:26:51 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=27 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.21583057848490217 --embedding_layers=4 --embedding_size=9 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.001 --max_steps=2442 --net_layers=4 --net_size=26 --noise_std=0.4114369559287576
2022-07-12 08:26:56 INFO Running runs: ['14sn5s9f']
2022-07-12 08:27:55 INFO Cleaning up finished run: 14sn5s9f
2022-07-12 08:27:56 INFO Agent received command: run
2022-07-12 08:27:56 INFO Agent starting run with config:
	batch_size: 4
	d_model: 62
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.9976449604308576
	embedding_layers: 1
	embedding_size: 98
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 3235
	net_layers: 1
	net_size: 128
	noise_std: 0.752064338412373
2022-07-12 08:27:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=62 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.9976449604308576 --embedding_layers=1 --embedding_size=98 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=3235 --net_layers=1 --net_size=128 --noise_std=0.752064338412373
2022-07-12 08:28:01 INFO Running runs: ['zgtvqkmn']
2022-07-12 08:30:07 INFO Cleaning up finished run: zgtvqkmn
2022-07-12 08:30:07 INFO Agent received command: run
2022-07-12 08:30:07 INFO Agent starting run with config:
	batch_size: 64
	d_model: 6
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.028170546180312117
	embedding_layers: 2
	embedding_size: 125
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 4121
	net_layers: 1
	net_size: 89
	noise_std: 0.6112982458330818
2022-07-12 08:30:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=6 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.028170546180312117 --embedding_layers=2 --embedding_size=125 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.0001 --max_steps=4121 --net_layers=1 --net_size=89 --noise_std=0.6112982458330818
2022-07-12 08:30:12 INFO Running runs: ['2qhz6u07']
2022-07-12 08:32:07 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 08:32:07 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 08:32:14 INFO Running runs: []
2022-07-12 08:32:15 INFO Agent received command: run
2022-07-12 08:32:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3935701643993976
	max_bin: 40
	max_depth: 30
	min_data_in_leaf: 27
	num_iterations: 725
	num_leaves: 26
2022-07-12 08:32:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3935701643993976 --max_bin=40 --max_depth=30 --min_data_in_leaf=27 --num_iterations=725 --num_leaves=26
2022-07-12 08:32:20 INFO Running runs: ['jmh3s5z2']
2022-07-12 08:32:36 INFO Cleaning up finished run: jmh3s5z2
2022-07-12 08:32:37 INFO Agent received command: run
2022-07-12 08:32:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.419720852708127
	max_bin: 64
	max_depth: 25
	min_data_in_leaf: 12
	num_iterations: 456
	num_leaves: 31
2022-07-12 08:32:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.419720852708127 --max_bin=64 --max_depth=25 --min_data_in_leaf=12 --num_iterations=456 --num_leaves=31
2022-07-12 08:32:42 INFO Running runs: ['bpq6ore5']
2022-07-12 08:32:58 INFO Cleaning up finished run: bpq6ore5
2022-07-12 08:32:59 INFO Agent received command: run
2022-07-12 08:32:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3767283204070794
	max_bin: 229
	max_depth: 4
	min_data_in_leaf: 11
	num_iterations: 141
	num_leaves: 10
2022-07-12 08:32:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.3767283204070794 --max_bin=229 --max_depth=4 --min_data_in_leaf=11 --num_iterations=141 --num_leaves=10
2022-07-12 08:33:04 INFO Running runs: ['eodp9og4']
2022-07-12 08:33:14 INFO Cleaning up finished run: eodp9og4
2022-07-12 08:33:15 INFO Agent received command: run
2022-07-12 08:33:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.45385823211807585
	max_bin: 29
	max_depth: 31
	min_data_in_leaf: 17
	num_iterations: 336
	num_leaves: 37
2022-07-12 08:33:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.45385823211807585 --max_bin=29 --max_depth=31 --min_data_in_leaf=17 --num_iterations=336 --num_leaves=37
2022-07-12 08:33:20 INFO Running runs: ['lwmyth6y']
2022-07-12 08:33:36 INFO Cleaning up finished run: lwmyth6y
2022-07-12 08:33:37 INFO Agent received command: run
2022-07-12 08:33:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6831826083380279
	max_bin: 205
	max_depth: 32
	min_data_in_leaf: 20
	num_iterations: 943
	num_leaves: 18
2022-07-12 08:33:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6831826083380279 --max_bin=205 --max_depth=32 --min_data_in_leaf=20 --num_iterations=943 --num_leaves=18
2022-07-12 08:33:42 INFO Running runs: ['u8ad5om5']
2022-07-12 08:33:58 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 08:33:58 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 08:34:06 INFO Running runs: []
2022-07-12 08:34:06 INFO Agent received command: run
2022-07-12 08:34:06 INFO Agent starting run with config:
	batch_size: 16
	d_model: 43
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.9899897290924832
	embedding_layers: 4
	embedding_size: 36
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 1931
	net_layers: 2
	net_size: 22
	noise_std: 0.24617025097178577
2022-07-12 08:34:06 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=43 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.9899897290924832 --embedding_layers=4 --embedding_size=36 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.001 --max_steps=1931 --net_layers=2 --net_size=22 --noise_std=0.24617025097178577
2022-07-12 08:34:11 INFO Running runs: ['4jrdoadu']
2022-07-12 08:36:00 INFO Cleaning up finished run: 4jrdoadu
2022-07-12 08:36:01 INFO Agent received command: run
2022-07-12 08:36:01 INFO Agent starting run with config:
	batch_size: 128
	d_model: 78
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.7521936742686538
	embedding_layers: 2
	embedding_size: 23
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 1606
	net_layers: 2
	net_size: 102
	noise_std: 0.7191518277704511
2022-07-12 08:36:01 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=78 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.7521936742686538 --embedding_layers=2 --embedding_size=23 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.0005 --max_steps=1606 --net_layers=2 --net_size=102 --noise_std=0.7191518277704511
2022-07-12 08:36:06 INFO Running runs: ['7wrbdr5t']
2022-07-12 08:37:38 INFO Cleaning up finished run: 7wrbdr5t
2022-07-12 08:37:39 INFO Agent received command: run
2022-07-12 08:37:39 INFO Agent starting run with config:
	batch_size: 16
	d_model: 107
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.0403095393814602
	embedding_layers: 4
	embedding_size: 116
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 4681
	net_layers: 4
	net_size: 115
	noise_std: 1.2384043776055698
2022-07-12 08:37:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=107 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.0403095393814602 --embedding_layers=4 --embedding_size=116 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.001 --max_steps=4681 --net_layers=4 --net_size=115 --noise_std=1.2384043776055698
2022-07-12 08:37:44 INFO Running runs: ['hiduc9m5']
2022-07-12 08:39:32 INFO Cleaning up finished run: hiduc9m5
2022-07-12 08:39:33 INFO Agent received command: run
2022-07-12 08:39:33 INFO Agent starting run with config:
	batch_size: 32
	d_model: 71
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.02460147639557042
	embedding_layers: 1
	embedding_size: 125
	encoder_heads: 5
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 1651
	net_layers: 1
	net_size: 20
	noise_std: 0.6744647286580923
2022-07-12 08:39:33 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=71 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.02460147639557042 --embedding_layers=1 --embedding_size=125 --encoder_heads=5 --encoder_layers=6 --learning_rate=0.0001 --max_steps=1651 --net_layers=1 --net_size=20 --noise_std=0.6744647286580923
2022-07-12 08:39:38 INFO Running runs: ['slvokmmq']
2022-07-12 08:40:54 INFO Cleaning up finished run: slvokmmq
2022-07-12 08:40:55 INFO Agent received command: run
2022-07-12 08:40:55 INFO Agent starting run with config:
	batch_size: 64
	d_model: 77
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.9734494966215216
	embedding_layers: 1
	embedding_size: 128
	encoder_heads: 2
	encoder_layers: 3
	learning_rate: 0.001
	max_steps: 2743
	net_layers: 2
	net_size: 43
	noise_std: 0.9666353023028108
2022-07-12 08:40:55 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=77 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.9734494966215216 --embedding_layers=1 --embedding_size=128 --encoder_heads=2 --encoder_layers=3 --learning_rate=0.001 --max_steps=2743 --net_layers=2 --net_size=43 --noise_std=0.9666353023028108
2022-07-12 08:41:00 INFO Running runs: ['2cs3kzps']
2022-07-12 08:43:37 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 08:43:37 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 08:43:39 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/missingness/5yhdub6l not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/missingness/5yhdub6l not found

2022-07-12 08:43:46 INFO Running runs: []
2022-07-12 08:43:46 INFO Agent received command: run
2022-07-12 08:43:46 INFO Agent starting run with config:
	batch_size: 32
	d_model: 88
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.3136546231193762
	embedding_layers: 2
	embedding_size: 112
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.001
	max_steps: 4719
	net_layers: 3
	net_size: 122
	noise_std: 1.2874596752924046
2022-07-12 08:43:46 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=88 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.3136546231193762 --embedding_layers=2 --embedding_size=112 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.001 --max_steps=4719 --net_layers=3 --net_size=122 --noise_std=1.2874596752924046
2022-07-12 08:43:52 INFO Running runs: ['jfup6yuc']
2022-07-12 08:49:08 INFO Cleaning up finished run: jfup6yuc
2022-07-12 08:49:09 INFO Agent received command: run
2022-07-12 08:49:09 INFO Agent starting run with config:
	batch_size: 32
	d_model: 71
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.8010023830141056
	embedding_layers: 1
	embedding_size: 62
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.0005
	max_steps: 1131
	net_layers: 1
	net_size: 67
	noise_std: 0.37754563599200613
2022-07-12 08:49:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=71 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.8010023830141056 --embedding_layers=1 --embedding_size=62 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.0005 --max_steps=1131 --net_layers=1 --net_size=67 --noise_std=0.37754563599200613
2022-07-12 08:49:14 INFO Running runs: ['m5yx0s07']
2022-07-12 08:51:51 INFO Cleaning up finished run: m5yx0s07
2022-07-12 08:51:52 INFO Agent received command: run
2022-07-12 08:51:52 INFO Agent starting run with config:
	batch_size: 128
	d_model: 33
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.4404888401897876
	embedding_layers: 4
	embedding_size: 73
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 2089
	net_layers: 3
	net_size: 82
	noise_std: 0.5162761031569825
2022-07-12 08:51:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=33 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.4404888401897876 --embedding_layers=4 --embedding_size=73 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0005 --max_steps=2089 --net_layers=3 --net_size=82 --noise_std=0.5162761031569825
2022-07-12 08:51:57 INFO Running runs: ['n9pbdxzk']
2022-07-12 08:56:29 INFO Cleaning up finished run: n9pbdxzk
2022-07-12 08:56:30 INFO Agent received command: run
2022-07-12 08:56:30 INFO Agent starting run with config:
	batch_size: 8
	d_model: 45
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.05018890055871694
	embedding_layers: 3
	embedding_size: 39
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 1645
	net_layers: 3
	net_size: 41
	noise_std: 0.10437262811785704
2022-07-12 08:56:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=45 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.05018890055871694 --embedding_layers=3 --embedding_size=39 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0005 --max_steps=1645 --net_layers=3 --net_size=41 --noise_std=0.10437262811785704
2022-07-12 08:56:35 INFO Running runs: ['9kbcztfa']
2022-07-12 08:58:07 INFO Cleaning up finished run: 9kbcztfa
2022-07-12 08:58:08 INFO Agent received command: run
2022-07-12 08:58:08 INFO Agent starting run with config:
	batch_size: 32
	d_model: 128
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.9691620422715876
	embedding_layers: 1
	embedding_size: 36
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 1331
	net_layers: 2
	net_size: 121
	noise_std: 1.1027502882883609
2022-07-12 08:58:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=128 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.9691620422715876 --embedding_layers=1 --embedding_size=36 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.001 --max_steps=1331 --net_layers=2 --net_size=121 --noise_std=1.1027502882883609
2022-07-12 08:58:13 INFO Running runs: ['bdb5m24t']
2022-07-12 09:02:46 INFO Cleaning up finished run: bdb5m24t
2022-07-12 09:02:47 INFO Agent received command: run
2022-07-12 09:02:47 INFO Agent starting run with config:
	batch_size: 128
	d_model: 98
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.9657761012024196
	embedding_layers: 2
	embedding_size: 124
	encoder_heads: 4
	encoder_layers: 7
	learning_rate: 0.001
	max_steps: 4387
	net_layers: 1
	net_size: 19
	noise_std: 0.8845608185401542
2022-07-12 09:02:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=98 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.9657761012024196 --embedding_layers=2 --embedding_size=124 --encoder_heads=4 --encoder_layers=7 --learning_rate=0.001 --max_steps=4387 --net_layers=1 --net_size=19 --noise_std=0.8845608185401542
2022-07-12 09:02:52 INFO Running runs: ['2upt4n2b']
2022-07-12 09:21:12 INFO Cleaning up finished run: 2upt4n2b
2022-07-12 09:21:13 INFO Agent received command: run
2022-07-12 09:21:13 INFO Agent starting run with config:
	batch_size: 128
	d_model: 85
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.9568031948934426
	embedding_layers: 4
	embedding_size: 62
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 3093
	net_layers: 1
	net_size: 60
	noise_std: 0.8959387019550489
2022-07-12 09:21:13 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=85 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.9568031948934426 --embedding_layers=4 --embedding_size=62 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.001 --max_steps=3093 --net_layers=1 --net_size=60 --noise_std=0.8959387019550489
2022-07-12 09:21:18 INFO Running runs: ['rcui275u']
2022-07-12 09:31:24 INFO Cleaning up finished run: rcui275u
2022-07-12 09:31:25 INFO Agent received command: run
2022-07-12 09:31:25 INFO Agent starting run with config:
	batch_size: 16
	d_model: 128
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.7889186354877712
	embedding_layers: 1
	embedding_size: 60
	encoder_heads: 3
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 1391
	net_layers: 2
	net_size: 47
	noise_std: 0.6154340204800404
2022-07-12 09:31:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=128 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.7889186354877712 --embedding_layers=1 --embedding_size=60 --encoder_heads=3 --encoder_layers=4 --learning_rate=0.001 --max_steps=1391 --net_layers=2 --net_size=47 --noise_std=0.6154340204800404
2022-07-12 09:31:30 INFO Running runs: ['ha0opfjx']
2022-07-12 09:34:41 INFO Cleaning up finished run: ha0opfjx
2022-07-12 09:34:41 INFO Agent received command: run
2022-07-12 09:34:41 INFO Agent starting run with config:
	batch_size: 64
	d_model: 90
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.24490697795406835
	embedding_layers: 1
	embedding_size: 62
	encoder_heads: 4
	encoder_layers: 7
	learning_rate: 0.0005
	max_steps: 3591
	net_layers: 3
	net_size: 17
	noise_std: 0.33326881594938895
2022-07-12 09:34:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=90 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.24490697795406835 --embedding_layers=1 --embedding_size=62 --encoder_heads=4 --encoder_layers=7 --learning_rate=0.0005 --max_steps=3591 --net_layers=3 --net_size=17 --noise_std=0.33326881594938895
2022-07-12 09:34:47 INFO Running runs: ['p07ptjy8']
2022-07-12 09:40:41 INFO Cleaning up finished run: p07ptjy8
2022-07-12 09:40:41 INFO Agent received command: run
2022-07-12 09:40:41 INFO Agent starting run with config:
	batch_size: 16
	d_model: 72
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.6592116255821893
	embedding_layers: 2
	embedding_size: 106
	encoder_heads: 3
	encoder_layers: 6
	learning_rate: 0.001
	max_steps: 4130
	net_layers: 3
	net_size: 12
	noise_std: 1.3000176054719983
2022-07-12 09:40:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=72 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.6592116255821893 --embedding_layers=2 --embedding_size=106 --encoder_heads=3 --encoder_layers=6 --learning_rate=0.001 --max_steps=4130 --net_layers=3 --net_size=12 --noise_std=1.3000176054719983
2022-07-12 09:40:46 INFO Running runs: ['4qxpn7ky']
2022-07-12 09:49:07 INFO Cleaning up finished run: 4qxpn7ky
2022-07-12 09:49:08 INFO Agent received command: run
2022-07-12 09:49:08 INFO Agent starting run with config:
	batch_size: 32
	d_model: 121
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.8656400184993254
	embedding_layers: 4
	embedding_size: 9
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 1854
	net_layers: 4
	net_size: 87
	noise_std: 0.4246703831111108
2022-07-12 09:49:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=121 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.8656400184993254 --embedding_layers=4 --embedding_size=9 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001 --max_steps=1854 --net_layers=4 --net_size=87 --noise_std=0.4246703831111108
2022-07-12 09:49:13 INFO Running runs: ['5qhh2t1t']
2022-07-12 09:53:57 INFO Cleaning up finished run: 5qhh2t1t
2022-07-12 09:53:57 INFO Agent received command: run
2022-07-12 09:53:57 INFO Agent starting run with config:
	batch_size: 32
	d_model: 102
	decoder_heads: 1
	decoder_layers: 6
	early_stopping: 0.4672566158106535
	embedding_layers: 1
	embedding_size: 83
	encoder_heads: 3
	encoder_layers: 4
	learning_rate: 0.0005
	max_steps: 2140
	net_layers: 1
	net_size: 76
	noise_std: 1.2355545462825903
2022-07-12 09:53:57 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=102 --decoder_heads=1 --decoder_layers=6 --early_stopping=0.4672566158106535 --embedding_layers=1 --embedding_size=83 --encoder_heads=3 --encoder_layers=4 --learning_rate=0.0005 --max_steps=2140 --net_layers=1 --net_size=76 --noise_std=1.2355545462825903
2022-07-12 09:54:03 INFO Running runs: ['9op28fe3']
2022-07-12 09:58:08 INFO Cleaning up finished run: 9op28fe3
2022-07-12 09:58:09 INFO Agent received command: run
2022-07-12 09:58:09 INFO Agent starting run with config:
	batch_size: 16
	d_model: 70
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.5810905491612733
	embedding_layers: 2
	embedding_size: 83
	encoder_heads: 5
	encoder_layers: 2
	learning_rate: 0.001
	max_steps: 4998
	net_layers: 4
	net_size: 35
	noise_std: 1.0302859487975164
2022-07-12 09:58:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=70 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.5810905491612733 --embedding_layers=2 --embedding_size=83 --encoder_heads=5 --encoder_layers=2 --learning_rate=0.001 --max_steps=4998 --net_layers=4 --net_size=35 --noise_std=1.0302859487975164
2022-07-12 09:58:14 INFO Running runs: ['xf6czpnl']
2022-07-12 10:05:48 INFO Cleaning up finished run: xf6czpnl
2022-07-12 10:05:48 INFO Agent received command: run
2022-07-12 10:05:48 INFO Agent starting run with config:
	batch_size: 16
	d_model: 110
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.44638464888223783
	embedding_layers: 2
	embedding_size: 117
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 1295
	net_layers: 4
	net_size: 96
	noise_std: 1.235509818606555
2022-07-12 10:05:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=110 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.44638464888223783 --embedding_layers=2 --embedding_size=117 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.001 --max_steps=1295 --net_layers=4 --net_size=96 --noise_std=1.235509818606555
2022-07-12 10:05:53 INFO Running runs: ['35eacaj0']
2022-07-12 10:07:58 INFO Cleaning up finished run: 35eacaj0
2022-07-12 10:07:59 INFO Agent received command: run
2022-07-12 10:07:59 INFO Agent starting run with config:
	batch_size: 128
	d_model: 124
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.6778993851652881
	embedding_layers: 4
	embedding_size: 10
	encoder_heads: 3
	encoder_layers: 6
	learning_rate: 0.0005
	max_steps: 1038
	net_layers: 1
	net_size: 23
	noise_std: 0.26970614184255215
2022-07-12 10:07:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=124 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.6778993851652881 --embedding_layers=4 --embedding_size=10 --encoder_heads=3 --encoder_layers=6 --learning_rate=0.0005 --max_steps=1038 --net_layers=1 --net_size=23 --noise_std=0.26970614184255215
2022-07-12 10:08:04 INFO Running runs: ['4un2azdt']
2022-07-12 10:12:42 INFO Cleaning up finished run: 4un2azdt
2022-07-12 10:12:42 INFO Agent received command: run
2022-07-12 10:12:42 INFO Agent starting run with config:
	batch_size: 16
	d_model: 82
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.2975149089607103
	embedding_layers: 2
	embedding_size: 52
	encoder_heads: 2
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 1212
	net_layers: 4
	net_size: 114
	noise_std: 1.039318746556943
2022-07-12 10:12:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=82 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.2975149089607103 --embedding_layers=2 --embedding_size=52 --encoder_heads=2 --encoder_layers=7 --learning_rate=0.0001 --max_steps=1212 --net_layers=4 --net_size=114 --noise_std=1.039318746556943
2022-07-12 10:12:47 INFO Running runs: ['ln7jcn46']
2022-07-12 10:15:08 INFO Cleaning up finished run: ln7jcn46
2022-07-12 10:15:09 INFO Agent received command: run
2022-07-12 10:15:09 INFO Agent starting run with config:
	batch_size: 4
	d_model: 118
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.8995571688352402
	embedding_layers: 4
	embedding_size: 128
	encoder_heads: 3
	encoder_layers: 6
	learning_rate: 0.0005
	max_steps: 2546
	net_layers: 4
	net_size: 94
	noise_std: 1.144701504814089
2022-07-12 10:15:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=118 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.8995571688352402 --embedding_layers=4 --embedding_size=128 --encoder_heads=3 --encoder_layers=6 --learning_rate=0.0005 --max_steps=2546 --net_layers=4 --net_size=94 --noise_std=1.144701504814089
2022-07-12 10:15:14 INFO Running runs: ['qyfpejoo']
2022-07-12 10:21:29 INFO Cleaning up finished run: qyfpejoo
2022-07-12 10:21:30 INFO Agent received command: run
2022-07-12 10:21:30 INFO Agent starting run with config:
	batch_size: 8
	d_model: 104
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.6961194302762419
	embedding_layers: 2
	embedding_size: 48
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 2442
	net_layers: 1
	net_size: 73
	noise_std: 0.8573746869811101
2022-07-12 10:21:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=8 --d_model=104 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.6961194302762419 --embedding_layers=2 --embedding_size=48 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0001 --max_steps=2442 --net_layers=1 --net_size=73 --noise_std=0.8573746869811101
2022-07-12 10:21:35 INFO Running runs: ['1nxhoadv']
2022-07-12 10:27:03 INFO Cleaning up finished run: 1nxhoadv
2022-07-12 10:27:04 INFO Agent received command: run
2022-07-12 10:27:04 INFO Agent starting run with config:
	batch_size: 16
	d_model: 71
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.033086806974979566
	embedding_layers: 3
	embedding_size: 39
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.001
	max_steps: 1088
	net_layers: 2
	net_size: 58
	noise_std: 1.4733611861399665
2022-07-12 10:27:04 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=71 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.033086806974979566 --embedding_layers=3 --embedding_size=39 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.001 --max_steps=1088 --net_layers=2 --net_size=58 --noise_std=1.4733611861399665
2022-07-12 10:27:09 INFO Running runs: ['2sptb5gi']
2022-07-12 10:28:40 INFO Cleaning up finished run: 2sptb5gi
2022-07-12 10:28:41 INFO Agent received command: run
2022-07-12 10:28:41 INFO Agent starting run with config:
	batch_size: 32
	d_model: 109
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.3909245844375028
	embedding_layers: 2
	embedding_size: 127
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 1749
	net_layers: 4
	net_size: 29
	noise_std: 0.6381585754496621
2022-07-12 10:28:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=109 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.3909245844375028 --embedding_layers=2 --embedding_size=127 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001 --max_steps=1749 --net_layers=4 --net_size=29 --noise_std=0.6381585754496621
2022-07-12 10:28:46 INFO Running runs: ['te798uee']
2022-07-12 10:32:29 INFO Cleaning up finished run: te798uee
2022-07-12 10:32:30 INFO Agent received command: run
2022-07-12 10:32:30 INFO Agent starting run with config:
	batch_size: 64
	d_model: 36
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.7797628433038704
	embedding_layers: 1
	embedding_size: 75
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 1460
	net_layers: 2
	net_size: 59
	noise_std: 0.4223472740209806
2022-07-12 10:32:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=36 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.7797628433038704 --embedding_layers=1 --embedding_size=75 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.0001 --max_steps=1460 --net_layers=2 --net_size=59 --noise_std=0.4223472740209806
2022-07-12 10:32:35 INFO Running runs: ['komwmn7v']
2022-07-12 10:36:08 INFO Cleaning up finished run: komwmn7v
2022-07-12 10:36:09 INFO Agent received command: run
2022-07-12 10:36:09 INFO Agent starting run with config:
	batch_size: 128
	d_model: 25
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.5587432289628335
	embedding_layers: 1
	embedding_size: 110
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 1438
	net_layers: 2
	net_size: 31
	noise_std: 0.2834399578823488
2022-07-12 10:36:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=25 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.5587432289628335 --embedding_layers=1 --embedding_size=110 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.0005 --max_steps=1438 --net_layers=2 --net_size=31 --noise_std=0.2834399578823488
2022-07-12 10:36:14 INFO Running runs: ['flt5o0z1']
2022-07-12 10:39:20 INFO Cleaning up finished run: flt5o0z1
2022-07-12 10:39:21 INFO Agent received command: run
2022-07-12 10:39:21 INFO Agent starting run with config:
	batch_size: 128
	d_model: 7
	decoder_heads: 4
	decoder_layers: 6
	early_stopping: 0.3005678869142575
	embedding_layers: 2
	embedding_size: 90
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 2543
	net_layers: 3
	net_size: 56
	noise_std: 0.5746476257697062
2022-07-12 10:39:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=7 --decoder_heads=4 --decoder_layers=6 --early_stopping=0.3005678869142575 --embedding_layers=2 --embedding_size=90 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.0001 --max_steps=2543 --net_layers=3 --net_size=56 --noise_std=0.5746476257697062
2022-07-12 10:39:26 INFO Running runs: ['7zlkkhth']
2022-07-12 10:43:37 INFO Cleaning up finished run: 7zlkkhth
2022-07-12 10:43:37 INFO Agent received command: run
2022-07-12 10:43:37 INFO Agent starting run with config:
	batch_size: 64
	d_model: 23
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.7185901936465838
	embedding_layers: 3
	embedding_size: 110
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 2311
	net_layers: 2
	net_size: 58
	noise_std: 0.5645574220008678
2022-07-12 10:43:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=23 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.7185901936465838 --embedding_layers=3 --embedding_size=110 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.0001 --max_steps=2311 --net_layers=2 --net_size=58 --noise_std=0.5645574220008678
2022-07-12 10:43:42 INFO Running runs: ['12fj6s4n']
2022-07-12 10:48:26 INFO Cleaning up finished run: 12fj6s4n
2022-07-12 10:48:27 INFO Agent received command: run
2022-07-12 10:48:27 INFO Agent starting run with config:
	batch_size: 32
	d_model: 23
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.2916777009919729
	embedding_layers: 2
	embedding_size: 105
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 1012
	net_layers: 4
	net_size: 58
	noise_std: 1.0667213909202593
2022-07-12 10:48:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=23 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.2916777009919729 --embedding_layers=2 --embedding_size=105 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.0001 --max_steps=1012 --net_layers=4 --net_size=58 --noise_std=1.0667213909202593
2022-07-12 10:48:32 INFO Running runs: ['b9z221n8']
2022-07-12 10:50:26 INFO Cleaning up finished run: b9z221n8
2022-07-12 10:50:26 INFO Agent received command: run
2022-07-12 10:50:26 INFO Agent starting run with config:
	batch_size: 128
	d_model: 40
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.18634740963341123
	embedding_layers: 2
	embedding_size: 68
	encoder_heads: 5
	encoder_layers: 2
	learning_rate: 0.0005
	max_steps: 1306
	net_layers: 2
	net_size: 16
	noise_std: 0.2648904310679198
2022-07-12 10:50:26 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=40 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.18634740963341123 --embedding_layers=2 --embedding_size=68 --encoder_heads=5 --encoder_layers=2 --learning_rate=0.0005 --max_steps=1306 --net_layers=2 --net_size=16 --noise_std=0.2648904310679198
2022-07-12 10:50:31 INFO Running runs: ['bm8hdwra']
2022-07-12 10:53:20 INFO Cleaning up finished run: bm8hdwra
2022-07-12 10:53:21 INFO Agent received command: run
2022-07-12 10:53:21 INFO Agent starting run with config:
	batch_size: 32
	d_model: 35
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.3066233511381877
	embedding_layers: 2
	embedding_size: 97
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 2487
	net_layers: 2
	net_size: 49
	noise_std: 0.2213989169277437
2022-07-12 10:53:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=35 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.3066233511381877 --embedding_layers=2 --embedding_size=97 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.0005 --max_steps=2487 --net_layers=2 --net_size=49 --noise_std=0.2213989169277437
2022-07-12 10:53:26 INFO Running runs: ['r2uc9io6']
2022-07-12 10:57:20 INFO Cleaning up finished run: r2uc9io6
2022-07-12 10:57:21 INFO Agent received command: run
2022-07-12 10:57:21 INFO Agent starting run with config:
	batch_size: 32
	d_model: 22
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.44261257023116063
	embedding_layers: 2
	embedding_size: 67
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 1725
	net_layers: 2
	net_size: 80
	noise_std: 0.1389768035052113
2022-07-12 10:57:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=22 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.44261257023116063 --embedding_layers=2 --embedding_size=67 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.0005 --max_steps=1725 --net_layers=2 --net_size=80 --noise_std=0.1389768035052113
2022-07-12 10:57:26 INFO Running runs: ['50p1wfdv']
2022-07-12 11:00:15 INFO Cleaning up finished run: 50p1wfdv
2022-07-12 11:00:16 INFO Agent received command: run
2022-07-12 11:00:16 INFO Agent starting run with config:
	batch_size: 16
	d_model: 48
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.63952875040048
	embedding_layers: 1
	embedding_size: 109
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 1441
	net_layers: 3
	net_size: 60
	noise_std: 0.4606678982769832
2022-07-12 11:00:16 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=48 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.63952875040048 --embedding_layers=1 --embedding_size=109 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.0005 --max_steps=1441 --net_layers=3 --net_size=60 --noise_std=0.4606678982769832
2022-07-12 11:00:21 INFO Running runs: ['ywakv8rl']
2022-07-12 11:02:31 INFO Cleaning up finished run: ywakv8rl
2022-07-12 11:02:33 INFO Agent received command: run
2022-07-12 11:02:33 INFO Agent starting run with config:
	batch_size: 128
	d_model: 19
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.5316751561250513
	embedding_layers: 3
	embedding_size: 81
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 1524
	net_layers: 2
	net_size: 13
	noise_std: 0.02507959418200284
2022-07-12 11:02:33 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=19 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.5316751561250513 --embedding_layers=3 --embedding_size=81 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.0005 --max_steps=1524 --net_layers=2 --net_size=13 --noise_std=0.02507959418200284
2022-07-12 11:02:38 INFO Running runs: ['uiomqo2h']
2022-07-12 11:05:38 INFO Cleaning up finished run: uiomqo2h
2022-07-12 11:05:45 INFO Running runs: []
2022-07-12 11:05:46 INFO Agent received command: run
2022-07-12 11:05:46 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.058330434029143285
	max_bin: 188
	max_depth: 7
	min_data_in_leaf: 15
	num_iterations: 177
	num_leaves: 35
2022-07-12 11:05:46 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.058330434029143285 --max_bin=188 --max_depth=7 --min_data_in_leaf=15 --num_iterations=177 --num_leaves=35
2022-07-12 11:05:51 INFO Running runs: ['23xgdrf5']
2022-07-12 11:06:07 INFO Cleaning up finished run: 23xgdrf5
2022-07-12 11:06:10 INFO Agent received command: run
2022-07-12 11:06:10 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8653107076055507
	max_bin: 32
	max_depth: 30
	min_data_in_leaf: 22
	num_iterations: 827
	num_leaves: 23
2022-07-12 11:06:10 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8653107076055507 --max_bin=32 --max_depth=30 --min_data_in_leaf=22 --num_iterations=827 --num_leaves=23
2022-07-12 11:06:15 INFO Running runs: ['bn810im0']
2022-07-12 11:06:31 INFO Cleaning up finished run: bn810im0
2022-07-12 11:06:31 INFO Agent received command: run
2022-07-12 11:06:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.7885414212848572
	max_bin: 142
	max_depth: 17
	min_data_in_leaf: 24
	num_iterations: 972
	num_leaves: 21
2022-07-12 11:06:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.7885414212848572 --max_bin=142 --max_depth=17 --min_data_in_leaf=24 --num_iterations=972 --num_leaves=21
2022-07-12 11:06:36 INFO Running runs: ['5owo0qrk']
2022-07-12 11:06:53 INFO Cleaning up finished run: 5owo0qrk
2022-07-12 11:06:53 INFO Agent received command: run
2022-07-12 11:06:53 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0373656362691801
	max_bin: 245
	max_depth: 12
	min_data_in_leaf: 20
	num_iterations: 156
	num_leaves: 40
2022-07-12 11:06:53 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0373656362691801 --max_bin=245 --max_depth=12 --min_data_in_leaf=20 --num_iterations=156 --num_leaves=40
2022-07-12 11:06:58 INFO Running runs: ['p3jsndqt']
2022-07-12 11:07:15 INFO Cleaning up finished run: p3jsndqt
2022-07-12 11:07:15 INFO Agent received command: run
2022-07-12 11:07:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06543095483039063
	max_bin: 224
	max_depth: 11
	min_data_in_leaf: 11
	num_iterations: 124
	num_leaves: 8
2022-07-12 11:07:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06543095483039063 --max_bin=224 --max_depth=11 --min_data_in_leaf=11 --num_iterations=124 --num_leaves=8
2022-07-12 11:07:20 INFO Running runs: ['cmtnw90g']
2022-07-12 11:07:36 INFO Cleaning up finished run: cmtnw90g
2022-07-12 11:07:37 INFO Agent received command: run
2022-07-12 11:07:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2884423324530635
	max_bin: 92
	max_depth: 6
	min_data_in_leaf: 29
	num_iterations: 104
	num_leaves: 38
2022-07-12 11:07:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2884423324530635 --max_bin=92 --max_depth=6 --min_data_in_leaf=29 --num_iterations=104 --num_leaves=38
2022-07-12 11:07:42 INFO Running runs: ['pkq2d73d']
2022-07-12 11:07:58 INFO Cleaning up finished run: pkq2d73d
2022-07-12 11:07:59 INFO Agent received command: run
2022-07-12 11:07:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.007840995123871042
	max_bin: 238
	max_depth: 30
	min_data_in_leaf: 14
	num_iterations: 180
	num_leaves: 40
2022-07-12 11:07:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.007840995123871042 --max_bin=238 --max_depth=30 --min_data_in_leaf=14 --num_iterations=180 --num_leaves=40
2022-07-12 11:08:04 INFO Running runs: ['bvukp7ps']
2022-07-12 11:08:20 INFO Cleaning up finished run: bvukp7ps
2022-07-12 11:08:21 INFO Agent received command: run
2022-07-12 11:08:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.20213470926949195
	max_bin: 215
	max_depth: 8
	min_data_in_leaf: 17
	num_iterations: 174
	num_leaves: 33
2022-07-12 11:08:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.20213470926949195 --max_bin=215 --max_depth=8 --min_data_in_leaf=17 --num_iterations=174 --num_leaves=33
2022-07-12 11:08:26 INFO Running runs: ['9112iawr']
2022-07-12 11:08:42 INFO Cleaning up finished run: 9112iawr
2022-07-12 11:08:43 INFO Agent received command: run
2022-07-12 11:08:43 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08261702380705505
	max_bin: 168
	max_depth: 8
	min_data_in_leaf: 25
	num_iterations: 111
	num_leaves: 33
2022-07-12 11:08:43 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08261702380705505 --max_bin=168 --max_depth=8 --min_data_in_leaf=25 --num_iterations=111 --num_leaves=33
2022-07-12 11:08:48 INFO Running runs: ['8g3rpnkl']
2022-07-12 11:09:04 INFO Cleaning up finished run: 8g3rpnkl
2022-07-12 11:09:05 INFO Agent received command: run
2022-07-12 11:09:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07170918852793895
	max_bin: 193
	max_depth: 5
	min_data_in_leaf: 20
	num_iterations: 402
	num_leaves: 39
2022-07-12 11:09:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07170918852793895 --max_bin=193 --max_depth=5 --min_data_in_leaf=20 --num_iterations=402 --num_leaves=39
2022-07-12 11:09:10 INFO Running runs: ['3wk6ena8']
2022-07-12 11:09:26 INFO Cleaning up finished run: 3wk6ena8
2022-07-12 11:09:26 INFO Agent received command: run
2022-07-12 11:09:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.18194320000449904
	max_bin: 111
	max_depth: 5
	min_data_in_leaf: 15
	num_iterations: 218
	num_leaves: 14
2022-07-12 11:09:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.18194320000449904 --max_bin=111 --max_depth=5 --min_data_in_leaf=15 --num_iterations=218 --num_leaves=14
2022-07-12 11:09:31 INFO Running runs: ['r5cas7dw']
2022-07-12 11:09:47 INFO Cleaning up finished run: r5cas7dw
2022-07-12 11:09:48 INFO Agent received command: run
2022-07-12 11:09:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4322679998217682
	max_bin: 220
	max_depth: 6
	min_data_in_leaf: 27
	num_iterations: 469
	num_leaves: 7
2022-07-12 11:09:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4322679998217682 --max_bin=220 --max_depth=6 --min_data_in_leaf=27 --num_iterations=469 --num_leaves=7
2022-07-12 11:09:53 INFO Running runs: ['2fkrz0uo']
2022-07-12 11:10:09 INFO Cleaning up finished run: 2fkrz0uo
2022-07-12 11:10:10 INFO Agent received command: run
2022-07-12 11:10:10 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.01422589356423476
	max_bin: 97
	max_depth: 4
	min_data_in_leaf: 11
	num_iterations: 230
	num_leaves: 36
2022-07-12 11:10:10 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.01422589356423476 --max_bin=97 --max_depth=4 --min_data_in_leaf=11 --num_iterations=230 --num_leaves=36
2022-07-12 11:10:15 INFO Running runs: ['ml89nrnv']
2022-07-12 11:10:31 INFO Cleaning up finished run: ml89nrnv
2022-07-12 11:10:32 INFO Agent received command: run
2022-07-12 11:10:32 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.11501143166450256
	max_bin: 234
	max_depth: 4
	min_data_in_leaf: 24
	num_iterations: 228
	num_leaves: 38
2022-07-12 11:10:32 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.11501143166450256 --max_bin=234 --max_depth=4 --min_data_in_leaf=24 --num_iterations=228 --num_leaves=38
2022-07-12 11:10:37 INFO Running runs: ['6s1csw0n']
2022-07-12 11:10:53 INFO Cleaning up finished run: 6s1csw0n
2022-07-12 11:10:54 INFO Agent received command: run
2022-07-12 11:10:54 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09475498540326056
	max_bin: 178
	max_depth: 6
	min_data_in_leaf: 19
	num_iterations: 186
	num_leaves: 5
2022-07-12 11:10:54 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09475498540326056 --max_bin=178 --max_depth=6 --min_data_in_leaf=19 --num_iterations=186 --num_leaves=5
2022-07-12 11:10:59 INFO Running runs: ['img8nf4w']
2022-07-12 11:11:15 INFO Cleaning up finished run: img8nf4w
2022-07-12 11:11:16 INFO Agent received command: run
2022-07-12 11:11:16 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5778501055883674
	max_bin: 40
	max_depth: 11
	min_data_in_leaf: 13
	num_iterations: 682
	num_leaves: 7
2022-07-12 11:11:16 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.5778501055883674 --max_bin=40 --max_depth=11 --min_data_in_leaf=13 --num_iterations=682 --num_leaves=7
2022-07-12 11:11:21 INFO Running runs: ['pu8nx7ns']
2022-07-12 11:11:37 INFO Cleaning up finished run: pu8nx7ns
2022-07-12 11:11:38 INFO Agent received command: run
2022-07-12 11:11:38 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05016655915533663
	max_bin: 70
	max_depth: 4
	min_data_in_leaf: 27
	num_iterations: 112
	num_leaves: 24
2022-07-12 11:11:38 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05016655915533663 --max_bin=70 --max_depth=4 --min_data_in_leaf=27 --num_iterations=112 --num_leaves=24
2022-07-12 11:11:43 INFO Running runs: ['kvi5sq9v']
2022-07-12 11:11:59 INFO Cleaning up finished run: kvi5sq9v
2022-07-12 11:12:00 INFO Agent received command: run
2022-07-12 11:12:00 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.791235566997457
	max_bin: 46
	max_depth: 14
	min_data_in_leaf: 30
	num_iterations: 914
	num_leaves: 39
2022-07-12 11:12:00 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.791235566997457 --max_bin=46 --max_depth=14 --min_data_in_leaf=30 --num_iterations=914 --num_leaves=39
2022-07-12 11:12:05 INFO Running runs: ['ucer2p4r']
2022-07-12 11:12:21 INFO Cleaning up finished run: ucer2p4r
2022-07-12 11:12:22 INFO Agent received command: run
2022-07-12 11:12:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.014212787751502145
	max_bin: 188
	max_depth: 4
	min_data_in_leaf: 19
	num_iterations: 327
	num_leaves: 17
2022-07-12 11:12:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.014212787751502145 --max_bin=188 --max_depth=4 --min_data_in_leaf=19 --num_iterations=327 --num_leaves=17
2022-07-12 11:12:27 INFO Running runs: ['omgavps4']
2022-07-12 11:12:43 INFO Cleaning up finished run: omgavps4
2022-07-12 11:12:44 INFO Agent received command: run
2022-07-12 11:12:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0916102225418718
	max_bin: 125
	max_depth: 5
	min_data_in_leaf: 12
	num_iterations: 135
	num_leaves: 11
2022-07-12 11:12:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0916102225418718 --max_bin=125 --max_depth=5 --min_data_in_leaf=12 --num_iterations=135 --num_leaves=11
2022-07-12 11:12:49 INFO Running runs: ['k1vrhiyv']
2022-07-12 11:13:05 INFO Cleaning up finished run: k1vrhiyv
2022-07-12 11:13:05 INFO Agent received command: run
2022-07-12 11:13:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04527839541586354
	max_bin: 251
	max_depth: 4
	min_data_in_leaf: 12
	num_iterations: 423
	num_leaves: 10
2022-07-12 11:13:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04527839541586354 --max_bin=251 --max_depth=4 --min_data_in_leaf=12 --num_iterations=423 --num_leaves=10
2022-07-12 11:13:10 INFO Running runs: ['iykqqr1c']
2022-07-12 11:13:26 INFO Cleaning up finished run: iykqqr1c
2022-07-12 11:13:27 INFO Agent received command: run
2022-07-12 11:13:27 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8041835537235048
	max_bin: 253
	max_depth: 4
	min_data_in_leaf: 10
	num_iterations: 784
	num_leaves: 5
2022-07-12 11:13:27 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8041835537235048 --max_bin=253 --max_depth=4 --min_data_in_leaf=10 --num_iterations=784 --num_leaves=5
2022-07-12 11:13:32 INFO Running runs: ['vge6mpkk']
2022-07-12 11:13:48 INFO Cleaning up finished run: vge6mpkk
2022-07-12 11:13:49 INFO Agent received command: run
2022-07-12 11:13:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8062121142292938
	max_bin: 141
	max_depth: 25
	min_data_in_leaf: 30
	num_iterations: 972
	num_leaves: 7
2022-07-12 11:13:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8062121142292938 --max_bin=141 --max_depth=25 --min_data_in_leaf=30 --num_iterations=972 --num_leaves=7
2022-07-12 11:13:54 INFO Running runs: ['yhxo33ff']
2022-07-12 11:14:10 INFO Cleaning up finished run: yhxo33ff
2022-07-12 11:14:11 INFO Agent received command: run
2022-07-12 11:14:11 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.21492722973595868
	max_bin: 219
	max_depth: 4
	min_data_in_leaf: 15
	num_iterations: 114
	num_leaves: 20
2022-07-12 11:14:11 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.21492722973595868 --max_bin=219 --max_depth=4 --min_data_in_leaf=15 --num_iterations=114 --num_leaves=20
2022-07-12 11:14:16 INFO Running runs: ['afnvdiqv']
2022-07-12 11:14:32 INFO Cleaning up finished run: afnvdiqv
2022-07-12 11:14:33 INFO Agent received command: run
2022-07-12 11:14:33 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.1282310411594635
	max_bin: 232
	max_depth: 4
	min_data_in_leaf: 10
	num_iterations: 312
	num_leaves: 28
2022-07-12 11:14:33 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.1282310411594635 --max_bin=232 --max_depth=4 --min_data_in_leaf=10 --num_iterations=312 --num_leaves=28
2022-07-12 11:14:38 INFO Running runs: ['0uba9luq']
2022-07-12 11:14:54 INFO Cleaning up finished run: 0uba9luq
2022-07-12 11:14:55 INFO Agent received command: run
2022-07-12 11:14:55 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6302369584618024
	max_bin: 239
	max_depth: 4
	min_data_in_leaf: 17
	num_iterations: 126
	num_leaves: 14
2022-07-12 11:14:55 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6302369584618024 --max_bin=239 --max_depth=4 --min_data_in_leaf=17 --num_iterations=126 --num_leaves=14
2022-07-12 11:15:00 INFO Running runs: ['gm2dpop1']
2022-07-12 11:15:18 INFO Cleaning up finished run: gm2dpop1
2022-07-12 11:15:19 INFO Agent received command: run
2022-07-12 11:15:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9493201942654648
	max_bin: 50
	max_depth: 30
	min_data_in_leaf: 25
	num_iterations: 129
	num_leaves: 11
2022-07-12 11:15:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9493201942654648 --max_bin=50 --max_depth=30 --min_data_in_leaf=25 --num_iterations=129 --num_leaves=11
2022-07-12 11:15:24 INFO Running runs: ['3imnehln']
2022-07-12 11:15:40 INFO Cleaning up finished run: 3imnehln
2022-07-12 11:15:41 INFO Agent received command: run
2022-07-12 11:15:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04454808439881386
	max_bin: 208
	max_depth: 4
	min_data_in_leaf: 12
	num_iterations: 178
	num_leaves: 23
2022-07-12 11:15:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04454808439881386 --max_bin=208 --max_depth=4 --min_data_in_leaf=12 --num_iterations=178 --num_leaves=23
2022-07-12 11:15:46 INFO Running runs: ['wjocv85i']
2022-07-12 11:16:02 INFO Cleaning up finished run: wjocv85i
2022-07-12 11:16:02 INFO Agent received command: run
2022-07-12 11:16:02 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0986795856085726
	max_bin: 198
	max_depth: 5
	min_data_in_leaf: 13
	num_iterations: 172
	num_leaves: 6
2022-07-12 11:16:02 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0986795856085726 --max_bin=198 --max_depth=5 --min_data_in_leaf=13 --num_iterations=172 --num_leaves=6
2022-07-12 11:16:07 INFO Running runs: ['l6531wjr']
2022-07-12 11:16:24 INFO Cleaning up finished run: l6531wjr
2022-07-12 11:16:24 INFO Agent received command: run
2022-07-12 11:16:24 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9723945235339436
	max_bin: 15
	max_depth: 7
	min_data_in_leaf: 28
	num_iterations: 128
	num_leaves: 23
2022-07-12 11:16:24 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9723945235339436 --max_bin=15 --max_depth=7 --min_data_in_leaf=28 --num_iterations=128 --num_leaves=23
2022-07-12 11:16:29 INFO Running runs: ['o3uo8faz']
2022-07-12 11:16:45 INFO Cleaning up finished run: o3uo8faz
2022-07-12 11:16:53 INFO Running runs: []
2022-07-12 11:16:54 INFO Agent received command: run
2022-07-12 11:16:54 INFO Agent starting run with config:
	batch_size: 32
	d_model: 91
	decoder_heads: 4
	decoder_layers: 6
	early_stopping: 0.8573411111034016
	embedding_layers: 1
	embedding_size: 110
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 3984
	net_layers: 2
	net_size: 27
	noise_std: 0.6920074597144692
2022-07-12 11:16:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=91 --decoder_heads=4 --decoder_layers=6 --early_stopping=0.8573411111034016 --embedding_layers=1 --embedding_size=110 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0005 --max_steps=3984 --net_layers=2 --net_size=27 --noise_std=0.6920074597144692
2022-07-12 11:16:59 INFO Running runs: ['9dt6pqbo']
2022-07-12 11:21:31 INFO Cleaning up finished run: 9dt6pqbo
2022-07-12 11:21:32 INFO Agent received command: run
2022-07-12 11:21:32 INFO Agent starting run with config:
	batch_size: 16
	d_model: 10
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.16555438125417743
	embedding_layers: 1
	embedding_size: 36
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 1466
	net_layers: 2
	net_size: 9
	noise_std: 1.3468800725040295
2022-07-12 11:21:32 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=10 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.16555438125417743 --embedding_layers=1 --embedding_size=36 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.001 --max_steps=1466 --net_layers=2 --net_size=9 --noise_std=1.3468800725040295
2022-07-12 11:21:37 INFO Running runs: ['l8q8l8zr']
2022-07-12 11:22:36 INFO Cleaning up finished run: l8q8l8zr
2022-07-12 11:22:37 INFO Agent received command: run
2022-07-12 11:22:37 INFO Agent starting run with config:
	batch_size: 128
	d_model: 85
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.6092755044603045
	embedding_layers: 1
	embedding_size: 74
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 4820
	net_layers: 2
	net_size: 99
	noise_std: 0.13887662091979153
2022-07-12 11:22:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=85 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.6092755044603045 --embedding_layers=1 --embedding_size=74 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.001 --max_steps=4820 --net_layers=2 --net_size=99 --noise_std=0.13887662091979153
2022-07-12 11:22:42 INFO Running runs: ['yuk0haq9']
2022-07-12 11:25:14 INFO Cleaning up finished run: yuk0haq9
2022-07-12 11:25:15 INFO Agent received command: run
2022-07-12 11:25:15 INFO Agent starting run with config:
	batch_size: 32
	d_model: 120
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.06575401691092364
	embedding_layers: 4
	embedding_size: 59
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 4890
	net_layers: 4
	net_size: 70
	noise_std: 0.4916828149963878
2022-07-12 11:25:15 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=120 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.06575401691092364 --embedding_layers=4 --embedding_size=59 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0001 --max_steps=4890 --net_layers=4 --net_size=70 --noise_std=0.4916828149963878
2022-07-12 11:25:20 INFO Running runs: ['0rxvgvm4']
2022-07-12 11:27:49 INFO Cleaning up finished run: 0rxvgvm4
2022-07-12 11:27:50 INFO Agent received command: run
2022-07-12 11:27:50 INFO Agent starting run with config:
	batch_size: 16
	d_model: 118
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.6248951418415567
	embedding_layers: 2
	embedding_size: 88
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1986
	net_layers: 1
	net_size: 10
	noise_std: 0.7562991277825474
2022-07-12 11:27:50 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=118 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.6248951418415567 --embedding_layers=2 --embedding_size=88 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1986 --net_layers=1 --net_size=10 --noise_std=0.7562991277825474
2022-07-12 11:27:55 INFO Running runs: ['w5v85kih']
2022-07-12 11:30:00 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:30:00 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:30:08 INFO Running runs: []
2022-07-12 11:30:09 INFO Agent received command: run
2022-07-12 11:30:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.7501586540718519
	max_bin: 236
	max_depth: 18
	min_data_in_leaf: 11
	num_iterations: 696
	num_leaves: 21
2022-07-12 11:30:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.7501586540718519 --max_bin=236 --max_depth=18 --min_data_in_leaf=11 --num_iterations=696 --num_leaves=21
2022-07-12 11:30:14 INFO Running runs: ['3xilia3g']
2022-07-12 11:30:30 INFO Cleaning up finished run: 3xilia3g
2022-07-12 11:30:31 INFO Agent received command: run
2022-07-12 11:30:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.335059218402055
	max_bin: 130
	max_depth: 7
	min_data_in_leaf: 17
	num_iterations: 815
	num_leaves: 36
2022-07-12 11:30:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.335059218402055 --max_bin=130 --max_depth=7 --min_data_in_leaf=17 --num_iterations=815 --num_leaves=36
2022-07-12 11:30:36 INFO Running runs: ['op3l0hz0']
2022-07-12 11:30:47 INFO Cleaning up finished run: op3l0hz0
2022-07-12 11:30:47 INFO Agent received command: run
2022-07-12 11:30:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.2831689859574845
	max_bin: 71
	max_depth: 4
	min_data_in_leaf: 29
	num_iterations: 125
	num_leaves: 14
2022-07-12 11:30:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.2831689859574845 --max_bin=71 --max_depth=4 --min_data_in_leaf=29 --num_iterations=125 --num_leaves=14
2022-07-12 11:30:52 INFO Running runs: ['5lkj9c2r']
2022-07-12 11:31:03 INFO Cleaning up finished run: 5lkj9c2r
2022-07-12 11:31:04 INFO Agent received command: run
2022-07-12 11:31:04 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06045819579727507
	max_bin: 200
	max_depth: 27
	min_data_in_leaf: 15
	num_iterations: 810
	num_leaves: 38
2022-07-12 11:31:04 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06045819579727507 --max_bin=200 --max_depth=27 --min_data_in_leaf=15 --num_iterations=810 --num_leaves=38
2022-07-12 11:31:09 INFO Running runs: ['xqn8mc3f']
2022-07-12 11:31:25 INFO Cleaning up finished run: xqn8mc3f
2022-07-12 11:31:25 INFO Agent received command: run
2022-07-12 11:31:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9304004186412622
	max_bin: 46
	max_depth: 27
	min_data_in_leaf: 26
	num_iterations: 679
	num_leaves: 28
2022-07-12 11:31:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9304004186412622 --max_bin=46 --max_depth=27 --min_data_in_leaf=26 --num_iterations=679 --num_leaves=28
2022-07-12 11:31:30 INFO Running runs: ['zg0gcmcy']
2022-07-12 11:31:46 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:31:46 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:31:54 INFO Running runs: []
2022-07-12 11:31:55 INFO Agent received command: run
2022-07-12 11:31:55 INFO Agent starting run with config:
	batch_size: 32
	d_model: 36
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.875118742997072
	embedding_layers: 3
	embedding_size: 93
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.001
	max_steps: 4880
	net_layers: 1
	net_size: 84
	noise_std: 1.323857214337043
2022-07-12 11:31:55 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=36 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.875118742997072 --embedding_layers=3 --embedding_size=93 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.001 --max_steps=4880 --net_layers=1 --net_size=84 --noise_std=1.323857214337043
2022-07-12 11:32:00 INFO Running runs: ['dlm1511h']
2022-07-12 11:34:37 INFO Cleaning up finished run: dlm1511h
2022-07-12 11:34:38 INFO Agent received command: run
2022-07-12 11:34:38 INFO Agent starting run with config:
	batch_size: 16
	d_model: 97
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.08865596463370207
	embedding_layers: 4
	embedding_size: 101
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 4913
	net_layers: 2
	net_size: 107
	noise_std: 1.396685218415472
2022-07-12 11:34:38 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=97 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.08865596463370207 --embedding_layers=4 --embedding_size=101 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.0001 --max_steps=4913 --net_layers=2 --net_size=107 --noise_std=1.396685218415472
2022-07-12 11:34:43 INFO Running runs: ['bpaq23vb']
2022-07-12 11:38:26 INFO Cleaning up finished run: bpaq23vb
2022-07-12 11:38:26 INFO Agent received command: run
2022-07-12 11:38:26 INFO Agent starting run with config:
	batch_size: 4
	d_model: 35
	decoder_heads: 5
	decoder_layers: 8
	early_stopping: 0.6616503457435424
	embedding_layers: 1
	embedding_size: 115
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.001
	max_steps: 1293
	net_layers: 4
	net_size: 35
	noise_std: 0.6042230359988878
2022-07-12 11:38:26 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=4 --d_model=35 --decoder_heads=5 --decoder_layers=8 --early_stopping=0.6616503457435424 --embedding_layers=1 --embedding_size=115 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.001 --max_steps=1293 --net_layers=4 --net_size=35 --noise_std=0.6042230359988878
2022-07-12 11:38:31 INFO Running runs: ['ltrrjcb5']
2022-07-12 11:39:37 INFO Cleaning up finished run: ltrrjcb5
2022-07-12 11:39:37 INFO Agent received command: run
2022-07-12 11:39:37 INFO Agent starting run with config:
	batch_size: 128
	d_model: 60
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.8406533664997693
	embedding_layers: 1
	embedding_size: 36
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 2992
	net_layers: 3
	net_size: 21
	noise_std: 0.3663433327861535
2022-07-12 11:39:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=60 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.8406533664997693 --embedding_layers=1 --embedding_size=36 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.0001 --max_steps=2992 --net_layers=3 --net_size=21 --noise_std=0.3663433327861535
2022-07-12 11:39:42 INFO Running runs: ['2xebaw4b']
2022-07-12 11:42:20 INFO Cleaning up finished run: 2xebaw4b
2022-07-12 11:42:21 INFO Agent received command: run
2022-07-12 11:42:21 INFO Agent starting run with config:
	batch_size: 16
	d_model: 10
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.7049802218384537
	embedding_layers: 3
	embedding_size: 64
	encoder_heads: 3
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 1774
	net_layers: 2
	net_size: 48
	noise_std: 1.296854138877887
2022-07-12 11:42:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=16 --d_model=10 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.7049802218384537 --embedding_layers=3 --embedding_size=64 --encoder_heads=3 --encoder_layers=7 --learning_rate=0.0001 --max_steps=1774 --net_layers=2 --net_size=48 --noise_std=1.296854138877887
2022-07-12 11:42:26 INFO Running runs: ['wlyy8ub7']
2022-07-12 11:43:47 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:43:47 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:43:55 INFO Running runs: []
2022-07-12 11:43:56 INFO Agent received command: run
2022-07-12 11:43:56 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4612166311731024
	max_bin: 164
	max_depth: 6
	min_data_in_leaf: 15
	num_iterations: 224
	num_leaves: 33
2022-07-12 11:43:56 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.4612166311731024 --max_bin=164 --max_depth=6 --min_data_in_leaf=15 --num_iterations=224 --num_leaves=33
2022-07-12 11:44:01 INFO Running runs: ['yv957csk']
2022-07-12 11:44:17 INFO Cleaning up finished run: yv957csk
2022-07-12 11:44:17 INFO Agent received command: run
2022-07-12 11:44:17 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.30920666178616585
	max_bin: 130
	max_depth: 25
	min_data_in_leaf: 14
	num_iterations: 481
	num_leaves: 12
2022-07-12 11:44:17 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.30920666178616585 --max_bin=130 --max_depth=25 --min_data_in_leaf=14 --num_iterations=481 --num_leaves=12
2022-07-12 11:44:22 INFO Running runs: ['xggpnb2y']
2022-07-12 11:44:39 INFO Cleaning up finished run: xggpnb2y
2022-07-12 11:44:39 INFO Agent received command: run
2022-07-12 11:44:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9537823861040772
	max_bin: 42
	max_depth: 11
	min_data_in_leaf: 30
	num_iterations: 812
	num_leaves: 20
2022-07-12 11:44:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.9537823861040772 --max_bin=42 --max_depth=11 --min_data_in_leaf=30 --num_iterations=812 --num_leaves=20
2022-07-12 11:44:44 INFO Running runs: ['lwlmw5wj']
2022-07-12 11:45:00 INFO Cleaning up finished run: lwlmw5wj
2022-07-12 11:45:01 INFO Agent received command: run
2022-07-12 11:45:01 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03980677654238862
	max_bin: 228
	max_depth: 22
	min_data_in_leaf: 23
	num_iterations: 626
	num_leaves: 29
2022-07-12 11:45:01 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03980677654238862 --max_bin=228 --max_depth=22 --min_data_in_leaf=23 --num_iterations=626 --num_leaves=29
2022-07-12 11:45:06 INFO Running runs: ['zh2agn7h']
2022-07-12 11:45:22 INFO Cleaning up finished run: zh2agn7h
2022-07-12 11:45:23 INFO Agent received command: run
2022-07-12 11:45:23 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.12861633528981997
	max_bin: 63
	max_depth: 5
	min_data_in_leaf: 21
	num_iterations: 586
	num_leaves: 10
2022-07-12 11:45:23 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.12861633528981997 --max_bin=63 --max_depth=5 --min_data_in_leaf=21 --num_iterations=586 --num_leaves=10
2022-07-12 11:45:28 INFO Running runs: ['5ravps5s']
2022-07-12 11:45:44 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:45:44 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:45:51 INFO Running runs: []
2022-07-12 11:45:52 INFO Agent received command: run
2022-07-12 11:45:52 INFO Agent starting run with config:
	batch_size: 8
	d_model: 126
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.02252323172046866
	embedding_layers: 3
	embedding_size: 55
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 2937
	net_layers: 3
	net_size: 70
	noise_std: 1.291229961230299
2022-07-12 11:45:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=8 --d_model=126 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.02252323172046866 --embedding_layers=3 --embedding_size=55 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=2937 --net_layers=3 --net_size=70 --noise_std=1.291229961230299
2022-07-12 11:45:57 INFO Running runs: ['4r43wfxo']
2022-07-12 11:46:08 INFO Cleaning up finished run: 4r43wfxo
2022-07-12 11:46:08 INFO Agent received command: run
2022-07-12 11:46:08 INFO Agent starting run with config:
	batch_size: 64
	d_model: 55
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.062012334096611776
	embedding_layers: 3
	embedding_size: 31
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.001
	max_steps: 2334
	net_layers: 1
	net_size: 17
	noise_std: 1.225577927360984
2022-07-12 11:46:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=64 --d_model=55 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.062012334096611776 --embedding_layers=3 --embedding_size=31 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.001 --max_steps=2334 --net_layers=1 --net_size=17 --noise_std=1.225577927360984
2022-07-12 11:46:13 INFO Running runs: ['c4p4uvvc']
2022-07-12 11:46:24 INFO Cleaning up finished run: c4p4uvvc
2022-07-12 11:46:25 INFO Agent received command: run
2022-07-12 11:46:25 INFO Agent starting run with config:
	batch_size: 8
	d_model: 8
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.9392000027278872
	embedding_layers: 1
	embedding_size: 105
	encoder_heads: 2
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 1047
	net_layers: 2
	net_size: 96
	noise_std: 0.06770345190281495
2022-07-12 11:46:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=8 --d_model=8 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.9392000027278872 --embedding_layers=1 --embedding_size=105 --encoder_heads=2 --encoder_layers=3 --learning_rate=0.0005 --max_steps=1047 --net_layers=2 --net_size=96 --noise_std=0.06770345190281495
2022-07-12 11:46:30 INFO Running runs: ['aof0lxhw']
2022-07-12 11:46:41 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 11:46:41 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 11:46:48 INFO Running runs: []
2022-07-12 11:46:49 INFO Agent received command: run
2022-07-12 11:46:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5814480254748986
	max_bin: 246
	max_depth: 30
	min_data_in_leaf: 15
	num_iterations: 120
	num_leaves: 39
2022-07-12 11:46:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.5814480254748986 --max_bin=246 --max_depth=30 --min_data_in_leaf=15 --num_iterations=120 --num_leaves=39
2022-07-12 11:46:54 INFO Running runs: ['cumjsx7s']
2022-07-12 11:47:05 INFO Cleaning up finished run: cumjsx7s
2022-07-12 11:47:05 INFO Agent received command: run
2022-07-12 11:47:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.33970226370886414
	max_bin: 116
	max_depth: 22
	min_data_in_leaf: 23
	num_iterations: 520
	num_leaves: 28
2022-07-12 11:47:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.33970226370886414 --max_bin=116 --max_depth=22 --min_data_in_leaf=23 --num_iterations=520 --num_leaves=28
2022-07-12 11:47:10 INFO Running runs: ['zosd2lmm']
2022-07-12 11:47:21 INFO Cleaning up finished run: zosd2lmm
2022-07-12 11:47:22 INFO Agent received command: run
2022-07-12 11:47:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6459064715245914
	max_bin: 16
	max_depth: 7
	min_data_in_leaf: 29
	num_iterations: 757
	num_leaves: 5
2022-07-12 11:47:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.6459064715245914 --max_bin=16 --max_depth=7 --min_data_in_leaf=29 --num_iterations=757 --num_leaves=5
2022-07-12 11:47:27 INFO Running runs: ['udisyg4y']
2022-07-12 11:47:38 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 11:47:38 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 11:47:45 INFO Running runs: []
2022-07-12 11:47:46 INFO Agent received command: run
2022-07-12 11:47:46 INFO Agent starting run with config:
	batch_size: 8
	d_model: 37
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.20003079228285128
	embedding_layers: 4
	embedding_size: 123
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.0001
	max_steps: 1817
	net_layers: 3
	net_size: 108
	noise_std: 0.14128505645967818
2022-07-12 11:47:46 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=8 --d_model=37 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.20003079228285128 --embedding_layers=4 --embedding_size=123 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.0001 --max_steps=1817 --net_layers=3 --net_size=108 --noise_std=0.14128505645967818
2022-07-12 11:47:51 INFO Running runs: ['x5mpckk1']
2022-07-12 11:48:02 INFO Cleaning up finished run: x5mpckk1
2022-07-12 11:48:02 INFO Agent received command: run
2022-07-12 11:48:02 INFO Agent starting run with config:
	batch_size: 4
	d_model: 15
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.1942299546961609
	embedding_layers: 1
	embedding_size: 98
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.0005
	max_steps: 3847
	net_layers: 3
	net_size: 66
	noise_std: 0.3493671420217029
2022-07-12 11:48:02 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=4 --d_model=15 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.1942299546961609 --embedding_layers=1 --embedding_size=98 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.0005 --max_steps=3847 --net_layers=3 --net_size=66 --noise_std=0.3493671420217029
2022-07-12 11:48:07 INFO Running runs: ['er68sdax']
2022-07-12 11:48:18 INFO Cleaning up finished run: er68sdax
2022-07-12 11:48:19 INFO Agent received command: run
2022-07-12 11:48:19 INFO Agent starting run with config:
	batch_size: 128
	d_model: 97
	decoder_heads: 5
	decoder_layers: 8
	early_stopping: 0.8900235391846828
	embedding_layers: 1
	embedding_size: 16
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 2935
	net_layers: 1
	net_size: 119
	noise_std: 1.4088489710232186
2022-07-12 11:48:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=128 --d_model=97 --decoder_heads=5 --decoder_layers=8 --early_stopping=0.8900235391846828 --embedding_layers=1 --embedding_size=16 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.0001 --max_steps=2935 --net_layers=1 --net_size=119 --noise_std=1.4088489710232186
2022-07-12 11:48:24 INFO Running runs: ['scyv1g4t']
2022-07-12 11:48:34 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 11:48:34 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 11:48:42 INFO Running runs: []
2022-07-12 11:48:42 INFO Agent received command: run
2022-07-12 11:48:42 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6200701046401197
	max_bin: 47
	max_depth: 15
	min_data_in_leaf: 17
	num_iterations: 388
	num_leaves: 31
2022-07-12 11:48:42 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.6200701046401197 --max_bin=47 --max_depth=15 --min_data_in_leaf=17 --num_iterations=388 --num_leaves=31
2022-07-12 11:48:48 INFO Running runs: ['kegtngs7']
2022-07-12 11:48:58 INFO Cleaning up finished run: kegtngs7
2022-07-12 11:48:59 INFO Agent received command: run
2022-07-12 11:48:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6849355318748948
	max_bin: 52
	max_depth: 24
	min_data_in_leaf: 28
	num_iterations: 952
	num_leaves: 6
2022-07-12 11:48:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.6849355318748948 --max_bin=52 --max_depth=24 --min_data_in_leaf=28 --num_iterations=952 --num_leaves=6
2022-07-12 11:49:04 INFO Running runs: ['gljfaanb']
2022-07-12 11:49:26 INFO Cleaning up finished run: gljfaanb
2022-07-12 11:49:26 INFO Agent received command: run
2022-07-12 11:49:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.11955592681336236
	max_bin: 235
	max_depth: 8
	min_data_in_leaf: 14
	num_iterations: 930
	num_leaves: 40
2022-07-12 11:49:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.11955592681336236 --max_bin=235 --max_depth=8 --min_data_in_leaf=14 --num_iterations=930 --num_leaves=40
2022-07-12 11:49:31 INFO Running runs: ['ix721ns8']
2022-07-12 11:49:42 INFO Cleaning up finished run: ix721ns8
2022-07-12 11:49:43 INFO Agent received command: run
2022-07-12 11:49:43 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.436986814186016
	max_bin: 14
	max_depth: 31
	min_data_in_leaf: 12
	num_iterations: 146
	num_leaves: 18
2022-07-12 11:49:43 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.436986814186016 --max_bin=14 --max_depth=31 --min_data_in_leaf=12 --num_iterations=146 --num_leaves=18
2022-07-12 11:49:48 INFO Running runs: ['zi8pi6ak']
2022-07-12 11:49:58 INFO Cleaning up finished run: zi8pi6ak
2022-07-12 11:49:59 INFO Agent received command: run
2022-07-12 11:49:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9149364057617598
	max_bin: 254
	max_depth: 23
	min_data_in_leaf: 29
	num_iterations: 649
	num_leaves: 6
2022-07-12 11:49:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.9149364057617598 --max_bin=254 --max_depth=23 --min_data_in_leaf=29 --num_iterations=649 --num_leaves=6
2022-07-12 11:50:04 INFO Running runs: ['fhszr8nj']
2022-07-12 11:50:15 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:50:15 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:50:22 INFO Running runs: []
2022-07-12 11:50:23 INFO Agent received command: run
2022-07-12 11:50:23 INFO Agent starting run with config:
	batch_size: 32
	d_model: 19
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.5917409549218936
	embedding_layers: 2
	embedding_size: 34
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 2366
	net_layers: 2
	net_size: 120
	noise_std: 0.6222786458141811
2022-07-12 11:50:23 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=32 --d_model=19 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.5917409549218936 --embedding_layers=2 --embedding_size=34 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.0005 --max_steps=2366 --net_layers=2 --net_size=120 --noise_std=0.6222786458141811
2022-07-12 11:50:28 INFO Running runs: ['oqnexy4i']
2022-07-12 11:50:39 INFO Cleaning up finished run: oqnexy4i
2022-07-12 11:50:39 INFO Agent received command: run
2022-07-12 11:50:39 INFO Agent starting run with config:
	batch_size: 64
	d_model: 122
	decoder_heads: 5
	decoder_layers: 7
	early_stopping: 0.5932527153047668
	embedding_layers: 2
	embedding_size: 104
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.0001
	max_steps: 4676
	net_layers: 1
	net_size: 55
	noise_std: 1.096951868563651
2022-07-12 11:50:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=64 --d_model=122 --decoder_heads=5 --decoder_layers=7 --early_stopping=0.5932527153047668 --embedding_layers=2 --embedding_size=104 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.0001 --max_steps=4676 --net_layers=1 --net_size=55 --noise_std=1.096951868563651
2022-07-12 11:50:44 INFO Running runs: ['rxrcwykl']
2022-07-12 11:50:55 INFO Cleaning up finished run: rxrcwykl
2022-07-12 11:50:56 INFO Agent received command: run
2022-07-12 11:50:56 INFO Agent starting run with config:
	batch_size: 4
	d_model: 117
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.9595783506228878
	embedding_layers: 2
	embedding_size: 9
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 1009
	net_layers: 4
	net_size: 25
	noise_std: 0.7153770505465332
2022-07-12 11:50:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=4 --d_model=117 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.9595783506228878 --embedding_layers=2 --embedding_size=9 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.001 --max_steps=1009 --net_layers=4 --net_size=25 --noise_std=0.7153770505465332
2022-07-12 11:51:01 INFO Running runs: ['59ob5m0i']
2022-07-12 11:51:17 INFO Cleaning up finished run: 59ob5m0i
2022-07-12 11:51:17 INFO Agent received command: run
2022-07-12 11:51:17 INFO Agent starting run with config:
	batch_size: 16
	d_model: 9
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.14860172682914685
	embedding_layers: 2
	embedding_size: 108
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.001
	max_steps: 4719
	net_layers: 3
	net_size: 119
	noise_std: 0.6003300202921545
2022-07-12 11:51:17 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=16 --d_model=9 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.14860172682914685 --embedding_layers=2 --embedding_size=108 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.001 --max_steps=4719 --net_layers=3 --net_size=119 --noise_std=0.6003300202921545
2022-07-12 11:51:22 INFO Running runs: ['t08rx9pg']
2022-07-12 11:51:39 INFO Cleaning up finished run: t08rx9pg
2022-07-12 11:51:39 INFO Agent received command: run
2022-07-12 11:51:39 INFO Agent starting run with config:
	batch_size: 32
	d_model: 46
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.5715674484462332
	embedding_layers: 3
	embedding_size: 107
	encoder_heads: 5
	encoder_layers: 7
	learning_rate: 0.0005
	max_steps: 3315
	net_layers: 4
	net_size: 45
	noise_std: 0.8678839255144771
2022-07-12 11:51:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=32 --d_model=46 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.5715674484462332 --embedding_layers=3 --embedding_size=107 --encoder_heads=5 --encoder_layers=7 --learning_rate=0.0005 --max_steps=3315 --net_layers=4 --net_size=45 --noise_std=0.8678839255144771
2022-07-12 11:51:44 INFO Running runs: ['a4yviwdu']
2022-07-12 11:51:55 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:51:55 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:52:03 INFO Running runs: []
2022-07-12 11:52:04 INFO Agent received command: run
2022-07-12 11:52:04 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3647720040131933
	max_bin: 43
	max_depth: 21
	min_data_in_leaf: 25
	num_iterations: 795
	num_leaves: 23
2022-07-12 11:52:04 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.3647720040131933 --max_bin=43 --max_depth=21 --min_data_in_leaf=25 --num_iterations=795 --num_leaves=23
2022-07-12 11:52:09 INFO Running runs: ['rotv2jaj']
2022-07-12 11:52:20 INFO Cleaning up finished run: rotv2jaj
2022-07-12 11:52:20 INFO Agent received command: run
2022-07-12 11:52:20 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3118643739933007
	max_bin: 53
	max_depth: 26
	min_data_in_leaf: 10
	num_iterations: 399
	num_leaves: 12
2022-07-12 11:52:20 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.3118643739933007 --max_bin=53 --max_depth=26 --min_data_in_leaf=10 --num_iterations=399 --num_leaves=12
2022-07-12 11:52:25 INFO Running runs: ['xicq4fbe']
2022-07-12 11:52:36 INFO Cleaning up finished run: xicq4fbe
2022-07-12 11:52:36 INFO Agent received command: run
2022-07-12 11:52:36 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9597361677099084
	max_bin: 239
	max_depth: 11
	min_data_in_leaf: 10
	num_iterations: 201
	num_leaves: 36
2022-07-12 11:52:36 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.9597361677099084 --max_bin=239 --max_depth=11 --min_data_in_leaf=10 --num_iterations=201 --num_leaves=36
2022-07-12 11:52:41 INFO Running runs: ['z3hwt6ol']
2022-07-12 11:52:52 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 11:52:52 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 11:53:00 INFO Running runs: []
2022-07-12 11:53:00 INFO Agent received command: run
2022-07-12 11:53:00 INFO Agent starting run with config:
	batch_size: 16
	d_model: 10
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.39710532388303577
	embedding_layers: 2
	embedding_size: 59
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 2099
	net_layers: 1
	net_size: 45
	noise_std: 0.7629240973660576
2022-07-12 11:53:00 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=16 --d_model=10 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.39710532388303577 --embedding_layers=2 --embedding_size=59 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0005 --max_steps=2099 --net_layers=1 --net_size=45 --noise_std=0.7629240973660576
2022-07-12 11:53:05 INFO Running runs: ['5nq3kz49']
2022-07-12 11:53:16 INFO Cleaning up finished run: 5nq3kz49
2022-07-12 11:53:17 INFO Agent received command: run
2022-07-12 11:53:17 INFO Agent starting run with config:
	batch_size: 4
	d_model: 72
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.9375919732716804
	embedding_layers: 4
	embedding_size: 107
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 1251
	net_layers: 1
	net_size: 125
	noise_std: 0.9121547383181028
2022-07-12 11:53:17 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=4 --d_model=72 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.9375919732716804 --embedding_layers=4 --embedding_size=107 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.0005 --max_steps=1251 --net_layers=1 --net_size=125 --noise_std=0.9121547383181028
2022-07-12 11:53:22 INFO Running runs: ['9029bhnu']
2022-07-12 11:53:38 INFO Cleaning up finished run: 9029bhnu
2022-07-12 11:53:39 INFO Agent received command: run
2022-07-12 11:53:39 INFO Agent starting run with config:
	batch_size: 16
	d_model: 128
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.5217967353934289
	embedding_layers: 2
	embedding_size: 21
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 4268
	net_layers: 4
	net_size: 33
	noise_std: 1.4886274384666045
2022-07-12 11:53:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=16 --d_model=128 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.5217967353934289 --embedding_layers=2 --embedding_size=21 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.001 --max_steps=4268 --net_layers=4 --net_size=33 --noise_std=1.4886274384666045
2022-07-12 11:53:44 INFO Running runs: ['4ax62dgc']
2022-07-12 11:53:54 INFO Cleaning up finished run: 4ax62dgc
2022-07-12 11:53:55 INFO Agent received command: run
2022-07-12 11:53:55 INFO Agent starting run with config:
	batch_size: 4
	d_model: 126
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.7559305342472014
	embedding_layers: 4
	embedding_size: 104
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 1749
	net_layers: 2
	net_size: 75
	noise_std: 0.04135048425568367
2022-07-12 11:53:55 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=4 --d_model=126 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.7559305342472014 --embedding_layers=4 --embedding_size=104 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.0001 --max_steps=1749 --net_layers=2 --net_size=75 --noise_std=0.04135048425568367
2022-07-12 11:54:00 INFO Running runs: ['b9h6aqz2']
2022-07-12 11:54:16 INFO Cleaning up finished run: b9h6aqz2
2022-07-12 11:54:17 INFO Agent received command: run
2022-07-12 11:54:17 INFO Agent starting run with config:
	batch_size: 16
	d_model: 22
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.3599539520127948
	embedding_layers: 2
	embedding_size: 99
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 1264
	net_layers: 1
	net_size: 110
	noise_std: 0.029657899441909108
2022-07-12 11:54:17 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=16 --d_model=22 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.3599539520127948 --embedding_layers=2 --embedding_size=99 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0005 --max_steps=1264 --net_layers=1 --net_size=110 --noise_std=0.029657899441909108
2022-07-12 11:54:22 INFO Running runs: ['t9p31lo4']
2022-07-12 11:54:33 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:54:33 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:54:41 INFO Running runs: []
2022-07-12 11:54:41 INFO Agent received command: run
2022-07-12 11:54:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.14745902363116636
	max_bin: 249
	max_depth: 10
	min_data_in_leaf: 19
	num_iterations: 285
	num_leaves: 19
2022-07-12 11:54:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.14745902363116636 --max_bin=249 --max_depth=10 --min_data_in_leaf=19 --num_iterations=285 --num_leaves=19
2022-07-12 11:54:46 INFO Running runs: ['68rssici']
2022-07-12 11:54:57 INFO Cleaning up finished run: 68rssici
2022-07-12 11:54:57 INFO Agent received command: run
2022-07-12 11:54:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6888588058338613
	max_bin: 250
	max_depth: 22
	min_data_in_leaf: 26
	num_iterations: 375
	num_leaves: 28
2022-07-12 11:54:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.6888588058338613 --max_bin=250 --max_depth=22 --min_data_in_leaf=26 --num_iterations=375 --num_leaves=28
2022-07-12 11:55:02 INFO Running runs: ['8opnbo0v']
2022-07-12 11:55:18 INFO Cleaning up finished run: 8opnbo0v
2022-07-12 11:55:19 INFO Agent received command: run
2022-07-12 11:55:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9645558633276616
	max_bin: 45
	max_depth: 7
	min_data_in_leaf: 10
	num_iterations: 928
	num_leaves: 32
2022-07-12 11:55:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.9645558633276616 --max_bin=45 --max_depth=7 --min_data_in_leaf=10 --num_iterations=928 --num_leaves=32
2022-07-12 11:55:24 INFO Running runs: ['d71tfs1a']
2022-07-12 11:55:40 INFO Cleaning up finished run: d71tfs1a
2022-07-12 11:55:41 INFO Agent received command: run
2022-07-12 11:55:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.20894370624619052
	max_bin: 85
	max_depth: 27
	min_data_in_leaf: 13
	num_iterations: 455
	num_leaves: 9
2022-07-12 11:55:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.20894370624619052 --max_bin=85 --max_depth=27 --min_data_in_leaf=13 --num_iterations=455 --num_leaves=9
2022-07-12 11:55:46 INFO Running runs: ['fmgkdhuy']
2022-07-12 11:55:56 INFO Cleaning up finished run: fmgkdhuy
2022-07-12 11:56:02 INFO Agent received command: run
2022-07-12 11:56:02 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.01928093457912128
	max_bin: 45
	max_depth: 8
	min_data_in_leaf: 17
	num_iterations: 269
	num_leaves: 16
2022-07-12 11:56:02 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.01928093457912128 --max_bin=45 --max_depth=8 --min_data_in_leaf=17 --num_iterations=269 --num_leaves=16
2022-07-12 11:56:07 INFO Running runs: ['atu2f697']
2022-07-12 11:56:18 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:56:18 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:56:26 INFO Running runs: []
2022-07-12 11:56:26 INFO Agent received command: run
2022-07-12 11:56:26 INFO Agent starting run with config:
	batch_size: 128
	d_model: 98
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.21061341937864375
	embedding_layers: 4
	embedding_size: 56
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0001
	max_steps: 1800
	net_layers: 1
	net_size: 31
	noise_std: 0.013526268613981415
2022-07-12 11:56:26 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=128 --d_model=98 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.21061341937864375 --embedding_layers=4 --embedding_size=56 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0001 --max_steps=1800 --net_layers=1 --net_size=31 --noise_std=0.013526268613981415
2022-07-12 11:56:31 INFO Running runs: ['le2rrxw8']
2022-07-12 11:56:42 INFO Cleaning up finished run: le2rrxw8
2022-07-12 11:56:42 INFO Agent received command: run
2022-07-12 11:56:42 INFO Agent starting run with config:
	batch_size: 64
	d_model: 128
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.4098717829915184
	embedding_layers: 2
	embedding_size: 45
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 4452
	net_layers: 2
	net_size: 55
	noise_std: 0.09085979326964068
2022-07-12 11:56:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=64 --d_model=128 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.4098717829915184 --embedding_layers=2 --embedding_size=45 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0005 --max_steps=4452 --net_layers=2 --net_size=55 --noise_std=0.09085979326964068
2022-07-12 11:56:47 INFO Running runs: ['oc02nb1u']
2022-07-12 11:56:58 INFO Cleaning up finished run: oc02nb1u
2022-07-12 11:56:59 INFO Agent received command: run
2022-07-12 11:56:59 INFO Agent starting run with config:
	batch_size: 4
	d_model: 35
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.5100071043115318
	embedding_layers: 1
	embedding_size: 118
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 4136
	net_layers: 4
	net_size: 110
	noise_std: 1.2780123409620523
2022-07-12 11:56:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=4 --d_model=35 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.5100071043115318 --embedding_layers=1 --embedding_size=118 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.001 --max_steps=4136 --net_layers=4 --net_size=110 --noise_std=1.2780123409620523
2022-07-12 11:57:04 INFO Running runs: ['o479ttk1']
2022-07-12 11:57:15 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 11:57:15 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 11:57:22 INFO Running runs: []
2022-07-12 11:57:26 INFO Agent received command: run
2022-07-12 11:57:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.42534160362139894
	max_bin: 98
	max_depth: 10
	min_data_in_leaf: 30
	num_iterations: 174
	num_leaves: 21
2022-07-12 11:57:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.42534160362139894 --max_bin=98 --max_depth=10 --min_data_in_leaf=30 --num_iterations=174 --num_leaves=21
2022-07-12 11:57:31 INFO Running runs: ['xglrnaki']
2022-07-12 11:57:42 INFO Cleaning up finished run: xglrnaki
2022-07-12 11:57:42 INFO Agent received command: run
2022-07-12 11:57:42 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.22929613211795088
	max_bin: 251
	max_depth: 28
	min_data_in_leaf: 17
	num_iterations: 481
	num_leaves: 24
2022-07-12 11:57:42 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.22929613211795088 --max_bin=251 --max_depth=28 --min_data_in_leaf=17 --num_iterations=481 --num_leaves=24
2022-07-12 11:57:47 INFO Running runs: ['8vecb02i']
2022-07-12 11:57:58 INFO Cleaning up finished run: 8vecb02i
2022-07-12 11:57:59 INFO Agent received command: run
2022-07-12 11:57:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5851893280232279
	max_bin: 152
	max_depth: 30
	min_data_in_leaf: 10
	num_iterations: 981
	num_leaves: 14
2022-07-12 11:57:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.5851893280232279 --max_bin=152 --max_depth=30 --min_data_in_leaf=10 --num_iterations=981 --num_leaves=14
2022-07-12 11:58:04 INFO Running runs: ['jnrt4nw4']
2022-07-12 11:58:20 INFO Cleaning up finished run: jnrt4nw4
2022-07-12 11:58:21 INFO Agent received command: run
2022-07-12 11:58:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6960962487564075
	max_bin: 92
	max_depth: 18
	min_data_in_leaf: 14
	num_iterations: 589
	num_leaves: 39
2022-07-12 11:58:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.6960962487564075 --max_bin=92 --max_depth=18 --min_data_in_leaf=14 --num_iterations=589 --num_leaves=39
2022-07-12 11:58:26 INFO Running runs: ['d6b7o18m']
2022-07-12 11:58:42 INFO Cleaning up finished run: d6b7o18m
2022-07-12 11:58:42 INFO Agent received command: run
2022-07-12 11:58:42 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9763257429650624
	max_bin: 64
	max_depth: 17
	min_data_in_leaf: 30
	num_iterations: 140
	num_leaves: 10
2022-07-12 11:58:42 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.9763257429650624 --max_bin=64 --max_depth=17 --min_data_in_leaf=30 --num_iterations=140 --num_leaves=10
2022-07-12 11:58:47 INFO Running runs: ['zvhl0vel']
2022-07-12 11:58:59 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 11:58:59 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 11:59:06 INFO Running runs: []
2022-07-12 11:59:07 INFO Agent received command: run
2022-07-12 11:59:07 INFO Agent starting run with config:
	batch_size: 4
	d_model: 27
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.07863013588749024
	embedding_layers: 2
	embedding_size: 50
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 1156
	net_layers: 4
	net_size: 94
	noise_std: 0.4676546305166864
2022-07-12 11:59:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=4 --d_model=27 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.07863013588749024 --embedding_layers=2 --embedding_size=50 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001 --max_steps=1156 --net_layers=4 --net_size=94 --noise_std=0.4676546305166864
2022-07-12 11:59:12 INFO Running runs: ['6n47tua6']
2022-07-12 11:59:33 INFO Cleaning up finished run: 6n47tua6
2022-07-12 11:59:34 INFO Agent received command: run
2022-07-12 11:59:34 INFO Agent starting run with config:
	batch_size: 64
	d_model: 128
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.3099777169091198
	embedding_layers: 1
	embedding_size: 119
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.0001
	max_steps: 1388
	net_layers: 2
	net_size: 43
	noise_std: 0.7981969047393782
2022-07-12 11:59:34 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=64 --d_model=128 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.3099777169091198 --embedding_layers=1 --embedding_size=119 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.0001 --max_steps=1388 --net_layers=2 --net_size=43 --noise_std=0.7981969047393782
2022-07-12 11:59:39 INFO Running runs: ['b9s0oe9f']
2022-07-12 11:59:50 INFO Cleaning up finished run: b9s0oe9f
2022-07-12 11:59:51 INFO Agent received command: run
2022-07-12 11:59:51 INFO Agent starting run with config:
	batch_size: 8
	d_model: 111
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.9257303365435008
	embedding_layers: 4
	embedding_size: 92
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.001
	max_steps: 5000
	net_layers: 1
	net_size: 9
	noise_std: 0.811593352789152
2022-07-12 11:59:51 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=8 --d_model=111 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.9257303365435008 --embedding_layers=4 --embedding_size=92 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.001 --max_steps=5000 --net_layers=1 --net_size=9 --noise_std=0.811593352789152
2022-07-12 11:59:56 INFO Running runs: ['9id83r3x']
2022-07-12 12:00:06 INFO Cleaning up finished run: 9id83r3x
2022-07-12 12:00:07 INFO Agent received command: run
2022-07-12 12:00:07 INFO Agent starting run with config:
	batch_size: 8
	d_model: 34
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.7590207275775492
	embedding_layers: 3
	embedding_size: 32
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.001
	max_steps: 3842
	net_layers: 4
	net_size: 124
	noise_std: 0.9328849219018092
2022-07-12 12:00:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=8 --d_model=34 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.7590207275775492 --embedding_layers=3 --embedding_size=32 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.001 --max_steps=3842 --net_layers=4 --net_size=124 --noise_std=0.9328849219018092
2022-07-12 12:00:12 INFO Running runs: ['2hcstrkj']
2022-07-12 12:00:23 INFO Cleaning up finished run: 2hcstrkj
2022-07-12 12:00:24 INFO Agent received command: run
2022-07-12 12:00:24 INFO Agent starting run with config:
	batch_size: 4
	d_model: 122
	decoder_heads: 1
	decoder_layers: 6
	early_stopping: 0.9556531014373146
	embedding_layers: 3
	embedding_size: 76
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.0005
	max_steps: 4953
	net_layers: 1
	net_size: 114
	noise_std: 1.2998332161704198
2022-07-12 12:00:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=4 --d_model=122 --decoder_heads=1 --decoder_layers=6 --early_stopping=0.9556531014373146 --embedding_layers=3 --embedding_size=76 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.0005 --max_steps=4953 --net_layers=1 --net_size=114 --noise_std=1.2998332161704198
2022-07-12 12:00:29 INFO Running runs: ['q26fi4ce']
2022-07-12 12:00:45 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 12:00:45 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 12:00:52 INFO Running runs: []
2022-07-12 12:00:53 INFO Agent received command: run
2022-07-12 12:00:53 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6145394003520136
	max_bin: 239
	max_depth: 27
	min_data_in_leaf: 12
	num_iterations: 835
	num_leaves: 12
2022-07-12 12:00:53 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.6145394003520136 --max_bin=239 --max_depth=27 --min_data_in_leaf=12 --num_iterations=835 --num_leaves=12
2022-07-12 12:00:58 INFO Running runs: ['rk9l1jn6']
2022-07-12 12:01:14 INFO Cleaning up finished run: rk9l1jn6
2022-07-12 12:01:15 INFO Agent received command: run
2022-07-12 12:01:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.37809223531891434
	max_bin: 26
	max_depth: 6
	min_data_in_leaf: 21
	num_iterations: 445
	num_leaves: 22
2022-07-12 12:01:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.37809223531891434 --max_bin=26 --max_depth=6 --min_data_in_leaf=21 --num_iterations=445 --num_leaves=22
2022-07-12 12:01:20 INFO Running runs: ['vh91714p']
2022-07-12 12:01:36 INFO Cleaning up finished run: vh91714p
2022-07-12 12:01:37 INFO Agent received command: run
2022-07-12 12:01:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8694657588530449
	max_bin: 224
	max_depth: 5
	min_data_in_leaf: 11
	num_iterations: 308
	num_leaves: 36
2022-07-12 12:01:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.8694657588530449 --max_bin=224 --max_depth=5 --min_data_in_leaf=11 --num_iterations=308 --num_leaves=36
2022-07-12 12:01:42 INFO Running runs: ['yjt4st4i']
2022-07-12 12:01:53 INFO Cleaning up finished run: yjt4st4i
2022-07-12 12:01:53 INFO Agent received command: run
2022-07-12 12:01:53 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.3919827762797805
	max_bin: 41
	max_depth: 6
	min_data_in_leaf: 29
	num_iterations: 576
	num_leaves: 6
2022-07-12 12:01:53 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.3919827762797805 --max_bin=41 --max_depth=6 --min_data_in_leaf=29 --num_iterations=576 --num_leaves=6
2022-07-12 12:01:58 INFO Running runs: ['8ugyjxcp']
2022-07-12 12:02:09 INFO Cleaning up finished run: 8ugyjxcp
2022-07-12 12:02:10 INFO Agent received command: run
2022-07-12 12:02:10 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6367577437491155
	max_bin: 149
	max_depth: 17
	min_data_in_leaf: 12
	num_iterations: 592
	num_leaves: 26
2022-07-12 12:02:10 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.6367577437491155 --max_bin=149 --max_depth=17 --min_data_in_leaf=12 --num_iterations=592 --num_leaves=26
2022-07-12 12:02:15 INFO Running runs: ['jxq8cge2']
2022-07-12 12:02:31 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 12:02:31 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 12:02:39 INFO Running runs: []
2022-07-12 12:02:39 INFO Agent received command: run
2022-07-12 12:02:39 INFO Agent starting run with config:
	batch_size: 16
	d_model: 21
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.3365165498759912
	embedding_layers: 3
	embedding_size: 19
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 2703
	net_layers: 2
	net_size: 62
	noise_std: 0.4656392865548587
2022-07-12 12:02:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=16 --d_model=21 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.3365165498759912 --embedding_layers=3 --embedding_size=19 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0005 --max_steps=2703 --net_layers=2 --net_size=62 --noise_std=0.4656392865548587
2022-07-12 12:02:44 INFO Running runs: ['5g4s7dx8']
2022-07-12 12:02:55 INFO Cleaning up finished run: 5g4s7dx8
2022-07-12 12:02:55 INFO Agent received command: run
2022-07-12 12:02:55 INFO Agent starting run with config:
	batch_size: 8
	d_model: 41
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.4026232629758081
	embedding_layers: 2
	embedding_size: 120
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 3790
	net_layers: 2
	net_size: 83
	noise_std: 1.124192242032791
2022-07-12 12:02:55 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=8 --d_model=41 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.4026232629758081 --embedding_layers=2 --embedding_size=120 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0001 --max_steps=3790 --net_layers=2 --net_size=83 --noise_std=1.124192242032791
2022-07-12 12:03:01 INFO Running runs: ['xach412u']
2022-07-12 12:03:11 INFO Cleaning up finished run: xach412u
2022-07-12 12:03:12 INFO Agent received command: run
2022-07-12 12:03:12 INFO Agent starting run with config:
	batch_size: 32
	d_model: 113
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.8111904514787565
	embedding_layers: 1
	embedding_size: 126
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 4646
	net_layers: 2
	net_size: 41
	noise_std: 0.21402586932376752
2022-07-12 12:03:12 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=32 --d_model=113 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.8111904514787565 --embedding_layers=1 --embedding_size=126 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.001 --max_steps=4646 --net_layers=2 --net_size=41 --noise_std=0.21402586932376752
2022-07-12 12:03:17 INFO Running runs: ['p1w9c9vb']
2022-07-12 12:03:33 INFO Cleaning up finished run: p1w9c9vb
2022-07-12 12:03:34 INFO Agent received command: run
2022-07-12 12:03:34 INFO Agent starting run with config:
	batch_size: 128
	d_model: 23
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.7313622953852432
	embedding_layers: 3
	embedding_size: 68
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 3032
	net_layers: 1
	net_size: 63
	noise_std: 0.8877786002720358
2022-07-12 12:03:34 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=128 --d_model=23 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.7313622953852432 --embedding_layers=3 --embedding_size=68 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.0001 --max_steps=3032 --net_layers=1 --net_size=63 --noise_std=0.8877786002720358
2022-07-12 12:03:39 INFO Running runs: ['b5ai29nc']
2022-07-12 12:03:50 INFO Cleaning up finished run: b5ai29nc
2022-07-12 12:03:51 INFO Agent received command: run
2022-07-12 12:03:51 INFO Agent starting run with config:
	batch_size: 128
	d_model: 19
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.3346409095260673
	embedding_layers: 2
	embedding_size: 75
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001
	max_steps: 3327
	net_layers: 1
	net_size: 58
	noise_std: 1.375275305863363
2022-07-12 12:03:51 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=128 --d_model=19 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.3346409095260673 --embedding_layers=2 --embedding_size=75 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001 --max_steps=3327 --net_layers=1 --net_size=58 --noise_std=1.375275305863363
2022-07-12 12:03:56 INFO Running runs: ['ske1n2am']
2022-07-12 12:04:07 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 12:04:07 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 12:04:14 INFO Running runs: []
2022-07-12 12:04:15 INFO Agent received command: run
2022-07-12 12:04:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.018206907381068116
	max_bin: 191
	max_depth: 10
	min_data_in_leaf: 27
	num_iterations: 943
	num_leaves: 39
2022-07-12 12:04:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.018206907381068116 --max_bin=191 --max_depth=10 --min_data_in_leaf=27 --num_iterations=943 --num_leaves=39
2022-07-12 12:04:20 INFO Running runs: ['inv6wy8g']
2022-07-12 12:04:31 INFO Cleaning up finished run: inv6wy8g
2022-07-12 12:04:31 INFO Agent received command: run
2022-07-12 12:04:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.16358642963358205
	max_bin: 80
	max_depth: 29
	min_data_in_leaf: 18
	num_iterations: 494
	num_leaves: 7
2022-07-12 12:04:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.16358642963358205 --max_bin=80 --max_depth=29 --min_data_in_leaf=18 --num_iterations=494 --num_leaves=7
2022-07-12 12:04:36 INFO Running runs: ['3rgs9rod']
2022-07-12 12:04:47 INFO Cleaning up finished run: 3rgs9rod
2022-07-12 12:04:47 INFO Agent received command: run
2022-07-12 12:04:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.836505375527373
	max_bin: 222
	max_depth: 31
	min_data_in_leaf: 12
	num_iterations: 102
	num_leaves: 37
2022-07-12 12:04:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.836505375527373 --max_bin=222 --max_depth=31 --min_data_in_leaf=12 --num_iterations=102 --num_leaves=37
2022-07-12 12:04:52 INFO Running runs: ['4mz9z5u2']
2022-07-12 12:05:03 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 12:05:03 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 12:05:11 INFO Running runs: []
2022-07-12 12:05:12 INFO Agent received command: run
2022-07-12 12:05:12 INFO Agent starting run with config:
	batch_size: 4
	d_model: 47
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.3794717453219596
	embedding_layers: 1
	embedding_size: 97
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 2443
	net_layers: 4
	net_size: 126
	noise_std: 0.4639125051486676
2022-07-12 12:05:12 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=4 --d_model=47 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.3794717453219596 --embedding_layers=1 --embedding_size=97 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.001 --max_steps=2443 --net_layers=4 --net_size=126 --noise_std=0.4639125051486676
2022-07-12 12:05:17 INFO Running runs: ['trzrfoig']
2022-07-12 12:05:27 INFO Cleaning up finished run: trzrfoig
2022-07-12 12:05:28 INFO Agent received command: run
2022-07-12 12:05:28 INFO Agent starting run with config:
	batch_size: 8
	d_model: 40
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.5003868836467164
	embedding_layers: 2
	embedding_size: 26
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 2258
	net_layers: 1
	net_size: 44
	noise_std: 0.08489962710732515
2022-07-12 12:05:28 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=8 --d_model=40 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.5003868836467164 --embedding_layers=2 --embedding_size=26 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0005 --max_steps=2258 --net_layers=1 --net_size=44 --noise_std=0.08489962710732515
2022-07-12 12:05:33 INFO Running runs: ['jfuth1jz']
2022-07-12 12:05:44 INFO Cleaning up finished run: jfuth1jz
2022-07-12 12:05:44 INFO Agent received command: run
2022-07-12 12:05:44 INFO Agent starting run with config:
	batch_size: 128
	d_model: 72
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.8647939304062765
	embedding_layers: 1
	embedding_size: 57
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.001
	max_steps: 4306
	net_layers: 1
	net_size: 10
	noise_std: 1.126774609069766
2022-07-12 12:05:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=128 --d_model=72 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.8647939304062765 --embedding_layers=1 --embedding_size=57 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.001 --max_steps=4306 --net_layers=1 --net_size=10 --noise_std=1.126774609069766
2022-07-12 12:05:49 INFO Running runs: ['41k5zclr']
2022-07-12 12:06:00 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 12:06:00 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 12:06:08 INFO Running runs: []
2022-07-12 12:06:09 INFO Agent received command: run
2022-07-12 12:06:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.13517012285691532
	max_bin: 242
	max_depth: 6
	min_data_in_leaf: 19
	num_iterations: 581
	num_leaves: 13
2022-07-12 12:06:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.13517012285691532 --max_bin=242 --max_depth=6 --min_data_in_leaf=19 --num_iterations=581 --num_leaves=13
2022-07-12 12:06:14 INFO Running runs: ['7xu6de6t']
2022-07-12 12:06:30 INFO Cleaning up finished run: 7xu6de6t
2022-07-12 12:06:31 INFO Agent received command: run
2022-07-12 12:06:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.5738511922730625
	max_bin: 21
	max_depth: 24
	min_data_in_leaf: 22
	num_iterations: 433
	num_leaves: 18
2022-07-12 12:06:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.5738511922730625 --max_bin=21 --max_depth=24 --min_data_in_leaf=22 --num_iterations=433 --num_leaves=18
2022-07-12 12:06:36 INFO Running runs: ['3kk91s5c']
2022-07-12 12:06:46 INFO Cleaning up finished run: 3kk91s5c
2022-07-12 12:06:47 INFO Agent received command: run
2022-07-12 12:06:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8121516665246203
	max_bin: 244
	max_depth: 4
	min_data_in_leaf: 12
	num_iterations: 922
	num_leaves: 36
2022-07-12 12:06:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.8121516665246203 --max_bin=244 --max_depth=4 --min_data_in_leaf=12 --num_iterations=922 --num_leaves=36
2022-07-12 12:06:52 INFO Running runs: ['wocuyeim']
2022-07-12 12:07:08 INFO Cleaning up finished run: wocuyeim
2022-07-12 12:07:09 INFO Agent received command: run
2022-07-12 12:07:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.02035199152140343
	max_bin: 7
	max_depth: 30
	min_data_in_leaf: 27
	num_iterations: 135
	num_leaves: 39
2022-07-12 12:07:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.02035199152140343 --max_bin=7 --max_depth=30 --min_data_in_leaf=27 --num_iterations=135 --num_leaves=39
2022-07-12 12:07:14 INFO Running runs: ['3jwvxjta']
2022-07-12 12:07:25 INFO Cleaning up finished run: 3jwvxjta
2022-07-12 12:07:26 INFO Agent received command: run
2022-07-12 12:07:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.631921914454545
	max_bin: 236
	max_depth: 32
	min_data_in_leaf: 12
	num_iterations: 380
	num_leaves: 18
2022-07-12 12:07:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.631921914454545 --max_bin=236 --max_depth=32 --min_data_in_leaf=12 --num_iterations=380 --num_leaves=18
2022-07-12 12:07:31 INFO Running runs: ['5atbqr4z']
2022-07-12 12:07:42 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 12:07:42 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 12:07:49 INFO Running runs: []
2022-07-12 12:07:50 INFO Agent received command: run
2022-07-12 12:07:50 INFO Agent starting run with config:
	batch_size: 64
	d_model: 38
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.6299895306543971
	embedding_layers: 4
	embedding_size: 44
	encoder_heads: 1
	encoder_layers: 7
	learning_rate: 0.0001
	max_steps: 2238
	net_layers: 1
	net_size: 115
	noise_std: 0.18774627484549777
2022-07-12 12:07:50 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=64 --d_model=38 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.6299895306543971 --embedding_layers=4 --embedding_size=44 --encoder_heads=1 --encoder_layers=7 --learning_rate=0.0001 --max_steps=2238 --net_layers=1 --net_size=115 --noise_std=0.18774627484549777
2022-07-12 12:07:55 INFO Running runs: ['b8a96kj8']
2022-07-12 12:08:05 INFO Cleaning up finished run: b8a96kj8
2022-07-12 12:08:06 INFO Agent received command: run
2022-07-12 12:08:06 INFO Agent starting run with config:
	batch_size: 16
	d_model: 20
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.1711787105767295
	embedding_layers: 4
	embedding_size: 28
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.0005
	max_steps: 4869
	net_layers: 2
	net_size: 78
	noise_std: 1.1083209513016288
2022-07-12 12:08:06 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=16 --d_model=20 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.1711787105767295 --embedding_layers=4 --embedding_size=28 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.0005 --max_steps=4869 --net_layers=2 --net_size=78 --noise_std=1.1083209513016288
2022-07-12 12:08:11 INFO Running runs: ['jgm0hhcq']
2022-07-12 12:08:22 INFO Cleaning up finished run: jgm0hhcq
2022-07-12 12:08:23 INFO Agent received command: run
2022-07-12 12:08:23 INFO Agent starting run with config:
	batch_size: 64
	d_model: 6
	decoder_heads: 1
	decoder_layers: 6
	early_stopping: 0.8276506061177954
	embedding_layers: 1
	embedding_size: 122
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.001
	max_steps: 3802
	net_layers: 3
	net_size: 90
	noise_std: 1.0890739329544783
2022-07-12 12:08:23 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=64 --d_model=6 --decoder_heads=1 --decoder_layers=6 --early_stopping=0.8276506061177954 --embedding_layers=1 --embedding_size=122 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.001 --max_steps=3802 --net_layers=3 --net_size=90 --noise_std=1.0890739329544783
2022-07-12 12:08:28 INFO Running runs: ['lff16rpi']
2022-07-12 12:08:38 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 12:08:38 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 12:08:46 INFO Running runs: []
2022-07-12 12:08:47 INFO Agent received command: run
2022-07-12 12:08:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.9615050817286488
	max_bin: 23
	max_depth: 7
	min_data_in_leaf: 17
	num_iterations: 180
	num_leaves: 36
2022-07-12 12:08:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.9615050817286488 --max_bin=23 --max_depth=7 --min_data_in_leaf=17 --num_iterations=180 --num_leaves=36
2022-07-12 12:08:52 INFO Running runs: ['y8tio4o3']
2022-07-12 12:09:08 INFO Cleaning up finished run: y8tio4o3
2022-07-12 12:09:09 INFO Agent received command: run
2022-07-12 12:09:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.4453537676651319
	max_bin: 244
	max_depth: 20
	min_data_in_leaf: 29
	num_iterations: 650
	num_leaves: 36
2022-07-12 12:09:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.4453537676651319 --max_bin=244 --max_depth=20 --min_data_in_leaf=29 --num_iterations=650 --num_leaves=36
2022-07-12 12:09:14 INFO Running runs: ['sz2zb895']
2022-07-12 12:09:24 INFO Cleaning up finished run: sz2zb895
2022-07-12 12:09:25 INFO Agent received command: run
2022-07-12 12:09:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.008057397456709192
	max_bin: 199
	max_depth: 8
	min_data_in_leaf: 24
	num_iterations: 887
	num_leaves: 13
2022-07-12 12:09:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.008057397456709192 --max_bin=199 --max_depth=8 --min_data_in_leaf=24 --num_iterations=887 --num_leaves=13
2022-07-12 12:09:30 INFO Running runs: ['fpwqh6u1']
2022-07-12 12:09:40 INFO Cleaning up finished run: fpwqh6u1
2022-07-12 12:09:41 INFO Agent received command: run
2022-07-12 12:09:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.7609223516526531
	max_bin: 219
	max_depth: 22
	min_data_in_leaf: 24
	num_iterations: 688
	num_leaves: 5
2022-07-12 12:09:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.7609223516526531 --max_bin=219 --max_depth=22 --min_data_in_leaf=24 --num_iterations=688 --num_leaves=5
2022-07-12 12:09:46 INFO Running runs: ['1d1qlhpg']
2022-07-12 12:09:57 INFO Cleaning up finished run: 1d1qlhpg
2022-07-12 12:09:57 INFO Agent received command: run
2022-07-12 12:09:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.383134347672492
	max_bin: 200
	max_depth: 25
	min_data_in_leaf: 21
	num_iterations: 754
	num_leaves: 34
2022-07-12 12:09:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.383134347672492 --max_bin=200 --max_depth=25 --min_data_in_leaf=21 --num_iterations=754 --num_leaves=34
2022-07-12 12:10:02 INFO Running runs: ['hczqg0iz']
2022-07-12 12:10:19 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-12 12:10:19 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-12 12:10:26 INFO Running runs: []
2022-07-12 12:10:27 INFO Agent received command: run
2022-07-12 12:10:27 INFO Agent starting run with config:
	batch_size: 16
	d_model: 54
	decoder_heads: 1
	decoder_layers: 6
	early_stopping: 0.9768587940783524
	embedding_layers: 1
	embedding_size: 110
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.0005
	max_steps: 1698
	net_layers: 4
	net_size: 86
	noise_std: 0.6373048962854456
2022-07-12 12:10:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=16 --d_model=54 --decoder_heads=1 --decoder_layers=6 --early_stopping=0.9768587940783524 --embedding_layers=1 --embedding_size=110 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.0005 --max_steps=1698 --net_layers=4 --net_size=86 --noise_std=0.6373048962854456
2022-07-12 12:10:32 INFO Running runs: ['uv6ppi88']
2022-07-12 12:10:42 INFO Cleaning up finished run: uv6ppi88
2022-07-12 12:10:43 INFO Agent received command: run
2022-07-12 12:10:43 INFO Agent starting run with config:
	batch_size: 16
	d_model: 5
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.8365437247240737
	embedding_layers: 2
	embedding_size: 11
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.0001
	max_steps: 2896
	net_layers: 2
	net_size: 123
	noise_std: 1.0774499202044645
2022-07-12 12:10:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=16 --d_model=5 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.8365437247240737 --embedding_layers=2 --embedding_size=11 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.0001 --max_steps=2896 --net_layers=2 --net_size=123 --noise_std=1.0774499202044645
2022-07-12 12:10:48 INFO Running runs: ['j0lwsncy']
2022-07-12 12:10:59 INFO Cleaning up finished run: j0lwsncy
2022-07-12 12:11:00 INFO Agent received command: run
2022-07-12 12:11:00 INFO Agent starting run with config:
	batch_size: 64
	d_model: 122
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.5496353952619737
	embedding_layers: 3
	embedding_size: 114
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0005
	max_steps: 3988
	net_layers: 1
	net_size: 30
	noise_std: 0.27787586099799566
2022-07-12 12:11:00 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --batch_size=64 --d_model=122 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.5496353952619737 --embedding_layers=3 --embedding_size=114 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0005 --max_steps=3988 --net_layers=1 --net_size=30 --noise_std=0.27787586099799566
2022-07-12 12:11:05 INFO Running runs: ['xhye28s5']
2022-07-12 12:11:15 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 12:11:15 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 12:11:23 INFO Running runs: []
2022-07-12 12:11:24 INFO Agent received command: run
2022-07-12 12:11:24 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.19134316649633676
	max_bin: 66
	max_depth: 24
	min_data_in_leaf: 24
	num_iterations: 830
	num_leaves: 37
2022-07-12 12:11:24 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.19134316649633676 --max_bin=66 --max_depth=24 --min_data_in_leaf=24 --num_iterations=830 --num_leaves=37
2022-07-12 12:11:29 INFO Running runs: ['6d59fskl']
2022-07-12 12:11:39 INFO Cleaning up finished run: 6d59fskl
2022-07-12 12:11:40 INFO Agent received command: run
2022-07-12 12:11:40 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8651882165699755
	max_bin: 109
	max_depth: 24
	min_data_in_leaf: 15
	num_iterations: 946
	num_leaves: 37
2022-07-12 12:11:40 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.8651882165699755 --max_bin=109 --max_depth=24 --min_data_in_leaf=15 --num_iterations=946 --num_leaves=37
2022-07-12 12:11:45 INFO Running runs: ['265teize']
2022-07-12 12:11:56 INFO Cleaning up finished run: 265teize
2022-07-12 12:11:56 INFO Agent received command: run
2022-07-12 12:11:56 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.25858836347028
	max_bin: 198
	max_depth: 10
	min_data_in_leaf: 26
	num_iterations: 128
	num_leaves: 5
2022-07-12 12:11:56 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --corrupt --lightgbm_learning_rate=0.25858836347028 --max_bin=198 --max_depth=10 --min_data_in_leaf=26 --num_iterations=128 --num_leaves=5
2022-07-12 12:12:01 INFO Running runs: ['llcegkdm']
2022-07-12 12:12:13 ERROR Detected 3 failed runs in the first 60 seconds, shutting down.
2022-07-12 12:12:13 INFO To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true
2022-07-12 13:18:29 INFO Running runs: []
2022-07-12 13:18:30 INFO Agent received command: run
2022-07-12 13:18:30 INFO Agent starting run with config:
	batch_size: 128
	d_model: 98
	decoder_heads: 5
	decoder_layers: 10
	early_stopping: 0.06670807675516825
	embedding_layers: 4
	encoder_heads: 2
	encoder_layers: 12
	learning_rate: 0.0001
	max_steps: 2498
	net_layers: 1
	noise_std: 0.01
2022-07-12 13:18:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=98 --decoder_heads=5 --decoder_layers=10 --early_stopping=0.06670807675516825 --embedding_layers=4 --encoder_heads=2 --encoder_layers=12 --learning_rate=0.0001 --max_steps=2498 --net_layers=1 --noise_std=0.01
2022-07-12 13:18:35 INFO Running runs: ['61cpscz7']
2022-07-12 13:22:29 INFO Cleaning up finished run: 61cpscz7
2022-07-12 13:22:30 INFO Agent received command: run
2022-07-12 13:22:30 INFO Agent starting run with config:
	batch_size: 64
	d_model: 96
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.2061089038987946
	embedding_layers: 1
	encoder_heads: 5
	encoder_layers: 9
	learning_rate: 0.001
	max_steps: 3911
	net_layers: 5
	noise_std: 0.1
2022-07-12 13:22:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=96 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.2061089038987946 --embedding_layers=1 --encoder_heads=5 --encoder_layers=9 --learning_rate=0.001 --max_steps=3911 --net_layers=5 --noise_std=0.1
2022-07-12 13:22:35 INFO Running runs: ['ivvf3vow']
2022-07-12 13:22:47 INFO Running runs: []
2022-07-12 13:22:48 INFO Agent received command: run
2022-07-12 13:22:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.6485978442264483
	max_bin: 81
	max_depth: 12
	min_data_in_leaf: 25
	num_iterations: 261
	num_leaves: 36
2022-07-12 13:22:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.6485978442264483 --max_bin=81 --max_depth=12 --min_data_in_leaf=25 --num_iterations=261 --num_leaves=36
2022-07-12 13:22:53 INFO Running runs: ['jtxel3co']
2022-07-12 13:24:21 INFO Running runs: []
2022-07-12 13:24:22 INFO Agent received command: run
2022-07-12 13:24:22 INFO Agent starting run with config:
	batch_size: 64
	d_model: 39
	decoder_heads: 2
	decoder_layers: 10
	early_stopping: 0.25543436378756174
	embedding_layers: 5
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.0001
	max_steps: 2985
	net_layers: 6
	noise_std: 1
2022-07-12 13:24:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=39 --decoder_heads=2 --decoder_layers=10 --early_stopping=0.25543436378756174 --embedding_layers=5 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.0001 --max_steps=2985 --net_layers=6 --noise_std=1
2022-07-12 13:24:27 INFO Running runs: ['3k4b9x4r']
2022-07-12 13:28:00 INFO Cleaning up finished run: 3k4b9x4r
2022-07-12 13:28:00 INFO Agent received command: run
2022-07-12 13:28:00 INFO Agent starting run with config:
	batch_size: 64
	d_model: 18
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.13239460720582086
	embedding_layers: 7
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.001
	max_steps: 3378
	net_layers: 7
	noise_std: 0.1
2022-07-12 13:28:00 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=18 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.13239460720582086 --embedding_layers=7 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.001 --max_steps=3378 --net_layers=7 --noise_std=0.1
2022-07-12 13:28:05 INFO Running runs: ['3yk2scrw']
2022-07-12 13:31:27 INFO Cleaning up finished run: 3yk2scrw
2022-07-12 13:31:28 INFO Agent received command: run
2022-07-12 13:31:28 INFO Agent starting run with config:
	batch_size: 64
	d_model: 52
	decoder_heads: 5
	decoder_layers: 7
	early_stopping: 0.07385923988373566
	embedding_layers: 4
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 2174
	net_layers: 6
	noise_std: 0.1
2022-07-12 13:31:28 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=52 --decoder_heads=5 --decoder_layers=7 --early_stopping=0.07385923988373566 --embedding_layers=4 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.0005 --max_steps=2174 --net_layers=6 --noise_std=0.1
2022-07-12 13:31:33 INFO Running runs: ['e5wv2aq2']
2022-07-12 13:34:04 INFO Cleaning up finished run: e5wv2aq2
2022-07-12 13:34:05 INFO Agent received command: run
2022-07-12 13:34:05 INFO Agent starting run with config:
	batch_size: 64
	d_model: 74
	decoder_heads: 5
	decoder_layers: 6
	early_stopping: 0.1866657782374407
	embedding_layers: 4
	encoder_heads: 3
	encoder_layers: 3
	learning_rate: 0.0005
	max_steps: 2444
	net_layers: 7
	noise_std: 1
2022-07-12 13:34:05 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=74 --decoder_heads=5 --decoder_layers=6 --early_stopping=0.1866657782374407 --embedding_layers=4 --encoder_heads=3 --encoder_layers=3 --learning_rate=0.0005 --max_steps=2444 --net_layers=7 --noise_std=1
2022-07-12 13:34:10 INFO Running runs: ['9zch6n9i']
2022-07-12 13:37:26 INFO Cleaning up finished run: 9zch6n9i
2022-07-12 13:37:27 INFO Agent received command: run
2022-07-12 13:37:27 INFO Agent starting run with config:
	batch_size: 128
	d_model: 57
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.26009349136186494
	embedding_layers: 6
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.0005
	max_steps: 3673
	net_layers: 7
	noise_std: 1
2022-07-12 13:37:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=57 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.26009349136186494 --embedding_layers=6 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.0005 --max_steps=3673 --net_layers=7 --noise_std=1
2022-07-12 13:37:32 INFO Running runs: ['p7syr5pf']
2022-07-12 13:41:58 INFO Running runs: []
2022-07-12 13:41:59 INFO Agent received command: run
2022-07-12 13:41:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.8853177831067719
	max_bin: 34
	max_depth: 4
	min_data_in_leaf: 17
	num_iterations: 617
	num_leaves: 34
2022-07-12 13:41:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.8853177831067719 --max_bin=34 --max_depth=4 --min_data_in_leaf=17 --num_iterations=617 --num_leaves=34
2022-07-12 13:46:13 INFO Running runs: []
2022-07-12 13:46:14 INFO Agent received command: run
2022-07-12 13:46:14 INFO Agent starting run with config:
	batch_size: 64
	d_model: 13
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.0997798246748554
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 3
	learning_rate: 0.008736843649771906
	max_steps: 2554
	net_layers: 3
	noise_std: 0.011772348145632572
2022-07-12 13:46:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=13 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.0997798246748554 --embedding_layers=6 --encoder_heads=3 --encoder_layers=3 --learning_rate=0.008736843649771906 --max_steps=2554 --net_layers=3 --noise_std=0.011772348145632572
2022-07-12 13:46:19 INFO Running runs: ['dr1o0wnt']
2022-07-12 13:47:37 INFO Running runs: []
2022-07-12 13:47:38 INFO Agent received command: run
2022-07-12 13:47:38 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0007599062269264768
	max_bin: 15
	max_depth: 16
	min_data_in_leaf: 16
	num_iterations: 326
	num_leaves: 36
2022-07-12 13:47:38 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0007599062269264768 --max_bin=15 --max_depth=16 --min_data_in_leaf=16 --num_iterations=326 --num_leaves=36
2022-07-12 13:47:43 INFO Running runs: ['btmuclkz']
2022-07-12 13:47:59 INFO Cleaning up finished run: btmuclkz
2022-07-12 13:47:59 INFO Agent received command: run
2022-07-12 13:47:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 3.2964243184719735e-05
	max_bin: 186
	max_depth: 23
	min_data_in_leaf: 30
	num_iterations: 736
	num_leaves: 39
2022-07-12 13:47:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=3.2964243184719735e-05 --max_bin=186 --max_depth=23 --min_data_in_leaf=30 --num_iterations=736 --num_leaves=39
2022-07-12 13:48:04 INFO Running runs: ['rhg2q9ok']
2022-07-12 13:48:20 INFO Cleaning up finished run: rhg2q9ok
2022-07-12 13:48:21 INFO Agent received command: run
2022-07-12 13:48:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 1.5792848514445623e-05
	max_bin: 139
	max_depth: 6
	min_data_in_leaf: 13
	num_iterations: 775
	num_leaves: 30
2022-07-12 13:48:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=1.5792848514445623e-05 --max_bin=139 --max_depth=6 --min_data_in_leaf=13 --num_iterations=775 --num_leaves=30
2022-07-12 13:48:33 INFO Running runs: []
2022-07-12 13:48:33 INFO Agent received command: run
2022-07-12 13:48:33 INFO Agent starting run with config:
	batch_size: 64
	d_model: 34
	decoder_heads: 1
	decoder_layers: 10
	early_stopping: 0.21085601614513175
	embedding_layers: 3
	encoder_heads: 3
	encoder_layers: 10
	learning_rate: 0.00017146109288795634
	max_steps: 2730
	net_layers: 2
	noise_std: 0.036730912532248514
2022-07-12 13:48:33 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=34 --decoder_heads=1 --decoder_layers=10 --early_stopping=0.21085601614513175 --embedding_layers=3 --encoder_heads=3 --encoder_layers=10 --learning_rate=0.00017146109288795634 --max_steps=2730 --net_layers=2 --noise_std=0.036730912532248514
2022-07-12 13:48:50 INFO Running runs: []
2022-07-12 13:48:51 INFO Agent received command: run
2022-07-12 13:48:51 INFO Agent starting run with config:
	batch_size: 32
	d_model: 9
	decoder_heads: 4
	decoder_layers: 8
	early_stopping: 0.25866098024447
	embedding_layers: 2
	encoder_heads: 3
	encoder_layers: 12
	learning_rate: 0.000789333448473479
	max_steps: 2174
	net_layers: 5
	noise_std: 0.7655105760579884
2022-07-12 13:48:51 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=9 --decoder_heads=4 --decoder_layers=8 --early_stopping=0.25866098024447 --embedding_layers=2 --encoder_heads=3 --encoder_layers=12 --learning_rate=0.000789333448473479 --max_steps=2174 --net_layers=5 --noise_std=0.7655105760579884
2022-07-12 13:48:56 INFO Running runs: ['bsnpsse2']
2022-07-12 13:52:07 INFO Cleaning up finished run: bsnpsse2
2022-07-12 13:52:07 INFO Agent received command: run
2022-07-12 13:52:07 INFO Agent starting run with config:
	batch_size: 32
	d_model: 27
	decoder_heads: 2
	decoder_layers: 11
	early_stopping: 0.20365470547400571
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.0007185998308441142
	max_steps: 2862
	net_layers: 4
	noise_std: 0.002817187141724844
2022-07-12 13:52:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=27 --decoder_heads=2 --decoder_layers=11 --early_stopping=0.20365470547400571 --embedding_layers=6 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.0007185998308441142 --max_steps=2862 --net_layers=4 --noise_std=0.002817187141724844
2022-07-12 13:52:12 INFO Running runs: ['2k86q1d6']
2022-07-12 13:55:51 INFO Cleaning up finished run: 2k86q1d6
2022-07-12 13:55:51 INFO Agent received command: run
2022-07-12 13:55:51 INFO Agent starting run with config:
	batch_size: 128
	d_model: 22
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.0021741375652599704
	embedding_layers: 8
	encoder_heads: 1
	encoder_layers: 12
	learning_rate: 0.00019208599134352023
	max_steps: 3278
	net_layers: 1
	noise_std: 0.30704658165967663
2022-07-12 13:55:51 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=22 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.0021741375652599704 --embedding_layers=8 --encoder_heads=1 --encoder_layers=12 --learning_rate=0.00019208599134352023 --max_steps=3278 --net_layers=1 --noise_std=0.30704658165967663
2022-07-12 13:55:56 INFO Running runs: ['i426khq2']
2022-07-12 13:58:24 INFO Cleaning up finished run: i426khq2
2022-07-12 13:58:24 INFO Agent received command: run
2022-07-12 13:58:24 INFO Agent starting run with config:
	batch_size: 128
	d_model: 41
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.07990641917868753
	embedding_layers: 7
	encoder_heads: 1
	encoder_layers: 9
	learning_rate: 0.00010329493014220512
	max_steps: 2703
	net_layers: 3
	noise_std: 0.28193613714336735
2022-07-12 13:58:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=41 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.07990641917868753 --embedding_layers=7 --encoder_heads=1 --encoder_layers=9 --learning_rate=0.00010329493014220512 --max_steps=2703 --net_layers=3 --noise_std=0.28193613714336735
2022-07-12 13:58:29 INFO Running runs: ['cy9kxh21']
2022-07-12 14:02:35 INFO Cleaning up finished run: cy9kxh21
2022-07-12 14:02:36 INFO Agent received command: run
2022-07-12 14:02:36 INFO Agent starting run with config:
	batch_size: 128
	d_model: 26
	decoder_heads: 5
	decoder_layers: 8
	early_stopping: 0.1467200998810849
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 12
	learning_rate: 0.0001353239098440458
	max_steps: 2690
	net_layers: 7
	noise_std: 2.5087002128566143
2022-07-12 14:02:36 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=26 --decoder_heads=5 --decoder_layers=8 --early_stopping=0.1467200998810849 --embedding_layers=8 --encoder_heads=2 --encoder_layers=12 --learning_rate=0.0001353239098440458 --max_steps=2690 --net_layers=7 --noise_std=2.5087002128566143
2022-07-12 14:02:41 INFO Running runs: ['qc9f3h0j']
2022-07-12 14:06:20 INFO Cleaning up finished run: qc9f3h0j
2022-07-12 14:06:21 INFO Agent received command: run
2022-07-12 14:06:21 INFO Agent starting run with config:
	batch_size: 128
	d_model: 111
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.5023912001807073
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.0003807465690639099
	max_steps: 3895
	net_layers: 6
	noise_std: 0.0035813729715774858
2022-07-12 14:06:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=111 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.5023912001807073 --embedding_layers=8 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.0003807465690639099 --max_steps=3895 --net_layers=6 --noise_std=0.0035813729715774858
2022-07-12 14:06:26 INFO Running runs: ['rxhjcj9x']
2022-07-12 14:11:58 INFO Running runs: []
2022-07-12 14:11:59 INFO Agent received command: run
2022-07-12 14:11:59 INFO Agent starting run with config:
	batch_size: 64
	d_model: 64
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.34769268174933454
	embedding_layers: 7
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.0005976735645271199
	max_steps: 2253
	net_layers: 1
	noise_std: 0.0018532601316272668
2022-07-12 14:11:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=64 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.34769268174933454 --embedding_layers=7 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.0005976735645271199 --max_steps=2253 --net_layers=1 --noise_std=0.0018532601316272668
2022-07-12 14:12:04 INFO Running runs: ['msak45c9']
2022-07-12 14:14:32 INFO Cleaning up finished run: msak45c9
2022-07-12 14:14:32 INFO Agent received command: run
2022-07-12 14:14:32 INFO Agent starting run with config:
	batch_size: 32
	d_model: 64
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.4728233687044376
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.0008816764294471102
	max_steps: 3933
	net_layers: 1
	noise_std: 0.0037694853615546976
2022-07-12 14:14:32 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=64 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.4728233687044376 --embedding_layers=8 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.0008816764294471102 --max_steps=3933 --net_layers=1 --noise_std=0.0037694853615546976
2022-07-12 14:14:37 INFO Running runs: ['911ewemc']
2022-07-12 14:18:17 INFO Running runs: []
2022-07-12 14:18:17 INFO Agent received command: run
2022-07-12 14:18:17 INFO Agent starting run with config:
	batch_size: 32
	d_model: 77
	decoder_heads: 1
	decoder_layers: 10
	early_stopping: 0.2743385087276503
	embedding_layers: 5
	encoder_heads: 2
	encoder_layers: 10
	learning_rate: 0.00010131316316484512
	max_steps: 4248
	net_layers: 1
	noise_std: 0.2016151645989345
2022-07-12 14:18:17 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=77 --decoder_heads=1 --decoder_layers=10 --early_stopping=0.2743385087276503 --embedding_layers=5 --encoder_heads=2 --encoder_layers=10 --learning_rate=0.00010131316316484512 --max_steps=4248 --net_layers=1 --noise_std=0.2016151645989345
2022-07-12 14:18:22 INFO Running runs: ['0zngtbme']
2022-07-12 14:24:21 INFO Cleaning up finished run: 0zngtbme
2022-07-12 14:24:22 INFO Agent received command: run
2022-07-12 14:24:22 INFO Agent starting run with config:
	batch_size: 128
	d_model: 122
	decoder_heads: 5
	decoder_layers: 12
	early_stopping: 0.6114487794800765
	embedding_layers: 5
	encoder_heads: 5
	encoder_layers: 9
	learning_rate: 0.0002877585314971278
	max_steps: 3035
	net_layers: 1
	noise_std: 0.11812425938748512
2022-07-12 14:24:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=122 --decoder_heads=5 --decoder_layers=12 --early_stopping=0.6114487794800765 --embedding_layers=5 --encoder_heads=5 --encoder_layers=9 --learning_rate=0.0002877585314971278 --max_steps=3035 --net_layers=1 --noise_std=0.11812425938748512
2022-07-12 14:24:27 INFO Running runs: ['w9behlkz']
2022-07-12 14:36:58 INFO Cleaning up finished run: w9behlkz
2022-07-12 14:36:59 INFO Agent received command: run
2022-07-12 14:36:59 INFO Agent starting run with config:
	batch_size: 64
	d_model: 57
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.22580240516097125
	embedding_layers: 4
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.0004655218885886106
	max_steps: 4574
	net_layers: 5
	noise_std: 1.536235187649737
2022-07-12 14:36:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=57 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.22580240516097125 --embedding_layers=4 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.0004655218885886106 --max_steps=4574 --net_layers=5 --noise_std=1.536235187649737
2022-07-12 14:37:04 INFO Running runs: ['6nwkb1fy']
2022-07-12 14:41:46 INFO Cleaning up finished run: 6nwkb1fy
2022-07-12 14:41:47 INFO Agent received command: run
2022-07-12 14:41:47 INFO Agent starting run with config:
	batch_size: 32
	d_model: 50
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.08357438482511492
	embedding_layers: 5
	encoder_heads: 2
	encoder_layers: 9
	learning_rate: 0.00012970603832419348
	max_steps: 4457
	net_layers: 3
	noise_std: 0.17478978620917746
2022-07-12 14:41:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=50 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.08357438482511492 --embedding_layers=5 --encoder_heads=2 --encoder_layers=9 --learning_rate=0.00012970603832419348 --max_steps=4457 --net_layers=3 --noise_std=0.17478978620917746
2022-07-12 14:41:52 INFO Running runs: ['h1ihfdfw']
2022-07-12 14:45:51 INFO Cleaning up finished run: h1ihfdfw
2022-07-12 14:45:52 INFO Agent received command: run
2022-07-12 14:45:52 INFO Agent starting run with config:
	batch_size: 32
	d_model: 83
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.23835914285995335
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 7
	learning_rate: 0.00012745880648954133
	max_steps: 4697
	net_layers: 2
	noise_std: 1.4003710770127031
2022-07-12 14:45:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=83 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.23835914285995335 --embedding_layers=4 --encoder_heads=1 --encoder_layers=7 --learning_rate=0.00012745880648954133 --max_steps=4697 --net_layers=2 --noise_std=1.4003710770127031
2022-07-12 14:45:57 INFO Running runs: ['k2gqxx5n']
2022-07-12 14:50:21 INFO Cleaning up finished run: k2gqxx5n
2022-07-12 14:50:22 INFO Agent received command: run
2022-07-12 14:50:22 INFO Agent starting run with config:
	batch_size: 32
	d_model: 40
	decoder_heads: 2
	decoder_layers: 11
	early_stopping: 0.15040690639466694
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 12
	learning_rate: 0.0001485116722389574
	max_steps: 2757
	net_layers: 7
	noise_std: 0.2545423826895712
2022-07-12 14:50:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=40 --decoder_heads=2 --decoder_layers=11 --early_stopping=0.15040690639466694 --embedding_layers=4 --encoder_heads=1 --encoder_layers=12 --learning_rate=0.0001485116722389574 --max_steps=2757 --net_layers=7 --noise_std=0.2545423826895712
2022-07-12 14:50:27 INFO Running runs: ['eunqxtl6']
2022-07-12 14:53:37 INFO Cleaning up finished run: eunqxtl6
2022-07-12 14:53:42 INFO Agent received command: run
2022-07-12 14:53:42 INFO Agent starting run with config:
	batch_size: 32
	d_model: 72
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.2755067908273942
	embedding_layers: 1
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0002233091337449617
	max_steps: 4695
	net_layers: 2
	noise_std: 0.1033130099160768
2022-07-12 14:53:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=72 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.2755067908273942 --embedding_layers=1 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0002233091337449617 --max_steps=4695 --net_layers=2 --noise_std=0.1033130099160768
2022-07-12 14:53:47 INFO Running runs: ['aova8u60']
2022-07-12 14:58:47 INFO Cleaning up finished run: aova8u60
2022-07-12 14:58:48 INFO Agent received command: run
2022-07-12 14:58:48 INFO Agent starting run with config:
	batch_size: 32
	d_model: 51
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.4401659344950171
	embedding_layers: 8
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0001969525598762601
	max_steps: 4068
	net_layers: 2
	noise_std: 0.18714901646455856
2022-07-12 14:58:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=51 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.4401659344950171 --embedding_layers=8 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0001969525598762601 --max_steps=4068 --net_layers=2 --noise_std=0.18714901646455856
2022-07-12 14:58:53 INFO Running runs: ['f95q61w5']
2022-07-12 15:03:04 INFO Cleaning up finished run: f95q61w5
2022-07-12 15:03:04 INFO Agent received command: run
2022-07-12 15:03:04 INFO Agent starting run with config:
	batch_size: 32
	d_model: 113
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.17486425663559796
	embedding_layers: 4
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.0001233939138114616
	max_steps: 4936
	net_layers: 3
	noise_std: 0.13308599340516983
2022-07-12 15:03:04 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=113 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.17486425663559796 --embedding_layers=4 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.0001233939138114616 --max_steps=4936 --net_layers=3 --noise_std=0.13308599340516983
2022-07-12 15:03:10 INFO Running runs: ['1qz442g1']
2022-07-12 15:07:21 INFO Cleaning up finished run: 1qz442g1
2022-07-12 15:07:22 INFO Agent received command: run
2022-07-12 15:07:22 INFO Agent starting run with config:
	batch_size: 64
	d_model: 33
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.06296294136606422
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 12
	learning_rate: 0.00015164945097250637
	max_steps: 4619
	net_layers: 6
	noise_std: 0.6779393274578914
2022-07-12 15:07:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=33 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.06296294136606422 --embedding_layers=8 --encoder_heads=2 --encoder_layers=12 --learning_rate=0.00015164945097250637 --max_steps=4619 --net_layers=6 --noise_std=0.6779393274578914
2022-07-12 15:07:27 INFO Running runs: ['ytldh227']
2022-07-12 15:10:21 INFO Cleaning up finished run: ytldh227
2022-07-12 15:10:22 INFO Agent received command: run
2022-07-12 15:10:22 INFO Agent starting run with config:
	batch_size: 32
	d_model: 34
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.0962505313824639
	embedding_layers: 7
	encoder_heads: 4
	encoder_layers: 12
	learning_rate: 0.00010242526282736966
	max_steps: 3205
	net_layers: 6
	noise_std: 0.3856367493157093
2022-07-12 15:10:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=34 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.0962505313824639 --embedding_layers=7 --encoder_heads=4 --encoder_layers=12 --learning_rate=0.00010242526282736966 --max_steps=3205 --net_layers=6 --noise_std=0.3856367493157093
2022-07-12 15:10:27 INFO Running runs: ['64pok8ow']
2022-07-12 15:13:21 INFO Cleaning up finished run: 64pok8ow
2022-07-12 15:13:21 INFO Agent received command: run
2022-07-12 15:13:21 INFO Agent starting run with config:
	batch_size: 64
	d_model: 36
	decoder_heads: 1
	decoder_layers: 10
	early_stopping: 0.04346348309487907
	embedding_layers: 8
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.0001045498233728727
	max_steps: 4522
	net_layers: 1
	noise_std: 0.16442328179687674
2022-07-12 15:13:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=36 --decoder_heads=1 --decoder_layers=10 --early_stopping=0.04346348309487907 --embedding_layers=8 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.0001045498233728727 --max_steps=4522 --net_layers=1 --noise_std=0.16442328179687674
2022-07-12 15:13:26 INFO Running runs: ['2ip9yyeh']
2022-07-12 15:18:26 INFO Cleaning up finished run: 2ip9yyeh
2022-07-12 15:18:27 INFO Agent received command: run
2022-07-12 15:18:27 INFO Agent starting run with config:
	batch_size: 32
	d_model: 47
	decoder_heads: 1
	decoder_layers: 6
	early_stopping: 0.010416154902392505
	embedding_layers: 7
	encoder_heads: 4
	encoder_layers: 11
	learning_rate: 0.00019119670131305817
	max_steps: 3274
	net_layers: 1
	noise_std: 0.16463243955978857
2022-07-12 15:18:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=47 --decoder_heads=1 --decoder_layers=6 --early_stopping=0.010416154902392505 --embedding_layers=7 --encoder_heads=4 --encoder_layers=11 --learning_rate=0.00019119670131305817 --max_steps=3274 --net_layers=1 --noise_std=0.16463243955978857
2022-07-12 15:18:32 INFO Running runs: ['udprw7i9']
2022-07-12 15:21:36 INFO Cleaning up finished run: udprw7i9
2022-07-12 15:21:37 INFO Agent received command: run
2022-07-12 15:21:37 INFO Agent starting run with config:
	batch_size: 32
	d_model: 49
	decoder_heads: 2
	decoder_layers: 11
	early_stopping: 0.07021252795365024
	embedding_layers: 1
	encoder_heads: 3
	encoder_layers: 4
	learning_rate: 0.00010182546717201348
	max_steps: 3434
	net_layers: 1
	noise_std: 0.1261727825907372
2022-07-12 15:21:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=49 --decoder_heads=2 --decoder_layers=11 --early_stopping=0.07021252795365024 --embedding_layers=1 --encoder_heads=3 --encoder_layers=4 --learning_rate=0.00010182546717201348 --max_steps=3434 --net_layers=1 --noise_std=0.1261727825907372
2022-07-12 15:21:42 INFO Running runs: ['71704qb4']
2022-07-12 15:24:52 INFO Cleaning up finished run: 71704qb4
2022-07-12 15:24:52 INFO Agent received command: run
2022-07-12 15:24:52 INFO Agent starting run with config:
	batch_size: 32
	d_model: 50
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.30034741540692855
	embedding_layers: 3
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.0001120897306281038
	max_steps: 4926
	net_layers: 5
	noise_std: 0.46239775603635536
2022-07-12 15:24:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=50 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.30034741540692855 --embedding_layers=3 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.0001120897306281038 --max_steps=4926 --net_layers=5 --noise_std=0.46239775603635536
2022-07-12 15:24:57 INFO Running runs: ['opgtgbwm']
2022-07-12 15:30:19 INFO Cleaning up finished run: opgtgbwm
2022-07-12 15:30:20 INFO Agent received command: run
2022-07-12 15:30:20 INFO Agent starting run with config:
	batch_size: 32
	d_model: 51
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.4235485036868609
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.00012933178864535136
	max_steps: 4895
	net_layers: 1
	noise_std: 1.1405080790607698
2022-07-12 15:30:20 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=51 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.4235485036868609 --embedding_layers=6 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.00012933178864535136 --max_steps=4895 --net_layers=1 --noise_std=1.1405080790607698
2022-07-12 15:30:25 INFO Running runs: ['8z25ujgy']
2022-07-12 15:36:41 INFO Cleaning up finished run: 8z25ujgy
2022-07-12 15:36:42 INFO Agent received command: run
2022-07-12 15:36:42 INFO Agent starting run with config:
	batch_size: 64
	d_model: 41
	decoder_heads: 1
	decoder_layers: 6
	early_stopping: 0.03214126088760995
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 12
	learning_rate: 0.00012209476062808125
	max_steps: 4780
	net_layers: 5
	noise_std: 0.18706422705464407
2022-07-12 15:36:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=41 --decoder_heads=1 --decoder_layers=6 --early_stopping=0.03214126088760995 --embedding_layers=8 --encoder_heads=2 --encoder_layers=12 --learning_rate=0.00012209476062808125 --max_steps=4780 --net_layers=5 --noise_std=0.18706422705464407
2022-07-12 15:36:47 INFO Running runs: ['bief2f8b']
2022-07-12 15:40:57 INFO Cleaning up finished run: bief2f8b
2022-07-12 15:40:59 INFO Agent received command: run
2022-07-12 15:40:59 INFO Agent starting run with config:
	batch_size: 32
	d_model: 44
	decoder_heads: 1
	decoder_layers: 10
	early_stopping: 0.10163547276603668
	embedding_layers: 1
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00020632090760358223
	max_steps: 3202
	net_layers: 2
	noise_std: 0.9868599996602224
2022-07-12 15:40:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=44 --decoder_heads=1 --decoder_layers=10 --early_stopping=0.10163547276603668 --embedding_layers=1 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00020632090760358223 --max_steps=3202 --net_layers=2 --noise_std=0.9868599996602224
2022-07-12 15:41:04 INFO Running runs: ['wfg5fq77']
2022-07-12 15:44:26 INFO Cleaning up finished run: wfg5fq77
2022-07-12 15:44:27 INFO Agent received command: run
2022-07-12 15:44:27 INFO Agent starting run with config:
	batch_size: 64
	d_model: 33
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.050498180783065304
	embedding_layers: 1
	encoder_heads: 4
	encoder_layers: 12
	learning_rate: 0.00015734626748369797
	max_steps: 4940
	net_layers: 2
	noise_std: 0.2233508579741407
2022-07-12 15:44:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=33 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.050498180783065304 --embedding_layers=1 --encoder_heads=4 --encoder_layers=12 --learning_rate=0.00015734626748369797 --max_steps=4940 --net_layers=2 --noise_std=0.2233508579741407
2022-07-12 15:44:32 INFO Running runs: ['b7g8d783']
2022-07-12 15:49:47 INFO Cleaning up finished run: b7g8d783
2022-07-12 15:49:48 INFO Agent received command: run
2022-07-12 15:49:48 INFO Agent starting run with config:
	batch_size: 32
	d_model: 35
	decoder_heads: 1
	decoder_layers: 11
	early_stopping: 0.025558555279596377
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.00011735142338261949
	max_steps: 4755
	net_layers: 7
	noise_std: 0.22958657015631637
2022-07-12 15:49:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=35 --decoder_heads=1 --decoder_layers=11 --early_stopping=0.025558555279596377 --embedding_layers=4 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.00011735142338261949 --max_steps=4755 --net_layers=7 --noise_std=0.22958657015631637
2022-07-12 15:49:53 INFO Running runs: ['rpoek0f1']
2022-07-12 15:53:03 INFO Cleaning up finished run: rpoek0f1
2022-07-12 15:53:04 INFO Agent received command: run
2022-07-12 15:53:04 INFO Agent starting run with config:
	batch_size: 32
	d_model: 55
	decoder_heads: 1
	decoder_layers: 9
	early_stopping: 0.14451069248818288
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.00011703674189678485
	max_steps: 3520
	net_layers: 1
	noise_std: 0.2048865770210374
2022-07-12 15:53:04 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=55 --decoder_heads=1 --decoder_layers=9 --early_stopping=0.14451069248818288 --embedding_layers=6 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.00011703674189678485 --max_steps=3520 --net_layers=1 --noise_std=0.2048865770210374
2022-07-12 15:53:09 INFO Running runs: ['rynhljfh']
2022-07-12 15:57:32 INFO Cleaning up finished run: rynhljfh
2022-07-12 15:57:32 INFO Agent received command: run
2022-07-12 15:57:32 INFO Agent starting run with config:
	batch_size: 32
	d_model: 38
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.06362865849519475
	embedding_layers: 2
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.00010006168255116444
	max_steps: 2937
	net_layers: 2
	noise_std: 1.3464583696256949
2022-07-12 15:57:32 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=38 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.06362865849519475 --embedding_layers=2 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.00010006168255116444 --max_steps=2937 --net_layers=2 --noise_std=1.3464583696256949
2022-07-12 15:57:37 INFO Running runs: ['0han5g0k']
2022-07-12 15:59:44 INFO Cleaning up finished run: 0han5g0k
2022-07-12 15:59:45 INFO Agent received command: run
2022-07-12 15:59:45 INFO Agent starting run with config:
	batch_size: 32
	d_model: 69
	decoder_heads: 2
	decoder_layers: 12
	early_stopping: 0.015527921897537713
	embedding_layers: 7
	encoder_heads: 5
	encoder_layers: 6
	learning_rate: 0.00016924740450339934
	max_steps: 4548
	net_layers: 5
	noise_std: 0.327203240684476
2022-07-12 15:59:45 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=69 --decoder_heads=2 --decoder_layers=12 --early_stopping=0.015527921897537713 --embedding_layers=7 --encoder_heads=5 --encoder_layers=6 --learning_rate=0.00016924740450339934 --max_steps=4548 --net_layers=5 --noise_std=0.327203240684476
2022-07-12 15:59:50 INFO Running runs: ['pwxrygzu']
2022-07-12 16:02:56 INFO Cleaning up finished run: pwxrygzu
2022-07-12 16:02:57 INFO Agent received command: run
2022-07-12 16:02:57 INFO Agent starting run with config:
	batch_size: 64
	d_model: 59
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.10823783528484364
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.00011270464928065134
	max_steps: 4382
	net_layers: 1
	noise_std: 0.1935919586898761
2022-07-12 16:02:57 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=59 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.10823783528484364 --embedding_layers=6 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.00011270464928065134 --max_steps=4382 --net_layers=1 --noise_std=0.1935919586898761
2022-07-12 16:03:02 INFO Running runs: ['tgn3jhr1']
2022-07-12 16:06:40 INFO Cleaning up finished run: tgn3jhr1
2022-07-12 16:06:41 INFO Agent received command: run
2022-07-12 16:06:41 INFO Agent starting run with config:
	batch_size: 32
	d_model: 58
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.0764681996457481
	embedding_layers: 6
	encoder_heads: 5
	encoder_layers: 11
	learning_rate: 0.00011982494820631222
	max_steps: 4760
	net_layers: 6
	noise_std: 0.7665903599520842
2022-07-12 16:06:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=58 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.0764681996457481 --embedding_layers=6 --encoder_heads=5 --encoder_layers=11 --learning_rate=0.00011982494820631222 --max_steps=4760 --net_layers=6 --noise_std=0.7665903599520842
2022-07-12 16:06:46 INFO Running runs: ['7wlcnmot']
2022-07-12 16:10:34 INFO Cleaning up finished run: 7wlcnmot
2022-07-12 16:10:35 INFO Agent received command: run
2022-07-12 16:10:35 INFO Agent starting run with config:
	batch_size: 32
	d_model: 75
	decoder_heads: 2
	decoder_layers: 10
	early_stopping: 0.09565978445978772
	embedding_layers: 8
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.0001200003164250975
	max_steps: 4876
	net_layers: 3
	noise_std: 0.5317605996113755
2022-07-12 16:10:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=75 --decoder_heads=2 --decoder_layers=10 --early_stopping=0.09565978445978772 --embedding_layers=8 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.0001200003164250975 --max_steps=4876 --net_layers=3 --noise_std=0.5317605996113755
2022-07-12 16:10:40 INFO Running runs: ['n1etxvn9']
2022-07-12 16:15:23 INFO Cleaning up finished run: n1etxvn9
2022-07-12 16:15:24 INFO Agent received command: run
2022-07-12 16:15:24 INFO Agent starting run with config:
	batch_size: 32
	d_model: 40
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.46152023387943497
	embedding_layers: 3
	encoder_heads: 3
	encoder_layers: 8
	learning_rate: 0.00015989938294886212
	max_steps: 4962
	net_layers: 1
	noise_std: 0.15747819720903972
2022-07-12 16:15:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=40 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.46152023387943497 --embedding_layers=3 --encoder_heads=3 --encoder_layers=8 --learning_rate=0.00015989938294886212 --max_steps=4962 --net_layers=1 --noise_std=0.15747819720903972
2022-07-12 16:15:29 INFO Running runs: ['jzhhh5fl']
2022-07-12 16:21:43 INFO Cleaning up finished run: jzhhh5fl
2022-07-12 16:21:44 INFO Agent received command: run
2022-07-12 16:21:44 INFO Agent starting run with config:
	batch_size: 32
	d_model: 40
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.1486748526324739
	embedding_layers: 4
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0007736128081222422
	max_steps: 4976
	net_layers: 1
	noise_std: 0.510793251561271
2022-07-12 16:21:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=40 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.1486748526324739 --embedding_layers=4 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0007736128081222422 --max_steps=4976 --net_layers=1 --noise_std=0.510793251561271
2022-07-12 16:21:49 INFO Running runs: ['0ny3fxth']
2022-07-12 16:25:44 INFO Cleaning up finished run: 0ny3fxth
2022-07-12 16:25:44 INFO Agent received command: run
2022-07-12 16:25:44 INFO Agent starting run with config:
	batch_size: 32
	d_model: 43
	decoder_heads: 1
	decoder_layers: 11
	early_stopping: 0.01740594356657319
	embedding_layers: 3
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.0001364467877093646
	max_steps: 4319
	net_layers: 4
	noise_std: 0.45268519273944274
2022-07-12 16:25:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=43 --decoder_heads=1 --decoder_layers=11 --early_stopping=0.01740594356657319 --embedding_layers=3 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.0001364467877093646 --max_steps=4319 --net_layers=4 --noise_std=0.45268519273944274
2022-07-12 16:25:49 INFO Running runs: ['2t053b9s']
2022-07-12 16:29:10 INFO Cleaning up finished run: 2t053b9s
2022-07-12 16:29:11 INFO Agent received command: run
2022-07-12 16:29:11 INFO Agent starting run with config:
	batch_size: 64
	d_model: 37
	decoder_heads: 2
	decoder_layers: 7
	early_stopping: 0.0667721677547131
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 12
	learning_rate: 0.00034754231176437495
	max_steps: 4416
	net_layers: 1
	noise_std: 0.14695896392273414
2022-07-12 16:29:11 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=37 --decoder_heads=2 --decoder_layers=7 --early_stopping=0.0667721677547131 --embedding_layers=8 --encoder_heads=2 --encoder_layers=12 --learning_rate=0.00034754231176437495 --max_steps=4416 --net_layers=1 --noise_std=0.14695896392273414
2022-07-12 16:29:16 INFO Running runs: ['ppktntlf']
2022-07-12 16:33:04 INFO Cleaning up finished run: ppktntlf
2022-07-12 16:33:11 INFO Running runs: []
2022-07-12 16:33:12 INFO Agent received command: run
2022-07-12 16:33:12 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0007975422477619186
	max_bin: 141
	max_depth: 18
	min_data_in_leaf: 30
	num_iterations: 579
	num_leaves: 9
2022-07-12 16:33:12 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0007975422477619186 --max_bin=141 --max_depth=18 --min_data_in_leaf=30 --num_iterations=579 --num_leaves=9
2022-07-12 16:33:17 INFO Running runs: ['2wlzbpk4']
2022-07-12 16:33:33 INFO Cleaning up finished run: 2wlzbpk4
2022-07-12 16:33:34 INFO Agent received command: run
2022-07-12 16:33:34 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.003323313447705268
	max_bin: 131
	max_depth: 7
	min_data_in_leaf: 15
	num_iterations: 841
	num_leaves: 12
2022-07-12 16:33:34 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.003323313447705268 --max_bin=131 --max_depth=7 --min_data_in_leaf=15 --num_iterations=841 --num_leaves=12
2022-07-12 16:33:39 INFO Running runs: ['bxd82odz']
2022-07-12 16:33:55 INFO Cleaning up finished run: bxd82odz
2022-07-12 16:33:55 INFO Agent received command: run
2022-07-12 16:33:55 INFO Agent starting run with config:
	lightgbm_learning_rate: 9.269781234568028e-05
	max_bin: 250
	max_depth: 12
	min_data_in_leaf: 23
	num_iterations: 451
	num_leaves: 19
2022-07-12 16:33:55 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=9.269781234568028e-05 --max_bin=250 --max_depth=12 --min_data_in_leaf=23 --num_iterations=451 --num_leaves=19
2022-07-12 16:34:00 INFO Running runs: ['f64n6g0p']
2022-07-12 16:34:17 INFO Cleaning up finished run: f64n6g0p
2022-07-12 16:34:17 INFO Agent received command: run
2022-07-12 16:34:17 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0023955972931183167
	max_bin: 123
	max_depth: 6
	min_data_in_leaf: 17
	num_iterations: 865
	num_leaves: 16
2022-07-12 16:34:17 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0023955972931183167 --max_bin=123 --max_depth=6 --min_data_in_leaf=17 --num_iterations=865 --num_leaves=16
2022-07-12 16:34:22 INFO Running runs: ['6mo6egud']
2022-07-12 16:34:38 INFO Cleaning up finished run: 6mo6egud
2022-07-12 16:34:39 INFO Agent received command: run
2022-07-12 16:34:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08428686111126293
	max_bin: 87
	max_depth: 21
	min_data_in_leaf: 19
	num_iterations: 155
	num_leaves: 18
2022-07-12 16:34:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08428686111126293 --max_bin=87 --max_depth=21 --min_data_in_leaf=19 --num_iterations=155 --num_leaves=18
2022-07-12 16:34:44 INFO Running runs: ['3iyj5q66']
2022-07-12 16:35:00 INFO Cleaning up finished run: 3iyj5q66
2022-07-12 16:35:01 INFO Agent received command: run
2022-07-12 16:35:01 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00022750202057671487
	max_bin: 58
	max_depth: 32
	min_data_in_leaf: 24
	num_iterations: 617
	num_leaves: 5
2022-07-12 16:35:01 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00022750202057671487 --max_bin=58 --max_depth=32 --min_data_in_leaf=24 --num_iterations=617 --num_leaves=5
2022-07-12 16:35:06 INFO Running runs: ['04e9u17p']
2022-07-12 16:35:22 INFO Cleaning up finished run: 04e9u17p
2022-07-12 16:35:23 INFO Agent received command: run
2022-07-12 16:35:23 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0007575277988110551
	max_bin: 99
	max_depth: 27
	min_data_in_leaf: 11
	num_iterations: 582
	num_leaves: 6
2022-07-12 16:35:23 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0007575277988110551 --max_bin=99 --max_depth=27 --min_data_in_leaf=11 --num_iterations=582 --num_leaves=6
2022-07-12 16:35:28 INFO Running runs: ['1hrbo4em']
2022-07-12 16:35:44 INFO Cleaning up finished run: 1hrbo4em
2022-07-12 16:35:45 INFO Agent received command: run
2022-07-12 16:35:45 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00016437306290679313
	max_bin: 82
	max_depth: 8
	min_data_in_leaf: 17
	num_iterations: 400
	num_leaves: 29
2022-07-12 16:35:45 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00016437306290679313 --max_bin=82 --max_depth=8 --min_data_in_leaf=17 --num_iterations=400 --num_leaves=29
2022-07-12 16:35:50 INFO Running runs: ['bdz0mfm5']
2022-07-12 16:36:06 INFO Cleaning up finished run: bdz0mfm5
2022-07-12 16:36:07 INFO Agent received command: run
2022-07-12 16:36:07 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.025896928665908033
	max_bin: 142
	max_depth: 31
	min_data_in_leaf: 21
	num_iterations: 883
	num_leaves: 16
2022-07-12 16:36:07 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.025896928665908033 --max_bin=142 --max_depth=31 --min_data_in_leaf=21 --num_iterations=883 --num_leaves=16
2022-07-12 16:36:12 INFO Running runs: ['soodrwom']
2022-07-12 16:36:29 INFO Cleaning up finished run: soodrwom
2022-07-12 16:36:29 INFO Agent received command: run
2022-07-12 16:36:29 INFO Agent starting run with config:
	lightgbm_learning_rate: 1.991500391653458e-05
	max_bin: 63
	max_depth: 23
	min_data_in_leaf: 18
	num_iterations: 467
	num_leaves: 27
2022-07-12 16:36:29 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=1.991500391653458e-05 --max_bin=63 --max_depth=23 --min_data_in_leaf=18 --num_iterations=467 --num_leaves=27
2022-07-12 16:36:34 INFO Running runs: ['zs5blucl']
2022-07-12 16:36:50 INFO Cleaning up finished run: zs5blucl
2022-07-12 16:36:51 INFO Agent received command: run
2022-07-12 16:36:51 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0011466222289353055
	max_bin: 243
	max_depth: 13
	min_data_in_leaf: 14
	num_iterations: 636
	num_leaves: 31
2022-07-12 16:36:51 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0011466222289353055 --max_bin=243 --max_depth=13 --min_data_in_leaf=14 --num_iterations=636 --num_leaves=31
2022-07-12 16:36:56 INFO Running runs: ['fszhdcd5']
2022-07-12 16:37:12 INFO Cleaning up finished run: fszhdcd5
2022-07-12 16:37:13 INFO Agent received command: run
2022-07-12 16:37:13 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.024985927127962833
	max_bin: 57
	max_depth: 11
	min_data_in_leaf: 22
	num_iterations: 879
	num_leaves: 31
2022-07-12 16:37:13 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.024985927127962833 --max_bin=57 --max_depth=11 --min_data_in_leaf=22 --num_iterations=879 --num_leaves=31
2022-07-12 16:37:18 INFO Running runs: ['yrlau1i7']
2022-07-12 16:37:34 INFO Cleaning up finished run: yrlau1i7
2022-07-12 16:38:12 INFO Agent received command: run
2022-07-12 16:38:12 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09750326525775004
	max_bin: 136
	max_depth: 27
	min_data_in_leaf: 19
	num_iterations: 969
	num_leaves: 20
2022-07-12 16:38:12 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09750326525775004 --max_bin=136 --max_depth=27 --min_data_in_leaf=19 --num_iterations=969 --num_leaves=20
2022-07-12 16:38:17 INFO Running runs: ['rtu1fz8b']
2022-07-12 16:38:33 INFO Cleaning up finished run: rtu1fz8b
2022-07-12 16:39:08 INFO Agent received command: run
2022-07-12 16:39:08 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.02726835003075864
	max_bin: 201
	max_depth: 23
	min_data_in_leaf: 30
	num_iterations: 169
	num_leaves: 19
2022-07-12 16:39:08 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.02726835003075864 --max_bin=201 --max_depth=23 --min_data_in_leaf=30 --num_iterations=169 --num_leaves=19
2022-07-12 16:39:13 INFO Running runs: ['96txrb1e']
2022-07-12 16:39:29 INFO Cleaning up finished run: 96txrb1e
2022-07-12 16:39:48 INFO Agent received command: run
2022-07-12 16:39:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 2.0700431726794964e-05
	max_bin: 30
	max_depth: 6
	min_data_in_leaf: 11
	num_iterations: 245
	num_leaves: 9
2022-07-12 16:39:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=2.0700431726794964e-05 --max_bin=30 --max_depth=6 --min_data_in_leaf=11 --num_iterations=245 --num_leaves=9
2022-07-12 16:39:53 INFO Running runs: ['wag9pod3']
2022-07-12 16:40:09 INFO Cleaning up finished run: wag9pod3
2022-07-12 16:40:10 INFO Agent received command: run
2022-07-12 16:40:10 INFO Agent starting run with config:
	lightgbm_learning_rate: 6.053434127338558e-05
	max_bin: 168
	max_depth: 13
	min_data_in_leaf: 11
	num_iterations: 689
	num_leaves: 15
2022-07-12 16:40:10 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=6.053434127338558e-05 --max_bin=168 --max_depth=13 --min_data_in_leaf=11 --num_iterations=689 --num_leaves=15
2022-07-12 16:40:15 INFO Running runs: ['rjsd7wxl']
2022-07-12 16:40:36 INFO Cleaning up finished run: rjsd7wxl
2022-07-12 16:40:44 INFO Agent received command: run
2022-07-12 16:40:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0002553804225315571
	max_bin: 142
	max_depth: 6
	min_data_in_leaf: 21
	num_iterations: 465
	num_leaves: 16
2022-07-12 16:40:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0002553804225315571 --max_bin=142 --max_depth=6 --min_data_in_leaf=21 --num_iterations=465 --num_leaves=16
2022-07-12 16:40:49 INFO Running runs: ['3h81nj0n']
2022-07-12 16:41:05 INFO Cleaning up finished run: 3h81nj0n
2022-07-12 16:41:06 INFO Agent received command: run
2022-07-12 16:41:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0001136193597168511
	max_bin: 182
	max_depth: 15
	min_data_in_leaf: 22
	num_iterations: 341
	num_leaves: 24
2022-07-12 16:41:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0001136193597168511 --max_bin=182 --max_depth=15 --min_data_in_leaf=22 --num_iterations=341 --num_leaves=24
2022-07-12 16:41:11 INFO Running runs: ['xzlb6pab']
2022-07-12 16:41:27 INFO Cleaning up finished run: xzlb6pab
2022-07-12 16:41:28 INFO Agent received command: run
2022-07-12 16:41:28 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.002041230443307237
	max_bin: 203
	max_depth: 4
	min_data_in_leaf: 24
	num_iterations: 652
	num_leaves: 5
2022-07-12 16:41:28 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.002041230443307237 --max_bin=203 --max_depth=4 --min_data_in_leaf=24 --num_iterations=652 --num_leaves=5
2022-07-12 16:41:33 INFO Running runs: ['jzadamdq']
2022-07-12 16:41:49 INFO Cleaning up finished run: jzadamdq
2022-07-12 16:41:49 INFO Agent received command: run
2022-07-12 16:41:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03125704940732375
	max_bin: 9
	max_depth: 31
	min_data_in_leaf: 15
	num_iterations: 327
	num_leaves: 40
2022-07-12 16:41:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03125704940732375 --max_bin=9 --max_depth=31 --min_data_in_leaf=15 --num_iterations=327 --num_leaves=40
2022-07-12 16:41:54 INFO Running runs: ['2gzfasb9']
2022-07-12 16:42:10 INFO Cleaning up finished run: 2gzfasb9
2022-07-12 16:42:11 INFO Agent received command: run
2022-07-12 16:42:11 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00035498227450382874
	max_bin: 132
	max_depth: 18
	min_data_in_leaf: 25
	num_iterations: 887
	num_leaves: 14
2022-07-12 16:42:11 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00035498227450382874 --max_bin=132 --max_depth=18 --min_data_in_leaf=25 --num_iterations=887 --num_leaves=14
2022-07-12 16:42:16 INFO Running runs: ['4wx1g20z']
2022-07-12 16:42:32 INFO Cleaning up finished run: 4wx1g20z
2022-07-12 16:42:33 INFO Agent received command: run
2022-07-12 16:42:33 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.013851722979598012
	max_bin: 174
	max_depth: 32
	min_data_in_leaf: 25
	num_iterations: 747
	num_leaves: 39
2022-07-12 16:42:33 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.013851722979598012 --max_bin=174 --max_depth=32 --min_data_in_leaf=25 --num_iterations=747 --num_leaves=39
2022-07-12 16:42:38 INFO Running runs: ['55b7b20w']
2022-07-12 16:42:59 INFO Cleaning up finished run: 55b7b20w
2022-07-12 16:43:00 INFO Agent received command: run
2022-07-12 16:43:00 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0018614116761265789
	max_bin: 25
	max_depth: 31
	min_data_in_leaf: 15
	num_iterations: 425
	num_leaves: 9
2022-07-12 16:43:00 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0018614116761265789 --max_bin=25 --max_depth=31 --min_data_in_leaf=15 --num_iterations=425 --num_leaves=9
2022-07-12 16:43:05 INFO Running runs: ['gdnsonxr']
2022-07-12 16:43:22 INFO Cleaning up finished run: gdnsonxr
2022-07-12 16:43:22 INFO Agent received command: run
2022-07-12 16:43:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 1.1191580352955476e-05
	max_bin: 38
	max_depth: 16
	min_data_in_leaf: 22
	num_iterations: 781
	num_leaves: 7
2022-07-12 16:43:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=1.1191580352955476e-05 --max_bin=38 --max_depth=16 --min_data_in_leaf=22 --num_iterations=781 --num_leaves=7
2022-07-12 16:43:27 INFO Running runs: ['v2o8ktd9']
2022-07-12 16:43:43 INFO Cleaning up finished run: v2o8ktd9
2022-07-12 16:43:44 INFO Agent received command: run
2022-07-12 16:43:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00226160369169732
	max_bin: 203
	max_depth: 5
	min_data_in_leaf: 21
	num_iterations: 748
	num_leaves: 17
2022-07-12 16:43:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00226160369169732 --max_bin=203 --max_depth=5 --min_data_in_leaf=21 --num_iterations=748 --num_leaves=17
2022-07-12 16:43:49 INFO Running runs: ['v94012he']
2022-07-12 16:44:05 INFO Cleaning up finished run: v94012he
2022-07-12 16:44:06 INFO Agent received command: run
2022-07-12 16:44:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 6.899209986852945e-05
	max_bin: 236
	max_depth: 7
	min_data_in_leaf: 10
	num_iterations: 976
	num_leaves: 33
2022-07-12 16:44:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=6.899209986852945e-05 --max_bin=236 --max_depth=7 --min_data_in_leaf=10 --num_iterations=976 --num_leaves=33
2022-07-12 16:44:11 INFO Running runs: ['0eofgppt']
2022-07-12 16:44:32 INFO Cleaning up finished run: 0eofgppt
2022-07-12 16:44:33 INFO Agent received command: run
2022-07-12 16:44:33 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0011049319053046238
	max_bin: 61
	max_depth: 20
	min_data_in_leaf: 23
	num_iterations: 110
	num_leaves: 18
2022-07-12 16:44:33 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0011049319053046238 --max_bin=61 --max_depth=20 --min_data_in_leaf=23 --num_iterations=110 --num_leaves=18
2022-07-12 16:44:38 INFO Running runs: ['k7ek0i99']
2022-07-12 16:44:54 INFO Cleaning up finished run: k7ek0i99
2022-07-12 16:44:55 INFO Agent received command: run
2022-07-12 16:44:55 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07621737507121676
	max_bin: 28
	max_depth: 27
	min_data_in_leaf: 24
	num_iterations: 861
	num_leaves: 35
2022-07-12 16:44:55 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07621737507121676 --max_bin=28 --max_depth=27 --min_data_in_leaf=24 --num_iterations=861 --num_leaves=35
2022-07-12 16:45:00 INFO Running runs: ['tbujsjqz']
2022-07-12 16:45:16 INFO Cleaning up finished run: tbujsjqz
2022-07-12 16:45:17 INFO Agent received command: run
2022-07-12 16:45:17 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.001836037967641692
	max_bin: 119
	max_depth: 23
	min_data_in_leaf: 27
	num_iterations: 491
	num_leaves: 33
2022-07-12 16:45:17 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.001836037967641692 --max_bin=119 --max_depth=23 --min_data_in_leaf=27 --num_iterations=491 --num_leaves=33
2022-07-12 16:45:22 INFO Running runs: ['coe3n9kp']
2022-07-12 16:45:38 INFO Cleaning up finished run: coe3n9kp
2022-07-12 16:45:39 INFO Agent received command: run
2022-07-12 16:45:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00022232356392502345
	max_bin: 69
	max_depth: 19
	min_data_in_leaf: 16
	num_iterations: 326
	num_leaves: 34
2022-07-12 16:45:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 0 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00022232356392502345 --max_bin=69 --max_depth=19 --min_data_in_leaf=16 --num_iterations=326 --num_leaves=34
2022-07-12 16:45:44 INFO Running runs: ['cjzc8ah9']
2022-07-12 16:46:00 INFO Cleaning up finished run: cjzc8ah9
2022-07-12 16:46:08 INFO Running runs: []
2022-07-12 16:46:09 INFO Agent received command: run
2022-07-12 16:46:09 INFO Agent starting run with config:
	batch_size: 64
	d_model: 40
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.3755684755425635
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.0004446055079944505
	max_steps: 2557
	net_layers: 3
	noise_std: 2.9673354145547868
2022-07-12 16:46:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=40 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.3755684755425635 --embedding_layers=8 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.0004446055079944505 --max_steps=2557 --net_layers=3 --noise_std=2.9673354145547868
2022-07-12 16:46:14 INFO Running runs: ['7f9lvygc']
2022-07-12 16:50:36 INFO Cleaning up finished run: 7f9lvygc
2022-07-12 16:50:37 INFO Agent received command: run
2022-07-12 16:50:37 INFO Agent starting run with config:
	batch_size: 64
	d_model: 109
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.6762344742404885
	embedding_layers: 7
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00010891792215196753
	max_steps: 3682
	net_layers: 8
	noise_std: 1.7370197425877971
2022-07-12 16:50:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=109 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.6762344742404885 --embedding_layers=7 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00010891792215196753 --max_steps=3682 --net_layers=8 --noise_std=1.7370197425877971
2022-07-12 16:50:42 INFO Running runs: ['a8t57jyo']
2022-07-12 16:57:57 INFO Cleaning up finished run: a8t57jyo
2022-07-12 16:57:57 INFO Agent received command: run
2022-07-12 16:57:57 INFO Agent starting run with config:
	batch_size: 64
	d_model: 119
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.6149269478712455
	embedding_layers: 2
	encoder_heads: 4
	encoder_layers: 6
	learning_rate: 0.0008562637750103706
	max_steps: 2464
	net_layers: 8
	noise_std: 0.19645643946045768
2022-07-12 16:57:57 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=119 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.6149269478712455 --embedding_layers=2 --encoder_heads=4 --encoder_layers=6 --learning_rate=0.0008562637750103706 --max_steps=2464 --net_layers=8 --noise_std=0.19645643946045768
2022-07-12 16:58:02 INFO Running runs: ['lvcxbpzo']
2022-07-12 17:04:02 INFO Cleaning up finished run: lvcxbpzo
2022-07-12 17:04:03 INFO Agent received command: run
2022-07-12 17:04:03 INFO Agent starting run with config:
	batch_size: 32
	d_model: 98
	decoder_heads: 3
	decoder_layers: 9
	early_stopping: 0.25338678019096117
	embedding_layers: 2
	encoder_heads: 5
	encoder_layers: 12
	learning_rate: 0.0004885086737820637
	max_steps: 4824
	net_layers: 2
	noise_std: 0.5063686205887465
2022-07-12 17:04:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=98 --decoder_heads=3 --decoder_layers=9 --early_stopping=0.25338678019096117 --embedding_layers=2 --encoder_heads=5 --encoder_layers=12 --learning_rate=0.0004885086737820637 --max_steps=4824 --net_layers=2 --noise_std=0.5063686205887465
2022-07-12 17:04:08 INFO Running runs: ['wrrmp8yf']
2022-07-12 17:11:58 INFO Cleaning up finished run: wrrmp8yf
2022-07-12 17:11:59 INFO Agent received command: run
2022-07-12 17:11:59 INFO Agent starting run with config:
	batch_size: 128
	d_model: 88
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.5679491188081507
	embedding_layers: 5
	encoder_heads: 5
	encoder_layers: 6
	learning_rate: 0.00019900761201880888
	max_steps: 3883
	net_layers: 3
	noise_std: 0.5764437654508568
2022-07-12 17:11:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=88 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.5679491188081507 --embedding_layers=5 --encoder_heads=5 --encoder_layers=6 --learning_rate=0.00019900761201880888 --max_steps=3883 --net_layers=3 --noise_std=0.5764437654508568
2022-07-12 17:12:04 INFO Running runs: ['9htehtj0']
2022-07-12 17:24:02 INFO Cleaning up finished run: 9htehtj0
2022-07-12 17:24:03 INFO Agent received command: run
2022-07-12 17:24:03 INFO Agent starting run with config:
	batch_size: 128
	d_model: 125
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.7468273171918999
	embedding_layers: 3
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0009492929728953218
	max_steps: 3485
	net_layers: 6
	noise_std: 0.19550931210251313
2022-07-12 17:24:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=125 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.7468273171918999 --embedding_layers=3 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0009492929728953218 --max_steps=3485 --net_layers=6 --noise_std=0.19550931210251313
2022-07-12 17:24:08 INFO Running runs: ['d6wv9i39']
2022-07-12 17:33:25 INFO Cleaning up finished run: d6wv9i39
2022-07-12 17:33:25 INFO Agent received command: run
2022-07-12 17:33:25 INFO Agent starting run with config:
	batch_size: 32
	d_model: 92
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.6824100026718377
	embedding_layers: 8
	encoder_heads: 3
	encoder_layers: 5
	learning_rate: 0.00010051857603704336
	max_steps: 4709
	net_layers: 6
	noise_std: 1.6847267939392665
2022-07-12 17:33:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=92 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.6824100026718377 --embedding_layers=8 --encoder_heads=3 --encoder_layers=5 --learning_rate=0.00010051857603704336 --max_steps=4709 --net_layers=6 --noise_std=1.6847267939392665
2022-07-12 17:33:30 INFO Running runs: ['u55xbt1a']
2022-07-12 17:42:09 INFO Cleaning up finished run: u55xbt1a
2022-07-12 17:42:10 INFO Agent received command: run
2022-07-12 17:42:10 INFO Agent starting run with config:
	batch_size: 128
	d_model: 99
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.46809972573325814
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00018956060982858124
	max_steps: 2794
	net_layers: 5
	noise_std: 2.069629643351281
2022-07-12 17:42:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=99 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.46809972573325814 --embedding_layers=6 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00018956060982858124 --max_steps=2794 --net_layers=5 --noise_std=2.069629643351281
2022-07-12 17:42:15 INFO Running runs: ['wrzwt4c9']
2022-07-12 17:46:58 INFO Cleaning up finished run: wrzwt4c9
2022-07-12 17:46:59 INFO Agent received command: run
2022-07-12 17:46:59 INFO Agent starting run with config:
	batch_size: 128
	d_model: 65
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.44191211010597303
	embedding_layers: 6
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.00012732985925086385
	max_steps: 2007
	net_layers: 5
	noise_std: 2.0416668108460496
2022-07-12 17:46:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=65 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.44191211010597303 --embedding_layers=6 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.00012732985925086385 --max_steps=2007 --net_layers=5 --noise_std=2.0416668108460496
2022-07-12 17:47:04 INFO Running runs: ['2a9w7a75']
2022-07-12 17:50:14 INFO Cleaning up finished run: 2a9w7a75
2022-07-12 17:50:15 INFO Agent received command: run
2022-07-12 17:50:15 INFO Agent starting run with config:
	batch_size: 128
	d_model: 92
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.3949560592544329
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00028511532641004055
	max_steps: 3663
	net_layers: 8
	noise_std: 2.94555022471713
2022-07-12 17:50:15 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=92 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.3949560592544329 --embedding_layers=6 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00028511532641004055 --max_steps=3663 --net_layers=8 --noise_std=2.94555022471713
2022-07-12 17:50:20 INFO Running runs: ['c0eeq9r3']
2022-07-12 17:55:21 INFO Cleaning up finished run: c0eeq9r3
2022-07-12 17:55:21 INFO Agent received command: run
2022-07-12 17:55:21 INFO Agent starting run with config:
	batch_size: 64
	d_model: 114
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.46932544673984655
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.00011190515898502064
	max_steps: 3403
	net_layers: 6
	noise_std: 1.9847165275957617
2022-07-12 17:55:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=114 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.46932544673984655 --embedding_layers=6 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.00011190515898502064 --max_steps=3403 --net_layers=6 --noise_std=1.9847165275957617
2022-07-12 17:55:26 INFO Running runs: ['otdzri4s']
2022-07-12 18:01:37 INFO Cleaning up finished run: otdzri4s
2022-07-12 18:01:38 INFO Agent received command: run
2022-07-12 18:01:38 INFO Agent starting run with config:
	batch_size: 64
	d_model: 122
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.8709468488188985
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.0003246118402651511
	max_steps: 2462
	net_layers: 7
	noise_std: 1.7485093708945534
2022-07-12 18:01:38 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=122 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.8709468488188985 --embedding_layers=8 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.0003246118402651511 --max_steps=2462 --net_layers=7 --noise_std=1.7485093708945534
2022-07-12 18:01:43 INFO Running runs: ['e6pcyecu']
2022-07-12 18:08:43 INFO Cleaning up finished run: e6pcyecu
2022-07-12 18:08:44 INFO Agent received command: run
2022-07-12 18:08:44 INFO Agent starting run with config:
	batch_size: 128
	d_model: 57
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.7074502372656257
	embedding_layers: 7
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.00015912484054614854
	max_steps: 2111
	net_layers: 7
	noise_std: 1.3611973712724776
2022-07-12 18:08:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=57 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.7074502372656257 --embedding_layers=7 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.00015912484054614854 --max_steps=2111 --net_layers=7 --noise_std=1.3611973712724776
2022-07-12 18:08:49 INFO Running runs: ['ln9179ry']
2022-07-12 18:13:00 INFO Cleaning up finished run: ln9179ry
2022-07-12 18:13:01 INFO Agent received command: run
2022-07-12 18:13:01 INFO Agent starting run with config:
	batch_size: 128
	d_model: 122
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.5726697501904295
	embedding_layers: 5
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.000162142910274544
	max_steps: 2679
	net_layers: 6
	noise_std: 1.7418685454147276
2022-07-12 18:13:01 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=122 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.5726697501904295 --embedding_layers=5 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.000162142910274544 --max_steps=2679 --net_layers=6 --noise_std=1.7418685454147276
2022-07-12 18:13:06 INFO Running runs: ['wd837qt2']
2022-07-12 18:18:01 INFO Cleaning up finished run: wd837qt2
2022-07-12 18:18:02 INFO Agent received command: run
2022-07-12 18:18:02 INFO Agent starting run with config:
	batch_size: 128
	d_model: 88
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.24399475705152104
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0001301577674983131
	max_steps: 3175
	net_layers: 7
	noise_std: 1.7846406512133903
2022-07-12 18:18:02 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=88 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.24399475705152104 --embedding_layers=4 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0001301577674983131 --max_steps=3175 --net_layers=7 --noise_std=1.7846406512133903
2022-07-12 18:18:07 INFO Running runs: ['3km7j0lv']
2022-07-12 18:21:45 INFO Cleaning up finished run: 3km7j0lv
2022-07-12 18:21:46 INFO Agent received command: run
2022-07-12 18:21:46 INFO Agent starting run with config:
	batch_size: 128
	d_model: 124
	decoder_heads: 1
	decoder_layers: 12
	early_stopping: 0.5308830117269093
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.00013073039547600743
	max_steps: 2454
	net_layers: 4
	noise_std: 1.8128802119303995
2022-07-12 18:21:46 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=124 --decoder_heads=1 --decoder_layers=12 --early_stopping=0.5308830117269093 --embedding_layers=2 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.00013073039547600743 --max_steps=2454 --net_layers=4 --noise_std=1.8128802119303995
2022-07-12 18:21:51 INFO Running runs: ['6hztd7es']
2022-07-12 18:26:52 INFO Cleaning up finished run: 6hztd7es
2022-07-12 18:26:52 INFO Agent received command: run
2022-07-12 18:26:52 INFO Agent starting run with config:
	batch_size: 128
	d_model: 84
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.8150348614585361
	embedding_layers: 1
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.00012962646426618657
	max_steps: 2070
	net_layers: 8
	noise_std: 2.1058291888065677
2022-07-12 18:26:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=84 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.8150348614585361 --embedding_layers=1 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.00012962646426618657 --max_steps=2070 --net_layers=8 --noise_std=2.1058291888065677
2022-07-12 18:26:57 INFO Running runs: ['07fe34qg']
2022-07-12 18:30:53 INFO Cleaning up finished run: 07fe34qg
2022-07-12 18:30:53 INFO Agent received command: run
2022-07-12 18:30:53 INFO Agent starting run with config:
	batch_size: 64
	d_model: 80
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.47581912951559346
	embedding_layers: 1
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.00012006280047342344
	max_steps: 2522
	net_layers: 7
	noise_std: 2.5313984320434546
2022-07-12 18:30:53 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=80 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.47581912951559346 --embedding_layers=1 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.00012006280047342344 --max_steps=2522 --net_layers=7 --noise_std=2.5313984320434546
2022-07-12 18:30:58 INFO Running runs: ['upuu9b7n']
2022-07-12 18:34:20 INFO Cleaning up finished run: upuu9b7n
2022-07-12 18:34:21 INFO Agent received command: run
2022-07-12 18:34:21 INFO Agent starting run with config:
	batch_size: 64
	d_model: 77
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.7416338387676111
	embedding_layers: 6
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.00011941794623903474
	max_steps: 2433
	net_layers: 5
	noise_std: 2.611032157044782
2022-07-12 18:34:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=77 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.7416338387676111 --embedding_layers=6 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.00011941794623903474 --max_steps=2433 --net_layers=5 --noise_std=2.611032157044782
2022-07-12 18:34:26 INFO Running runs: ['ygkzj74k']
2022-07-12 18:38:20 INFO Cleaning up finished run: ygkzj74k
2022-07-12 18:38:21 INFO Agent received command: run
2022-07-12 18:38:21 INFO Agent starting run with config:
	batch_size: 64
	d_model: 127
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.5713473116232454
	embedding_layers: 5
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.00010964735354800942
	max_steps: 2602
	net_layers: 8
	noise_std: 0.3710691275240776
2022-07-12 18:38:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=127 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.5713473116232454 --embedding_layers=5 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.00010964735354800942 --max_steps=2602 --net_layers=8 --noise_std=0.3710691275240776
2022-07-12 18:38:26 INFO Running runs: ['5qjsfi8d']
2022-07-12 18:41:52 INFO Cleaning up finished run: 5qjsfi8d
2022-07-12 18:41:53 INFO Agent received command: run
2022-07-12 18:41:53 INFO Agent starting run with config:
	batch_size: 128
	d_model: 92
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.2443113220288456
	embedding_layers: 8
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0002259534480768547
	max_steps: 2226
	net_layers: 7
	noise_std: 0.18260147419889927
2022-07-12 18:41:53 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=92 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.2443113220288456 --embedding_layers=8 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0002259534480768547 --max_steps=2226 --net_layers=7 --noise_std=0.18260147419889927
2022-07-12 18:41:58 INFO Running runs: ['4i5r3sci']
2022-07-12 18:45:08 INFO Cleaning up finished run: 4i5r3sci
2022-07-12 18:45:09 INFO Agent received command: run
2022-07-12 18:45:09 INFO Agent starting run with config:
	batch_size: 128
	d_model: 128
	decoder_heads: 5
	decoder_layers: 8
	early_stopping: 0.6745494700172177
	embedding_layers: 5
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0002759995019583464
	max_steps: 2594
	net_layers: 8
	noise_std: 0.960735852822476
2022-07-12 18:45:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=128 --decoder_heads=5 --decoder_layers=8 --early_stopping=0.6745494700172177 --embedding_layers=5 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0002759995019583464 --max_steps=2594 --net_layers=8 --noise_std=0.960735852822476
2022-07-12 18:45:14 INFO Running runs: ['8auv197o']
2022-07-12 18:53:06 INFO Cleaning up finished run: 8auv197o
2022-07-12 18:53:07 INFO Agent received command: run
2022-07-12 18:53:07 INFO Agent starting run with config:
	batch_size: 128
	d_model: 113
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.70005436998278
	embedding_layers: 7
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001254473948968373
	max_steps: 4318
	net_layers: 7
	noise_std: 1.21977674095432
2022-07-12 18:53:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=113 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.70005436998278 --embedding_layers=7 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001254473948968373 --max_steps=4318 --net_layers=7 --noise_std=1.21977674095432
2022-07-12 18:53:12 INFO Running runs: ['ooabz78k']
2022-07-12 19:02:39 INFO Cleaning up finished run: ooabz78k
2022-07-12 19:02:40 INFO Agent received command: run
2022-07-12 19:02:40 INFO Agent starting run with config:
	batch_size: 64
	d_model: 122
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.31411857193589565
	embedding_layers: 6
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0001293344324605065
	max_steps: 4689
	net_layers: 8
	noise_std: 2.049106168691857
2022-07-12 19:02:40 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=122 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.31411857193589565 --embedding_layers=6 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0001293344324605065 --max_steps=4689 --net_layers=8 --noise_std=2.049106168691857
2022-07-12 19:02:45 INFO Running runs: ['pazox03w']
2022-07-12 19:08:08 INFO Cleaning up finished run: pazox03w
2022-07-12 19:08:09 INFO Agent received command: run
2022-07-12 19:08:09 INFO Agent starting run with config:
	batch_size: 64
	d_model: 127
	decoder_heads: 1
	decoder_layers: 3
	early_stopping: 0.5743459894939911
	embedding_layers: 4
	encoder_heads: 2
	encoder_layers: 7
	learning_rate: 0.0001032790633779828
	max_steps: 3957
	net_layers: 8
	noise_std: 0.30679919373547104
2022-07-12 19:08:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=127 --decoder_heads=1 --decoder_layers=3 --early_stopping=0.5743459894939911 --embedding_layers=4 --encoder_heads=2 --encoder_layers=7 --learning_rate=0.0001032790633779828 --max_steps=3957 --net_layers=8 --noise_std=0.30679919373547104
2022-07-12 19:08:14 INFO Running runs: ['72217sod']
2022-07-12 19:16:08 INFO Cleaning up finished run: 72217sod
2022-07-12 19:16:09 INFO Agent received command: run
2022-07-12 19:16:09 INFO Agent starting run with config:
	batch_size: 128
	d_model: 125
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.5184943954962425
	embedding_layers: 6
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001493381800644581
	max_steps: 2474
	net_layers: 5
	noise_std: 0.6987974808911519
2022-07-12 19:16:09 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=125 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.5184943954962425 --embedding_layers=6 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001493381800644581 --max_steps=2474 --net_layers=5 --noise_std=0.6987974808911519
2022-07-12 19:16:14 INFO Running runs: ['7ugyowie']
2022-07-12 19:22:35 INFO Cleaning up finished run: 7ugyowie
2022-07-12 19:22:36 INFO Agent received command: run
2022-07-12 19:22:36 INFO Agent starting run with config:
	batch_size: 64
	d_model: 117
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.4181357394250403
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.00011057727199688252
	max_steps: 2131
	net_layers: 6
	noise_std: 0.10255780677073896
2022-07-12 19:22:36 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=117 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.4181357394250403 --embedding_layers=4 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.00011057727199688252 --max_steps=2131 --net_layers=6 --noise_std=0.10255780677073896
2022-07-12 19:22:41 INFO Running runs: ['e7plennq']
2022-07-12 19:25:35 INFO Cleaning up finished run: e7plennq
2022-07-12 19:25:36 INFO Agent received command: run
2022-07-12 19:25:36 INFO Agent starting run with config:
	batch_size: 64
	d_model: 107
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.16571665503054653
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.00011249509505495926
	max_steps: 2559
	net_layers: 5
	noise_std: 0.4575312656252984
2022-07-12 19:25:36 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=107 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.16571665503054653 --embedding_layers=4 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.00011249509505495926 --max_steps=2559 --net_layers=5 --noise_std=0.4575312656252984
2022-07-12 19:25:41 INFO Running runs: ['arw4n6c7']
2022-07-12 19:28:35 INFO Cleaning up finished run: arw4n6c7
2022-07-12 19:28:35 INFO Agent received command: run
2022-07-12 19:28:35 INFO Agent starting run with config:
	batch_size: 128
	d_model: 105
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.5276074353338017
	embedding_layers: 5
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.00011085008674043903
	max_steps: 2853
	net_layers: 8
	noise_std: 0.6050472824392917
2022-07-12 19:28:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=105 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.5276074353338017 --embedding_layers=5 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.00011085008674043903 --max_steps=2853 --net_layers=8 --noise_std=0.6050472824392917
2022-07-12 19:28:40 INFO Running runs: ['zpaemv5m']
2022-07-12 19:34:18 INFO Cleaning up finished run: zpaemv5m
2022-07-12 19:34:19 INFO Agent received command: run
2022-07-12 19:34:19 INFO Agent starting run with config:
	batch_size: 128
	d_model: 128
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.5252676156041232
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.00015557368629933783
	max_steps: 2733
	net_layers: 7
	noise_std: 0.15014663180529017
2022-07-12 19:34:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=128 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.5252676156041232 --embedding_layers=3 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.00015557368629933783 --max_steps=2733 --net_layers=7 --noise_std=0.15014663180529017
2022-07-12 19:34:24 INFO Running runs: ['b8rv5cvr']
2022-07-12 19:39:18 INFO Cleaning up finished run: b8rv5cvr
2022-07-12 19:39:25 INFO Running runs: []
2022-07-12 19:39:26 INFO Agent received command: run
2022-07-12 19:39:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 8.901394492705321e-05
	max_bin: 126
	max_depth: 25
	min_data_in_leaf: 29
	num_iterations: 604
	num_leaves: 16
2022-07-12 19:39:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=8.901394492705321e-05 --max_bin=126 --max_depth=25 --min_data_in_leaf=29 --num_iterations=604 --num_leaves=16
2022-07-12 19:39:31 INFO Running runs: ['qlhc12mo']
2022-07-12 19:39:47 INFO Cleaning up finished run: qlhc12mo
2022-07-12 19:39:48 INFO Agent received command: run
2022-07-12 19:39:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 4.585945584328256e-05
	max_bin: 68
	max_depth: 25
	min_data_in_leaf: 12
	num_iterations: 350
	num_leaves: 26
2022-07-12 19:39:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=4.585945584328256e-05 --max_bin=68 --max_depth=25 --min_data_in_leaf=12 --num_iterations=350 --num_leaves=26
2022-07-12 19:39:53 INFO Running runs: ['8i1v65b4']
2022-07-12 19:40:09 INFO Cleaning up finished run: 8i1v65b4
2022-07-12 19:40:10 INFO Agent received command: run
2022-07-12 19:40:10 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0499742636696049
	max_bin: 151
	max_depth: 15
	min_data_in_leaf: 18
	num_iterations: 652
	num_leaves: 9
2022-07-12 19:40:10 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0499742636696049 --max_bin=151 --max_depth=15 --min_data_in_leaf=18 --num_iterations=652 --num_leaves=9
2022-07-12 19:40:15 INFO Running runs: ['24xux5r5']
2022-07-12 19:40:31 INFO Cleaning up finished run: 24xux5r5
2022-07-12 19:40:32 INFO Agent received command: run
2022-07-12 19:40:32 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00046005775898060833
	max_bin: 234
	max_depth: 6
	min_data_in_leaf: 20
	num_iterations: 589
	num_leaves: 20
2022-07-12 19:40:32 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00046005775898060833 --max_bin=234 --max_depth=6 --min_data_in_leaf=20 --num_iterations=589 --num_leaves=20
2022-07-12 19:40:37 INFO Running runs: ['vy3n4t0u']
2022-07-12 19:40:53 INFO Cleaning up finished run: vy3n4t0u
2022-07-12 19:40:53 INFO Agent received command: run
2022-07-12 19:40:53 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0002974442628541394
	max_bin: 86
	max_depth: 22
	min_data_in_leaf: 29
	num_iterations: 464
	num_leaves: 39
2022-07-12 19:40:53 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0002974442628541394 --max_bin=86 --max_depth=22 --min_data_in_leaf=29 --num_iterations=464 --num_leaves=39
2022-07-12 19:40:58 INFO Running runs: ['ivxwvf72']
2022-07-12 19:41:15 INFO Cleaning up finished run: ivxwvf72
2022-07-12 19:41:15 INFO Agent received command: run
2022-07-12 19:41:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.054078774688926065
	max_bin: 121
	max_depth: 15
	min_data_in_leaf: 20
	num_iterations: 537
	num_leaves: 7
2022-07-12 19:41:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.054078774688926065 --max_bin=121 --max_depth=15 --min_data_in_leaf=20 --num_iterations=537 --num_leaves=7
2022-07-12 19:41:20 INFO Running runs: ['ttdkozoo']
2022-07-12 19:41:37 INFO Cleaning up finished run: ttdkozoo
2022-07-12 19:41:37 INFO Agent received command: run
2022-07-12 19:41:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07091164867660461
	max_bin: 199
	max_depth: 19
	min_data_in_leaf: 17
	num_iterations: 678
	num_leaves: 7
2022-07-12 19:41:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07091164867660461 --max_bin=199 --max_depth=19 --min_data_in_leaf=17 --num_iterations=678 --num_leaves=7
2022-07-12 19:41:42 INFO Running runs: ['w2ifsn77']
2022-07-12 19:41:58 INFO Cleaning up finished run: w2ifsn77
2022-07-12 19:41:59 INFO Agent received command: run
2022-07-12 19:41:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06093575210180756
	max_bin: 73
	max_depth: 11
	min_data_in_leaf: 18
	num_iterations: 865
	num_leaves: 9
2022-07-12 19:41:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06093575210180756 --max_bin=73 --max_depth=11 --min_data_in_leaf=18 --num_iterations=865 --num_leaves=9
2022-07-12 19:42:04 INFO Running runs: ['3opttgj9']
2022-07-12 19:42:20 INFO Cleaning up finished run: 3opttgj9
2022-07-12 19:42:21 INFO Agent received command: run
2022-07-12 19:42:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06519498107536773
	max_bin: 82
	max_depth: 13
	min_data_in_leaf: 17
	num_iterations: 755
	num_leaves: 6
2022-07-12 19:42:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06519498107536773 --max_bin=82 --max_depth=13 --min_data_in_leaf=17 --num_iterations=755 --num_leaves=6
2022-07-12 19:42:26 INFO Running runs: ['tj5upex0']
2022-07-12 19:42:42 INFO Cleaning up finished run: tj5upex0
2022-07-12 19:42:43 INFO Agent received command: run
2022-07-12 19:42:43 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0792166116975568
	max_bin: 143
	max_depth: 7
	min_data_in_leaf: 14
	num_iterations: 605
	num_leaves: 8
2022-07-12 19:42:43 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0792166116975568 --max_bin=143 --max_depth=7 --min_data_in_leaf=14 --num_iterations=605 --num_leaves=8
2022-07-12 19:42:48 INFO Running runs: ['nvqi0o6y']
2022-07-12 19:43:04 INFO Cleaning up finished run: nvqi0o6y
2022-07-12 19:43:05 INFO Agent received command: run
2022-07-12 19:43:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07668668116047826
	max_bin: 32
	max_depth: 15
	min_data_in_leaf: 15
	num_iterations: 896
	num_leaves: 5
2022-07-12 19:43:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07668668116047826 --max_bin=32 --max_depth=15 --min_data_in_leaf=15 --num_iterations=896 --num_leaves=5
2022-07-12 19:43:10 INFO Running runs: ['psefk8x0']
2022-07-12 19:43:26 INFO Cleaning up finished run: psefk8x0
2022-07-12 19:43:27 INFO Agent received command: run
2022-07-12 19:43:27 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.036660636820195915
	max_bin: 142
	max_depth: 4
	min_data_in_leaf: 28
	num_iterations: 952
	num_leaves: 8
2022-07-12 19:43:27 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.036660636820195915 --max_bin=142 --max_depth=4 --min_data_in_leaf=28 --num_iterations=952 --num_leaves=8
2022-07-12 19:43:32 INFO Running runs: ['7jt3z4cf']
2022-07-12 19:43:48 INFO Cleaning up finished run: 7jt3z4cf
2022-07-12 19:43:48 INFO Agent received command: run
2022-07-12 19:43:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09348350150731916
	max_bin: 153
	max_depth: 17
	min_data_in_leaf: 18
	num_iterations: 918
	num_leaves: 16
2022-07-12 19:43:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09348350150731916 --max_bin=153 --max_depth=17 --min_data_in_leaf=18 --num_iterations=918 --num_leaves=16
2022-07-12 19:43:53 INFO Running runs: ['lh3mlot2']
2022-07-12 19:44:10 INFO Cleaning up finished run: lh3mlot2
2022-07-12 19:44:10 INFO Agent received command: run
2022-07-12 19:44:10 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06688680394846248
	max_bin: 39
	max_depth: 4
	min_data_in_leaf: 22
	num_iterations: 754
	num_leaves: 12
2022-07-12 19:44:10 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06688680394846248 --max_bin=39 --max_depth=4 --min_data_in_leaf=22 --num_iterations=754 --num_leaves=12
2022-07-12 19:44:15 INFO Running runs: ['s0jzuxs9']
2022-07-12 19:44:31 INFO Cleaning up finished run: s0jzuxs9
2022-07-12 19:44:32 INFO Agent received command: run
2022-07-12 19:44:32 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08385733032636679
	max_bin: 172
	max_depth: 20
	min_data_in_leaf: 11
	num_iterations: 928
	num_leaves: 5
2022-07-12 19:44:32 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08385733032636679 --max_bin=172 --max_depth=20 --min_data_in_leaf=11 --num_iterations=928 --num_leaves=5
2022-07-12 19:44:37 INFO Running runs: ['xcx91fmo']
2022-07-12 19:44:53 INFO Cleaning up finished run: xcx91fmo
2022-07-12 19:44:54 INFO Agent received command: run
2022-07-12 19:44:54 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07907189499349981
	max_bin: 121
	max_depth: 12
	min_data_in_leaf: 20
	num_iterations: 654
	num_leaves: 10
2022-07-12 19:44:54 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07907189499349981 --max_bin=121 --max_depth=12 --min_data_in_leaf=20 --num_iterations=654 --num_leaves=10
2022-07-12 19:44:59 INFO Running runs: ['btpwuhoi']
2022-07-12 19:45:15 INFO Cleaning up finished run: btpwuhoi
2022-07-12 19:45:16 INFO Agent received command: run
2022-07-12 19:45:16 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07456978787235921
	max_bin: 97
	max_depth: 9
	min_data_in_leaf: 14
	num_iterations: 773
	num_leaves: 6
2022-07-12 19:45:16 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07456978787235921 --max_bin=97 --max_depth=9 --min_data_in_leaf=14 --num_iterations=773 --num_leaves=6
2022-07-12 19:45:21 INFO Running runs: ['tgeytgu5']
2022-07-12 19:45:37 INFO Cleaning up finished run: tgeytgu5
2022-07-12 19:45:38 INFO Agent received command: run
2022-07-12 19:45:38 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05621879255311224
	max_bin: 83
	max_depth: 13
	min_data_in_leaf: 30
	num_iterations: 968
	num_leaves: 8
2022-07-12 19:45:38 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05621879255311224 --max_bin=83 --max_depth=13 --min_data_in_leaf=30 --num_iterations=968 --num_leaves=8
2022-07-12 19:45:43 INFO Running runs: ['aksrfccp']
2022-07-12 19:45:59 INFO Cleaning up finished run: aksrfccp
2022-07-12 19:46:00 INFO Agent received command: run
2022-07-12 19:46:00 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05518596567309638
	max_bin: 104
	max_depth: 11
	min_data_in_leaf: 19
	num_iterations: 902
	num_leaves: 5
2022-07-12 19:46:00 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05518596567309638 --max_bin=104 --max_depth=11 --min_data_in_leaf=19 --num_iterations=902 --num_leaves=5
2022-07-12 19:46:05 INFO Running runs: ['ziyiyfuu']
2022-07-12 19:46:21 INFO Cleaning up finished run: ziyiyfuu
2022-07-12 19:46:22 INFO Agent received command: run
2022-07-12 19:46:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09309411400442189
	max_bin: 208
	max_depth: 17
	min_data_in_leaf: 12
	num_iterations: 602
	num_leaves: 6
2022-07-12 19:46:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09309411400442189 --max_bin=208 --max_depth=17 --min_data_in_leaf=12 --num_iterations=602 --num_leaves=6
2022-07-12 19:46:27 INFO Running runs: ['wn1eonl3']
2022-07-12 19:46:43 INFO Cleaning up finished run: wn1eonl3
2022-07-12 19:46:44 INFO Agent received command: run
2022-07-12 19:46:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09557768849124818
	max_bin: 231
	max_depth: 23
	min_data_in_leaf: 12
	num_iterations: 270
	num_leaves: 12
2022-07-12 19:46:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09557768849124818 --max_bin=231 --max_depth=23 --min_data_in_leaf=12 --num_iterations=270 --num_leaves=12
2022-07-12 19:46:49 INFO Running runs: ['aeaxzbev']
2022-07-12 19:47:05 INFO Cleaning up finished run: aeaxzbev
2022-07-12 19:47:06 INFO Agent received command: run
2022-07-12 19:47:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0964242290220808
	max_bin: 156
	max_depth: 13
	min_data_in_leaf: 11
	num_iterations: 462
	num_leaves: 8
2022-07-12 19:47:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0964242290220808 --max_bin=156 --max_depth=13 --min_data_in_leaf=11 --num_iterations=462 --num_leaves=8
2022-07-12 19:47:11 INFO Running runs: ['01h2ayqr']
2022-07-12 19:47:38 INFO Cleaning up finished run: 01h2ayqr
2022-07-12 19:47:39 INFO Agent received command: run
2022-07-12 19:47:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05286280432594942
	max_bin: 253
	max_depth: 23
	min_data_in_leaf: 14
	num_iterations: 213
	num_leaves: 9
2022-07-12 19:47:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05286280432594942 --max_bin=253 --max_depth=23 --min_data_in_leaf=14 --num_iterations=213 --num_leaves=9
2022-07-12 19:47:44 INFO Running runs: ['zbadwqsh']
2022-07-12 19:48:00 INFO Cleaning up finished run: zbadwqsh
2022-07-12 19:48:00 INFO Agent received command: run
2022-07-12 19:48:00 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03689793083595168
	max_bin: 242
	max_depth: 26
	min_data_in_leaf: 11
	num_iterations: 854
	num_leaves: 9
2022-07-12 19:48:00 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03689793083595168 --max_bin=242 --max_depth=26 --min_data_in_leaf=11 --num_iterations=854 --num_leaves=9
2022-07-12 19:48:05 INFO Running runs: ['stbl0b8a']
2022-07-12 19:48:22 INFO Cleaning up finished run: stbl0b8a
2022-07-12 19:48:22 INFO Agent received command: run
2022-07-12 19:48:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.014441734048231797
	max_bin: 210
	max_depth: 32
	min_data_in_leaf: 11
	num_iterations: 579
	num_leaves: 6
2022-07-12 19:48:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.014441734048231797 --max_bin=210 --max_depth=32 --min_data_in_leaf=11 --num_iterations=579 --num_leaves=6
2022-07-12 19:48:27 INFO Running runs: ['fzc80oem']
2022-07-12 19:48:44 INFO Cleaning up finished run: fzc80oem
2022-07-12 19:48:44 INFO Agent received command: run
2022-07-12 19:48:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07635961184620065
	max_bin: 236
	max_depth: 25
	min_data_in_leaf: 10
	num_iterations: 449
	num_leaves: 5
2022-07-12 19:48:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07635961184620065 --max_bin=236 --max_depth=25 --min_data_in_leaf=10 --num_iterations=449 --num_leaves=5
2022-07-12 19:48:50 INFO Running runs: ['p0br36oh']
2022-07-12 19:49:05 INFO Cleaning up finished run: p0br36oh
2022-07-12 19:49:06 INFO Agent received command: run
2022-07-12 19:49:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.011943123026397558
	max_bin: 228
	max_depth: 29
	min_data_in_leaf: 10
	num_iterations: 752
	num_leaves: 11
2022-07-12 19:49:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.011943123026397558 --max_bin=228 --max_depth=29 --min_data_in_leaf=10 --num_iterations=752 --num_leaves=11
2022-07-12 19:49:11 INFO Running runs: ['0lpfduti']
2022-07-12 19:49:27 INFO Cleaning up finished run: 0lpfduti
2022-07-12 19:49:28 INFO Agent received command: run
2022-07-12 19:49:28 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06211415060823277
	max_bin: 165
	max_depth: 30
	min_data_in_leaf: 12
	num_iterations: 777
	num_leaves: 9
2022-07-12 19:49:28 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06211415060823277 --max_bin=165 --max_depth=30 --min_data_in_leaf=12 --num_iterations=777 --num_leaves=9
2022-07-12 19:49:33 INFO Running runs: ['ul7h601s']
2022-07-12 19:49:49 INFO Cleaning up finished run: ul7h601s
2022-07-12 19:49:50 INFO Agent received command: run
2022-07-12 19:49:50 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07274531866535065
	max_bin: 233
	max_depth: 29
	min_data_in_leaf: 11
	num_iterations: 545
	num_leaves: 32
2022-07-12 19:49:50 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07274531866535065 --max_bin=233 --max_depth=29 --min_data_in_leaf=11 --num_iterations=545 --num_leaves=32
2022-07-12 19:49:55 INFO Running runs: ['nrrcctph']
2022-07-12 19:50:11 INFO Cleaning up finished run: nrrcctph
2022-07-12 19:50:12 INFO Agent received command: run
2022-07-12 19:50:12 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.01551414696979639
	max_bin: 237
	max_depth: 30
	min_data_in_leaf: 10
	num_iterations: 348
	num_leaves: 16
2022-07-12 19:50:12 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 1 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.01551414696979639 --max_bin=237 --max_depth=30 --min_data_in_leaf=10 --num_iterations=348 --num_leaves=16
2022-07-12 19:50:17 INFO Running runs: ['yi49ejqp']
2022-07-12 19:50:34 INFO Cleaning up finished run: yi49ejqp
2022-07-12 19:50:41 INFO Running runs: []
2022-07-12 19:50:42 INFO Agent received command: run
2022-07-12 19:50:42 INFO Agent starting run with config:
	batch_size: 128
	d_model: 114
	decoder_heads: 1
	decoder_layers: 5
	early_stopping: 0.4058417074583424
	embedding_layers: 8
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.00045389061474888454
	max_steps: 2021
	net_layers: 3
	noise_std: 2.813354137895906
2022-07-12 19:50:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=114 --decoder_heads=1 --decoder_layers=5 --early_stopping=0.4058417074583424 --embedding_layers=8 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.00045389061474888454 --max_steps=2021 --net_layers=3 --noise_std=2.813354137895906
2022-07-12 19:50:47 INFO Running runs: ['93t9baa5']
2022-07-12 19:53:57 INFO Cleaning up finished run: 93t9baa5
2022-07-12 19:53:58 INFO Agent received command: run
2022-07-12 19:53:58 INFO Agent starting run with config:
	batch_size: 32
	d_model: 127
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.20879375403480435
	embedding_layers: 5
	encoder_heads: 5
	encoder_layers: 10
	learning_rate: 0.0005702119647084997
	max_steps: 4797
	net_layers: 3
	noise_std: 0.3582214636353001
2022-07-12 19:53:58 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=127 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.20879375403480435 --embedding_layers=5 --encoder_heads=5 --encoder_layers=10 --learning_rate=0.0005702119647084997 --max_steps=4797 --net_layers=3 --noise_std=0.3582214636353001
2022-07-12 19:54:03 INFO Running runs: ['74rrqh7m']
2022-07-12 19:59:20 INFO Cleaning up finished run: 74rrqh7m
2022-07-12 19:59:21 INFO Agent received command: run
2022-07-12 19:59:21 INFO Agent starting run with config:
	batch_size: 64
	d_model: 111
	decoder_heads: 2
	decoder_layers: 8
	early_stopping: 0.8410903459630726
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.00010800473596918777
	max_steps: 3719
	net_layers: 4
	noise_std: 0.48117366241823545
2022-07-12 19:59:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=111 --decoder_heads=2 --decoder_layers=8 --early_stopping=0.8410903459630726 --embedding_layers=3 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.00010800473596918777 --max_steps=3719 --net_layers=4 --noise_std=0.48117366241823545
2022-07-12 19:59:26 INFO Running runs: ['18ix5uf5']
2022-07-12 20:07:51 INFO Cleaning up finished run: 18ix5uf5
2022-07-12 20:07:52 INFO Agent received command: run
2022-07-12 20:07:52 INFO Agent starting run with config:
	batch_size: 32
	d_model: 64
	decoder_heads: 5
	decoder_layers: 12
	early_stopping: 0.46370089819720006
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.0006305857686421102
	max_steps: 4188
	net_layers: 7
	noise_std: 1.4038262874449376
2022-07-12 20:07:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=64 --decoder_heads=5 --decoder_layers=12 --early_stopping=0.46370089819720006 --embedding_layers=8 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.0006305857686421102 --max_steps=4188 --net_layers=7 --noise_std=1.4038262874449376
2022-07-12 20:07:57 INFO Running runs: ['5ec6uu7g']
2022-07-12 20:13:57 INFO Cleaning up finished run: 5ec6uu7g
2022-07-12 20:13:57 INFO Agent received command: run
2022-07-12 20:13:57 INFO Agent starting run with config:
	batch_size: 128
	d_model: 42
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.670435646436378
	embedding_layers: 2
	encoder_heads: 5
	encoder_layers: 11
	learning_rate: 0.0009882257327618108
	max_steps: 2043
	net_layers: 5
	noise_std: 1.1147817216384683
2022-07-12 20:13:57 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=42 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.670435646436378 --embedding_layers=2 --encoder_heads=5 --encoder_layers=11 --learning_rate=0.0009882257327618108 --max_steps=2043 --net_layers=5 --noise_std=1.1147817216384683
2022-07-12 20:14:02 INFO Running runs: ['oc9qmqna']
2022-07-12 20:18:52 INFO Cleaning up finished run: oc9qmqna
2022-07-12 20:18:53 INFO Agent received command: run
2022-07-12 20:18:53 INFO Agent starting run with config:
	batch_size: 64
	d_model: 128
	decoder_heads: 3
	decoder_layers: 12
	early_stopping: 0.3002018835038878
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 9
	learning_rate: 0.0009904012440369704
	max_steps: 3087
	net_layers: 7
	noise_std: 0.12013746716581608
2022-07-12 20:18:53 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=128 --decoder_heads=3 --decoder_layers=12 --early_stopping=0.3002018835038878 --embedding_layers=6 --encoder_heads=3 --encoder_layers=9 --learning_rate=0.0009904012440369704 --max_steps=3087 --net_layers=7 --noise_std=0.12013746716581608
2022-07-12 20:18:58 INFO Running runs: ['5dsh4hp9']
2022-07-12 20:24:36 INFO Cleaning up finished run: 5dsh4hp9
2022-07-12 20:24:40 INFO Agent received command: run
2022-07-12 20:24:40 INFO Agent starting run with config:
	batch_size: 64
	d_model: 124
	decoder_heads: 3
	decoder_layers: 10
	early_stopping: 0.6365928220661475
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 11
	learning_rate: 0.0002033138245671845
	max_steps: 3100
	net_layers: 5
	noise_std: 0.4711652732224144
2022-07-12 20:24:40 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=124 --decoder_heads=3 --decoder_layers=10 --early_stopping=0.6365928220661475 --embedding_layers=6 --encoder_heads=2 --encoder_layers=11 --learning_rate=0.0002033138245671845 --max_steps=3100 --net_layers=5 --noise_std=0.4711652732224144
2022-07-12 20:24:45 INFO Running runs: ['nvzxr48d']
2022-07-12 20:33:06 INFO Cleaning up finished run: nvzxr48d
2022-07-12 20:33:07 INFO Agent received command: run
2022-07-12 20:33:07 INFO Agent starting run with config:
	batch_size: 64
	d_model: 82
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.435372128010153
	embedding_layers: 4
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.0001355474651663093
	max_steps: 2875
	net_layers: 7
	noise_std: 1.0049115787619476
2022-07-12 20:33:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=82 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.435372128010153 --embedding_layers=4 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.0001355474651663093 --max_steps=2875 --net_layers=7 --noise_std=1.0049115787619476
2022-07-12 20:33:12 INFO Running runs: ['bujci2ss']
2022-07-12 20:36:54 INFO Cleaning up finished run: bujci2ss
2022-07-12 20:36:55 INFO Agent received command: run
2022-07-12 20:36:55 INFO Agent starting run with config:
	batch_size: 128
	d_model: 106
	decoder_heads: 4
	decoder_layers: 10
	early_stopping: 0.5852030293804302
	embedding_layers: 1
	encoder_heads: 1
	encoder_layers: 12
	learning_rate: 0.00011098854348164802
	max_steps: 2126
	net_layers: 3
	noise_std: 2.4939639450380064
2022-07-12 20:36:55 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=106 --decoder_heads=4 --decoder_layers=10 --early_stopping=0.5852030293804302 --embedding_layers=1 --encoder_heads=1 --encoder_layers=12 --learning_rate=0.00011098854348164802 --max_steps=2126 --net_layers=3 --noise_std=2.4939639450380064
2022-07-12 20:37:00 INFO Running runs: ['qg290euj']
2022-07-12 20:43:15 INFO Cleaning up finished run: qg290euj
2022-07-12 20:43:15 INFO Agent received command: run
2022-07-12 20:43:15 INFO Agent starting run with config:
	batch_size: 32
	d_model: 57
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.875666484128387
	embedding_layers: 3
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.00011001821480859084
	max_steps: 3755
	net_layers: 1
	noise_std: 2.753551163857093
2022-07-12 20:43:15 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=57 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.875666484128387 --embedding_layers=3 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.00011001821480859084 --max_steps=3755 --net_layers=1 --noise_std=2.753551163857093
2022-07-12 20:43:20 INFO Running runs: ['xt7i8gik']
2022-07-12 20:47:58 INFO Cleaning up finished run: xt7i8gik
2022-07-12 20:47:59 INFO Agent received command: run
2022-07-12 20:47:59 INFO Agent starting run with config:
	batch_size: 128
	d_model: 75
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.22500115270954632
	embedding_layers: 8
	encoder_heads: 4
	encoder_layers: 9
	learning_rate: 0.0002187326192063876
	max_steps: 4508
	net_layers: 4
	noise_std: 1.0254855533829794
2022-07-12 20:47:59 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=75 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.22500115270954632 --embedding_layers=8 --encoder_heads=4 --encoder_layers=9 --learning_rate=0.0002187326192063876 --max_steps=4508 --net_layers=4 --noise_std=1.0254855533829794
2022-07-12 20:48:04 INFO Running runs: ['9ku335nb']
2022-07-12 20:54:36 INFO Cleaning up finished run: 9ku335nb
2022-07-12 20:54:37 INFO Agent received command: run
2022-07-12 20:54:37 INFO Agent starting run with config:
	batch_size: 32
	d_model: 58
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.7829252796543491
	embedding_layers: 3
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.00018219050395185173
	max_steps: 3443
	net_layers: 4
	noise_std: 0.1080070468000359
2022-07-12 20:54:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=58 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.7829252796543491 --embedding_layers=3 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.00018219050395185173 --max_steps=3443 --net_layers=4 --noise_std=0.1080070468000359
2022-07-12 20:54:42 INFO Running runs: ['16n1iz1h']
2022-07-12 20:59:46 INFO Cleaning up finished run: 16n1iz1h
2022-07-12 20:59:47 INFO Agent received command: run
2022-07-12 20:59:47 INFO Agent starting run with config:
	batch_size: 128
	d_model: 54
	decoder_heads: 2
	decoder_layers: 9
	early_stopping: 0.31019625526973305
	embedding_layers: 2
	encoder_heads: 2
	encoder_layers: 12
	learning_rate: 0.00025013958207341656
	max_steps: 3410
	net_layers: 4
	noise_std: 0.21791875984491912
2022-07-12 20:59:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=54 --decoder_heads=2 --decoder_layers=9 --early_stopping=0.31019625526973305 --embedding_layers=2 --encoder_heads=2 --encoder_layers=12 --learning_rate=0.00025013958207341656 --max_steps=3410 --net_layers=4 --noise_std=0.21791875984491912
2022-07-12 20:59:52 INFO Running runs: ['eeusyi5k']
2022-07-12 21:06:08 INFO Cleaning up finished run: eeusyi5k
2022-07-12 21:06:08 INFO Agent received command: run
2022-07-12 21:06:08 INFO Agent starting run with config:
	batch_size: 128
	d_model: 69
	decoder_heads: 3
	decoder_layers: 9
	early_stopping: 0.4657632986370735
	embedding_layers: 3
	encoder_heads: 3
	encoder_layers: 11
	learning_rate: 0.00023365283600733768
	max_steps: 4127
	net_layers: 4
	noise_std: 0.2895203765776423
2022-07-12 21:06:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=69 --decoder_heads=3 --decoder_layers=9 --early_stopping=0.4657632986370735 --embedding_layers=3 --encoder_heads=3 --encoder_layers=11 --learning_rate=0.00023365283600733768 --max_steps=4127 --net_layers=4 --noise_std=0.2895203765776423
2022-07-12 21:06:13 INFO Running runs: ['2isq5ywy']
2022-07-12 21:13:28 INFO Cleaning up finished run: 2isq5ywy
2022-07-12 21:13:29 INFO Agent received command: run
2022-07-12 21:13:29 INFO Agent starting run with config:
	batch_size: 64
	d_model: 77
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.7071336348112889
	embedding_layers: 5
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0001200756818993405
	max_steps: 3970
	net_layers: 6
	noise_std: 0.3993681528739123
2022-07-12 21:13:29 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=77 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.7071336348112889 --embedding_layers=5 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0001200756818993405 --max_steps=3970 --net_layers=6 --noise_std=0.3993681528739123
2022-07-12 21:13:34 INFO Running runs: ['y7qvm8gx']
2022-07-12 21:19:49 INFO Cleaning up finished run: y7qvm8gx
2022-07-12 21:19:50 INFO Agent received command: run
2022-07-12 21:19:50 INFO Agent starting run with config:
	batch_size: 64
	d_model: 44
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 0.6459807178539029
	embedding_layers: 3
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.00016330085878245014
	max_steps: 4031
	net_layers: 5
	noise_std: 0.15423462771200014
2022-07-12 21:19:50 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=44 --decoder_heads=3 --decoder_layers=8 --early_stopping=0.6459807178539029 --embedding_layers=3 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.00016330085878245014 --max_steps=4031 --net_layers=5 --noise_std=0.15423462771200014
2022-07-12 21:19:55 INFO Running runs: ['ku5s2gkd']
2022-07-12 21:26:54 INFO Cleaning up finished run: ku5s2gkd
2022-07-12 21:26:55 INFO Agent received command: run
2022-07-12 21:26:55 INFO Agent starting run with config:
	batch_size: 64
	d_model: 60
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.7278476621261444
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.00020658114785488852
	max_steps: 3967
	net_layers: 8
	noise_std: 0.2423228500596688
2022-07-12 21:26:55 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=60 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.7278476621261444 --embedding_layers=2 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.00020658114785488852 --max_steps=3967 --net_layers=8 --noise_std=0.2423228500596688
2022-07-12 21:27:00 INFO Running runs: ['v06a78an']
2022-07-12 21:33:25 INFO Cleaning up finished run: v06a78an
2022-07-12 21:33:26 INFO Agent received command: run
2022-07-12 21:33:26 INFO Agent starting run with config:
	batch_size: 64
	d_model: 91
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.49732983963813027
	embedding_layers: 1
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00014145151596197425
	max_steps: 4555
	net_layers: 6
	noise_std: 0.10323220532274578
2022-07-12 21:33:26 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=91 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.49732983963813027 --embedding_layers=1 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00014145151596197425 --max_steps=4555 --net_layers=6 --noise_std=0.10323220532274578
2022-07-12 21:33:31 INFO Running runs: ['uo8qx767']
2022-07-12 21:39:38 INFO Cleaning up finished run: uo8qx767
2022-07-12 21:39:39 INFO Agent received command: run
2022-07-12 21:39:39 INFO Agent starting run with config:
	batch_size: 128
	d_model: 33
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.8816450431106524
	embedding_layers: 3
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.0001241565723459108
	max_steps: 4290
	net_layers: 8
	noise_std: 0.15209382725748288
2022-07-12 21:39:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=33 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.8816450431106524 --embedding_layers=3 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.0001241565723459108 --max_steps=4290 --net_layers=8 --noise_std=0.15209382725748288
2022-07-12 21:39:44 INFO Running runs: ['iu32qilp']
2022-07-12 21:48:25 INFO Cleaning up finished run: iu32qilp
2022-07-12 21:48:25 INFO Agent received command: run
2022-07-12 21:48:25 INFO Agent starting run with config:
	batch_size: 128
	d_model: 70
	decoder_heads: 3
	decoder_layers: 9
	early_stopping: 0.7640647184128938
	embedding_layers: 4
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.00010875530577970562
	max_steps: 3638
	net_layers: 7
	noise_std: 0.2196715559030844
2022-07-12 21:48:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=70 --decoder_heads=3 --decoder_layers=9 --early_stopping=0.7640647184128938 --embedding_layers=4 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.00010875530577970562 --max_steps=3638 --net_layers=7 --noise_std=0.2196715559030844
2022-07-12 21:48:30 INFO Running runs: ['grevrii1']
2022-07-12 21:56:35 INFO Cleaning up finished run: grevrii1
2022-07-12 21:56:36 INFO Agent received command: run
2022-07-12 21:56:36 INFO Agent starting run with config:
	batch_size: 64
	d_model: 80
	decoder_heads: 2
	decoder_layers: 6
	early_stopping: 0.5352229754155358
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.00010755470349570018
	max_steps: 3984
	net_layers: 5
	noise_std: 0.1577497606457272
2022-07-12 21:56:36 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=80 --decoder_heads=2 --decoder_layers=6 --early_stopping=0.5352229754155358 --embedding_layers=4 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.00010755470349570018 --max_steps=3984 --net_layers=5 --noise_std=0.1577497606457272
2022-07-12 21:56:41 INFO Running runs: ['r2waudhb']
2022-07-12 22:03:39 INFO Cleaning up finished run: r2waudhb
2022-07-12 22:03:40 INFO Agent received command: run
2022-07-12 22:03:40 INFO Agent starting run with config:
	batch_size: 32
	d_model: 50
	decoder_heads: 2
	decoder_layers: 7
	early_stopping: 0.8752755418789461
	embedding_layers: 3
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.00010498317161220052
	max_steps: 2349
	net_layers: 7
	noise_std: 0.1784407943716226
2022-07-12 22:03:40 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=50 --decoder_heads=2 --decoder_layers=7 --early_stopping=0.8752755418789461 --embedding_layers=3 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.00010498317161220052 --max_steps=2349 --net_layers=7 --noise_std=0.1784407943716226
2022-07-12 22:03:45 INFO Running runs: ['c8rhnt4r']
2022-07-12 22:08:18 INFO Cleaning up finished run: c8rhnt4r
2022-07-12 22:08:19 INFO Agent received command: run
2022-07-12 22:08:19 INFO Agent starting run with config:
	batch_size: 64
	d_model: 40
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.5242025419985841
	embedding_layers: 5
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0001501145278819824
	max_steps: 4540
	net_layers: 7
	noise_std: 0.13353504192141993
2022-07-12 22:08:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=40 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.5242025419985841 --embedding_layers=5 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0001501145278819824 --max_steps=4540 --net_layers=7 --noise_std=0.13353504192141993
2022-07-12 22:08:24 INFO Running runs: ['2ir9ug65']
2022-07-12 22:15:06 INFO Cleaning up finished run: 2ir9ug65
2022-07-12 22:15:07 INFO Agent received command: run
2022-07-12 22:15:07 INFO Agent starting run with config:
	batch_size: 64
	d_model: 44
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.303785754831444
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.00012749105987665125
	max_steps: 3622
	net_layers: 8
	noise_std: 0.1319755283205375
2022-07-12 22:15:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=44 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.303785754831444 --embedding_layers=3 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.00012749105987665125 --max_steps=3622 --net_layers=8 --noise_std=0.1319755283205375
2022-07-12 22:15:12 INFO Running runs: ['jg1yrl4p']
2022-07-12 22:19:34 INFO Cleaning up finished run: jg1yrl4p
2022-07-12 22:19:35 INFO Agent received command: run
2022-07-12 22:19:35 INFO Agent starting run with config:
	batch_size: 64
	d_model: 43
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.4665913045886946
	embedding_layers: 7
	encoder_heads: 3
	encoder_layers: 6
	learning_rate: 0.00010022040015199444
	max_steps: 3299
	net_layers: 8
	noise_std: 0.46050949145100983
2022-07-12 22:19:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=43 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.4665913045886946 --embedding_layers=7 --encoder_heads=3 --encoder_layers=6 --learning_rate=0.00010022040015199444 --max_steps=3299 --net_layers=8 --noise_std=0.46050949145100983
2022-07-12 22:19:40 INFO Running runs: ['7yxpj6dv']
2022-07-12 22:24:51 INFO Cleaning up finished run: 7yxpj6dv
2022-07-12 22:24:52 INFO Agent received command: run
2022-07-12 22:24:52 INFO Agent starting run with config:
	batch_size: 128
	d_model: 41
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.8694052302597565
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0001367122845148338
	max_steps: 3210
	net_layers: 7
	noise_std: 0.17746307975032338
2022-07-12 22:24:52 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=41 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.8694052302597565 --embedding_layers=3 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0001367122845148338 --max_steps=3210 --net_layers=7 --noise_std=0.17746307975032338
2022-07-12 22:24:57 INFO Running runs: ['gatro05i']
2022-07-12 22:31:15 INFO Cleaning up finished run: gatro05i
2022-07-12 22:31:16 INFO Agent received command: run
2022-07-12 22:31:16 INFO Agent starting run with config:
	batch_size: 128
	d_model: 36
	decoder_heads: 4
	decoder_layers: 7
	early_stopping: 0.6621077221875186
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.00013130939371284978
	max_steps: 4301
	net_layers: 5
	noise_std: 0.1170501797238303
2022-07-12 22:31:16 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=36 --decoder_heads=4 --decoder_layers=7 --early_stopping=0.6621077221875186 --embedding_layers=2 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.00013130939371284978 --max_steps=4301 --net_layers=5 --noise_std=0.1170501797238303
2022-07-12 22:31:21 INFO Running runs: ['jdmr3cgi']
2022-07-12 22:38:46 INFO Cleaning up finished run: jdmr3cgi
2022-07-12 22:38:48 INFO Agent received command: run
2022-07-12 22:38:48 INFO Agent starting run with config:
	batch_size: 128
	d_model: 62
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.6777174045894013
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.00015622925611430145
	max_steps: 4504
	net_layers: 4
	noise_std: 0.203936881541964
2022-07-12 22:38:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=62 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.6777174045894013 --embedding_layers=2 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.00015622925611430145 --max_steps=4504 --net_layers=4 --noise_std=0.203936881541964
2022-07-12 22:38:53 INFO Running runs: ['dvgmud30']
2022-07-12 22:45:42 INFO Cleaning up finished run: dvgmud30
2022-07-12 22:45:43 INFO Agent received command: run
2022-07-12 22:45:43 INFO Agent starting run with config:
	batch_size: 32
	d_model: 120
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.7023765033440608
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.00010064954320818096
	max_steps: 3295
	net_layers: 7
	noise_std: 0.4785213071797011
2022-07-12 22:45:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=120 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.7023765033440608 --embedding_layers=2 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.00010064954320818096 --max_steps=3295 --net_layers=7 --noise_std=0.4785213071797011
2022-07-12 22:45:48 INFO Running runs: ['y8krw2rb']
2022-07-12 22:52:09 INFO Cleaning up finished run: y8krw2rb
2022-07-12 22:52:10 INFO Agent received command: run
2022-07-12 22:52:10 INFO Agent starting run with config:
	batch_size: 32
	d_model: 57
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.5464349750373623
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.00016182847387671986
	max_steps: 2188
	net_layers: 8
	noise_std: 0.2485743254727437
2022-07-12 22:52:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=57 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.5464349750373623 --embedding_layers=2 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.00016182847387671986 --max_steps=2188 --net_layers=8 --noise_std=0.2485743254727437
2022-07-12 22:52:15 INFO Running runs: ['yrypaxrk']
2022-07-12 22:55:21 INFO Cleaning up finished run: yrypaxrk
2022-07-12 22:55:29 INFO Running runs: []
2022-07-12 22:55:30 INFO Agent received command: run
2022-07-12 22:55:30 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.001628247228100923
	max_bin: 169
	max_depth: 29
	min_data_in_leaf: 14
	num_iterations: 358
	num_leaves: 9
2022-07-12 22:55:30 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.001628247228100923 --max_bin=169 --max_depth=29 --min_data_in_leaf=14 --num_iterations=358 --num_leaves=9
2022-07-12 22:55:35 INFO Running runs: ['2glrenc5']
2022-07-12 22:55:56 INFO Cleaning up finished run: 2glrenc5
2022-07-12 22:55:57 INFO Agent received command: run
2022-07-12 22:55:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0005920392891752722
	max_bin: 227
	max_depth: 30
	min_data_in_leaf: 16
	num_iterations: 456
	num_leaves: 21
2022-07-12 22:55:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0005920392891752722 --max_bin=227 --max_depth=30 --min_data_in_leaf=16 --num_iterations=456 --num_leaves=21
2022-07-12 22:56:02 INFO Running runs: ['6x3f1d1f']
2022-07-12 22:56:24 INFO Cleaning up finished run: 6x3f1d1f
2022-07-12 22:56:24 INFO Agent received command: run
2022-07-12 22:56:24 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.007679022417884354
	max_bin: 133
	max_depth: 29
	min_data_in_leaf: 11
	num_iterations: 304
	num_leaves: 28
2022-07-12 22:56:24 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.007679022417884354 --max_bin=133 --max_depth=29 --min_data_in_leaf=11 --num_iterations=304 --num_leaves=28
2022-07-12 22:56:29 INFO Running runs: ['jwgt249d']
2022-07-12 22:56:51 INFO Cleaning up finished run: jwgt249d
2022-07-12 22:56:52 INFO Agent received command: run
2022-07-12 22:56:52 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.025267476730225315
	max_bin: 162
	max_depth: 26
	min_data_in_leaf: 15
	num_iterations: 342
	num_leaves: 30
2022-07-12 22:56:52 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.025267476730225315 --max_bin=162 --max_depth=26 --min_data_in_leaf=15 --num_iterations=342 --num_leaves=30
2022-07-12 22:56:57 INFO Running runs: ['8u226dhc']
2022-07-12 22:57:18 INFO Cleaning up finished run: 8u226dhc
2022-07-12 22:57:19 INFO Agent received command: run
2022-07-12 22:57:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.020165166447184045
	max_bin: 89
	max_depth: 26
	min_data_in_leaf: 14
	num_iterations: 248
	num_leaves: 37
2022-07-12 22:57:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.020165166447184045 --max_bin=89 --max_depth=26 --min_data_in_leaf=14 --num_iterations=248 --num_leaves=37
2022-07-12 22:57:24 INFO Running runs: ['l49djs6r']
2022-07-12 22:57:46 INFO Cleaning up finished run: l49djs6r
2022-07-12 22:57:46 INFO Agent received command: run
2022-07-12 22:57:46 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03411789944071205
	max_bin: 162
	max_depth: 18
	min_data_in_leaf: 16
	num_iterations: 374
	num_leaves: 36
2022-07-12 22:57:46 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03411789944071205 --max_bin=162 --max_depth=18 --min_data_in_leaf=16 --num_iterations=374 --num_leaves=36
2022-07-12 22:57:51 INFO Running runs: ['if7zv0a6']
2022-07-12 22:58:13 INFO Cleaning up finished run: if7zv0a6
2022-07-12 22:58:14 INFO Agent received command: run
2022-07-12 22:58:14 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07036909292520219
	max_bin: 191
	max_depth: 28
	min_data_in_leaf: 15
	num_iterations: 364
	num_leaves: 35
2022-07-12 22:58:14 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07036909292520219 --max_bin=191 --max_depth=28 --min_data_in_leaf=15 --num_iterations=364 --num_leaves=35
2022-07-12 22:58:19 INFO Running runs: ['7smnjy7a']
2022-07-12 22:58:35 INFO Cleaning up finished run: 7smnjy7a
2022-07-12 22:58:36 INFO Agent received command: run
2022-07-12 22:58:36 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09704500234372102
	max_bin: 151
	max_depth: 27
	min_data_in_leaf: 20
	num_iterations: 191
	num_leaves: 28
2022-07-12 22:58:36 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09704500234372102 --max_bin=151 --max_depth=27 --min_data_in_leaf=20 --num_iterations=191 --num_leaves=28
2022-07-12 22:58:41 INFO Running runs: ['07f2dxvm']
2022-07-12 22:58:57 INFO Cleaning up finished run: 07f2dxvm
2022-07-12 22:58:57 INFO Agent received command: run
2022-07-12 22:58:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07469350847220448
	max_bin: 147
	max_depth: 20
	min_data_in_leaf: 11
	num_iterations: 435
	num_leaves: 31
2022-07-12 22:58:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07469350847220448 --max_bin=147 --max_depth=20 --min_data_in_leaf=11 --num_iterations=435 --num_leaves=31
2022-07-12 22:59:02 INFO Running runs: ['lnaiz14y']
2022-07-12 22:59:18 INFO Cleaning up finished run: lnaiz14y
2022-07-12 22:59:19 INFO Agent received command: run
2022-07-12 22:59:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04714403683277288
	max_bin: 36
	max_depth: 24
	min_data_in_leaf: 18
	num_iterations: 641
	num_leaves: 39
2022-07-12 22:59:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04714403683277288 --max_bin=36 --max_depth=24 --min_data_in_leaf=18 --num_iterations=641 --num_leaves=39
2022-07-12 22:59:24 INFO Running runs: ['re6e0z2e']
2022-07-12 22:59:40 INFO Cleaning up finished run: re6e0z2e
2022-07-12 22:59:41 INFO Agent received command: run
2022-07-12 22:59:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.002201611348562557
	max_bin: 45
	max_depth: 5
	min_data_in_leaf: 16
	num_iterations: 243
	num_leaves: 40
2022-07-12 22:59:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.002201611348562557 --max_bin=45 --max_depth=5 --min_data_in_leaf=16 --num_iterations=243 --num_leaves=40
2022-07-12 22:59:46 INFO Running runs: ['t915962s']
2022-07-12 23:00:02 INFO Cleaning up finished run: t915962s
2022-07-12 23:00:03 INFO Agent received command: run
2022-07-12 23:00:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.012054260690187332
	max_bin: 163
	max_depth: 23
	min_data_in_leaf: 11
	num_iterations: 115
	num_leaves: 39
2022-07-12 23:00:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.012054260690187332 --max_bin=163 --max_depth=23 --min_data_in_leaf=11 --num_iterations=115 --num_leaves=39
2022-07-12 23:00:08 INFO Running runs: ['8y885rxc']
2022-07-12 23:00:24 INFO Cleaning up finished run: 8y885rxc
2022-07-12 23:00:25 INFO Agent received command: run
2022-07-12 23:00:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08421260974341695
	max_bin: 143
	max_depth: 26
	min_data_in_leaf: 14
	num_iterations: 405
	num_leaves: 37
2022-07-12 23:00:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08421260974341695 --max_bin=143 --max_depth=26 --min_data_in_leaf=14 --num_iterations=405 --num_leaves=37
2022-07-12 23:00:30 INFO Running runs: ['25h0tkea']
2022-07-12 23:00:46 INFO Cleaning up finished run: 25h0tkea
2022-07-12 23:00:47 INFO Agent received command: run
2022-07-12 23:00:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06160280536304903
	max_bin: 64
	max_depth: 25
	min_data_in_leaf: 30
	num_iterations: 989
	num_leaves: 36
2022-07-12 23:00:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06160280536304903 --max_bin=64 --max_depth=25 --min_data_in_leaf=30 --num_iterations=989 --num_leaves=36
2022-07-12 23:00:52 INFO Running runs: ['vxiq10ki']
2022-07-12 23:01:08 INFO Cleaning up finished run: vxiq10ki
2022-07-12 23:01:09 INFO Agent received command: run
2022-07-12 23:01:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07916346548950803
	max_bin: 151
	max_depth: 27
	min_data_in_leaf: 27
	num_iterations: 973
	num_leaves: 40
2022-07-12 23:01:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07916346548950803 --max_bin=151 --max_depth=27 --min_data_in_leaf=27 --num_iterations=973 --num_leaves=40
2022-07-12 23:01:14 INFO Running runs: ['zh74ycvq']
2022-07-12 23:01:31 INFO Cleaning up finished run: zh74ycvq
2022-07-12 23:01:31 INFO Agent received command: run
2022-07-12 23:01:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04004500689584215
	max_bin: 201
	max_depth: 18
	min_data_in_leaf: 26
	num_iterations: 739
	num_leaves: 40
2022-07-12 23:01:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04004500689584215 --max_bin=201 --max_depth=18 --min_data_in_leaf=26 --num_iterations=739 --num_leaves=40
2022-07-12 23:01:36 INFO Running runs: ['7ju2oc55']
2022-07-12 23:01:58 INFO Cleaning up finished run: 7ju2oc55
2022-07-12 23:01:59 INFO Agent received command: run
2022-07-12 23:01:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06032848378613801
	max_bin: 66
	max_depth: 32
	min_data_in_leaf: 26
	num_iterations: 794
	num_leaves: 38
2022-07-12 23:01:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06032848378613801 --max_bin=66 --max_depth=32 --min_data_in_leaf=26 --num_iterations=794 --num_leaves=38
2022-07-12 23:02:04 INFO Running runs: ['32nr3e63']
2022-07-12 23:02:21 INFO Cleaning up finished run: 32nr3e63
2022-07-12 23:02:21 INFO Agent received command: run
2022-07-12 23:02:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04547128874095415
	max_bin: 185
	max_depth: 31
	min_data_in_leaf: 25
	num_iterations: 993
	num_leaves: 36
2022-07-12 23:02:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04547128874095415 --max_bin=185 --max_depth=31 --min_data_in_leaf=25 --num_iterations=993 --num_leaves=36
2022-07-12 23:02:26 INFO Running runs: ['c3fyavth']
2022-07-12 23:02:48 INFO Cleaning up finished run: c3fyavth
2022-07-12 23:02:49 INFO Agent received command: run
2022-07-12 23:02:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05410631643745939
	max_bin: 139
	max_depth: 30
	min_data_in_leaf: 30
	num_iterations: 889
	num_leaves: 39
2022-07-12 23:02:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05410631643745939 --max_bin=139 --max_depth=30 --min_data_in_leaf=30 --num_iterations=889 --num_leaves=39
2022-07-12 23:02:54 INFO Running runs: ['qt5s1oio']
2022-07-12 23:03:10 INFO Cleaning up finished run: qt5s1oio
2022-07-12 23:03:11 INFO Agent received command: run
2022-07-12 23:03:11 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.030535280499950215
	max_bin: 209
	max_depth: 24
	min_data_in_leaf: 30
	num_iterations: 943
	num_leaves: 40
2022-07-12 23:03:11 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.030535280499950215 --max_bin=209 --max_depth=24 --min_data_in_leaf=30 --num_iterations=943 --num_leaves=40
2022-07-12 23:03:16 INFO Running runs: ['w7dban0j']
2022-07-12 23:03:37 INFO Cleaning up finished run: w7dban0j
2022-07-12 23:03:38 INFO Agent received command: run
2022-07-12 23:03:38 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0720953856389103
	max_bin: 138
	max_depth: 15
	min_data_in_leaf: 26
	num_iterations: 950
	num_leaves: 39
2022-07-12 23:03:38 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0720953856389103 --max_bin=138 --max_depth=15 --min_data_in_leaf=26 --num_iterations=950 --num_leaves=39
2022-07-12 23:03:43 INFO Running runs: ['xx684wj6']
2022-07-12 23:03:59 INFO Cleaning up finished run: xx684wj6
2022-07-12 23:04:00 INFO Agent received command: run
2022-07-12 23:04:00 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0318252272621932
	max_bin: 167
	max_depth: 8
	min_data_in_leaf: 30
	num_iterations: 979
	num_leaves: 33
2022-07-12 23:04:00 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0318252272621932 --max_bin=167 --max_depth=8 --min_data_in_leaf=30 --num_iterations=979 --num_leaves=33
2022-07-12 23:04:05 INFO Running runs: ['54icbb4i']
2022-07-12 23:04:21 INFO Cleaning up finished run: 54icbb4i
2022-07-12 23:04:22 INFO Agent received command: run
2022-07-12 23:04:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08846013124334061
	max_bin: 237
	max_depth: 7
	min_data_in_leaf: 30
	num_iterations: 757
	num_leaves: 35
2022-07-12 23:04:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08846013124334061 --max_bin=237 --max_depth=7 --min_data_in_leaf=30 --num_iterations=757 --num_leaves=35
2022-07-12 23:04:27 INFO Running runs: ['xzp3pds4']
2022-07-12 23:04:43 INFO Cleaning up finished run: xzp3pds4
2022-07-12 23:04:44 INFO Agent received command: run
2022-07-12 23:04:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0003294763845915569
	max_bin: 207
	max_depth: 9
	min_data_in_leaf: 30
	num_iterations: 982
	num_leaves: 34
2022-07-12 23:04:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0003294763845915569 --max_bin=207 --max_depth=9 --min_data_in_leaf=30 --num_iterations=982 --num_leaves=34
2022-07-12 23:04:49 INFO Running runs: ['j9weuz07']
2022-07-12 23:05:15 INFO Cleaning up finished run: j9weuz07
2022-07-12 23:05:16 INFO Agent received command: run
2022-07-12 23:05:16 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06744247295447887
	max_bin: 65
	max_depth: 6
	min_data_in_leaf: 28
	num_iterations: 937
	num_leaves: 30
2022-07-12 23:05:16 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06744247295447887 --max_bin=65 --max_depth=6 --min_data_in_leaf=28 --num_iterations=937 --num_leaves=30
2022-07-12 23:05:21 INFO Running runs: ['r4b3zj6n']
2022-07-12 23:05:37 INFO Cleaning up finished run: r4b3zj6n
2022-07-12 23:05:38 INFO Agent received command: run
2022-07-12 23:05:38 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07609851915281314
	max_bin: 142
	max_depth: 5
	min_data_in_leaf: 21
	num_iterations: 955
	num_leaves: 7
2022-07-12 23:05:38 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07609851915281314 --max_bin=142 --max_depth=5 --min_data_in_leaf=21 --num_iterations=955 --num_leaves=7
2022-07-12 23:05:43 INFO Running runs: ['tw0uzdkq']
2022-07-12 23:06:05 INFO Cleaning up finished run: tw0uzdkq
2022-07-12 23:06:05 INFO Agent received command: run
2022-07-12 23:06:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06247668779829309
	max_bin: 158
	max_depth: 18
	min_data_in_leaf: 29
	num_iterations: 921
	num_leaves: 32
2022-07-12 23:06:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06247668779829309 --max_bin=158 --max_depth=18 --min_data_in_leaf=29 --num_iterations=921 --num_leaves=32
2022-07-12 23:06:10 INFO Running runs: ['ovjdio0d']
2022-07-12 23:06:29 INFO Cleaning up finished run: ovjdio0d
2022-07-12 23:06:30 INFO Agent received command: run
2022-07-12 23:06:30 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09414850763593108
	max_bin: 237
	max_depth: 32
	min_data_in_leaf: 30
	num_iterations: 995
	num_leaves: 38
2022-07-12 23:06:30 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09414850763593108 --max_bin=237 --max_depth=32 --min_data_in_leaf=30 --num_iterations=995 --num_leaves=38
2022-07-12 23:06:35 INFO Running runs: ['7ublqync']
2022-07-12 23:06:51 INFO Cleaning up finished run: 7ublqync
2022-07-12 23:06:52 INFO Agent received command: run
2022-07-12 23:06:52 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08820426083281303
	max_bin: 6
	max_depth: 27
	min_data_in_leaf: 30
	num_iterations: 890
	num_leaves: 6
2022-07-12 23:06:52 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08820426083281303 --max_bin=6 --max_depth=27 --min_data_in_leaf=30 --num_iterations=890 --num_leaves=6
2022-07-12 23:06:57 INFO Running runs: ['okd56ezy']
2022-07-12 23:07:13 INFO Cleaning up finished run: okd56ezy
2022-07-12 23:07:14 INFO Agent received command: run
2022-07-12 23:07:14 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08321478750004015
	max_bin: 195
	max_depth: 4
	min_data_in_leaf: 10
	num_iterations: 897
	num_leaves: 22
2022-07-12 23:07:14 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 2 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08321478750004015 --max_bin=195 --max_depth=4 --min_data_in_leaf=10 --num_iterations=897 --num_leaves=22
2022-07-12 23:07:19 INFO Running runs: ['i4mv1mfa']
2022-07-12 23:07:35 INFO Cleaning up finished run: i4mv1mfa
2022-07-12 23:07:42 INFO Running runs: []
2022-07-12 23:07:43 INFO Agent received command: run
2022-07-12 23:07:43 INFO Agent starting run with config:
	batch_size: 128
	d_model: 82
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.7592975280434721
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00031241651349494333
	max_steps: 3796
	net_layers: 7
	noise_std: 0.24017293932965864
2022-07-12 23:07:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=82 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.7592975280434721 --embedding_layers=6 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00031241651349494333 --max_steps=3796 --net_layers=7 --noise_std=0.24017293932965864
2022-07-12 23:07:48 INFO Running runs: ['fo28eupj']
2022-07-12 23:18:03 INFO Cleaning up finished run: fo28eupj
2022-07-12 23:18:03 INFO Agent received command: run
2022-07-12 23:18:03 INFO Agent starting run with config:
	batch_size: 128
	d_model: 67
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.5602986273131609
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0002747205047158622
	max_steps: 2673
	net_layers: 3
	noise_std: 0.6358396093200231
2022-07-12 23:18:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=67 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.5602986273131609 --embedding_layers=4 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0002747205047158622 --max_steps=2673 --net_layers=3 --noise_std=0.6358396093200231
2022-07-12 23:18:08 INFO Running runs: ['p6kic6pn']
2022-07-12 23:24:12 INFO Cleaning up finished run: p6kic6pn
2022-07-12 23:24:13 INFO Agent received command: run
2022-07-12 23:24:13 INFO Agent starting run with config:
	batch_size: 64
	d_model: 73
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.5379041199002736
	embedding_layers: 4
	encoder_heads: 2
	encoder_layers: 6
	learning_rate: 0.00010136150546433328
	max_steps: 3959
	net_layers: 8
	noise_std: 2.6107259302048447
2022-07-12 23:24:13 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=73 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.5379041199002736 --embedding_layers=4 --encoder_heads=2 --encoder_layers=6 --learning_rate=0.00010136150546433328 --max_steps=3959 --net_layers=8 --noise_std=2.6107259302048447
2022-07-12 23:24:18 INFO Running runs: ['crm61wwj']
2022-07-12 23:33:41 INFO Cleaning up finished run: crm61wwj
2022-07-12 23:33:42 INFO Agent received command: run
2022-07-12 23:33:42 INFO Agent starting run with config:
	batch_size: 128
	d_model: 76
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.4532406386176867
	embedding_layers: 6
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.00027291934302227985
	max_steps: 3421
	net_layers: 4
	noise_std: 0.4106719079222293
2022-07-12 23:33:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=76 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.4532406386176867 --embedding_layers=6 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.00027291934302227985 --max_steps=3421 --net_layers=4 --noise_std=0.4106719079222293
2022-07-12 23:33:47 INFO Running runs: ['kscmxanh']
2022-07-12 23:41:42 INFO Cleaning up finished run: kscmxanh
2022-07-12 23:41:43 INFO Agent received command: run
2022-07-12 23:41:43 INFO Agent starting run with config:
	batch_size: 128
	d_model: 82
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.6409323722636845
	embedding_layers: 7
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.0008226911553349111
	max_steps: 4036
	net_layers: 8
	noise_std: 0.13348329115734614
2022-07-12 23:41:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=82 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.6409323722636845 --embedding_layers=7 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.0008226911553349111 --max_steps=4036 --net_layers=8 --noise_std=0.13348329115734614
2022-07-12 23:41:48 INFO Running runs: ['cglibdjw']
2022-07-12 23:53:38 INFO Cleaning up finished run: cglibdjw
2022-07-12 23:53:39 INFO Agent received command: run
2022-07-12 23:53:39 INFO Agent starting run with config:
	batch_size: 128
	d_model: 59
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.5954877266441114
	embedding_layers: 4
	encoder_heads: 3
	encoder_layers: 3
	learning_rate: 0.0004715104987604961
	max_steps: 2246
	net_layers: 7
	noise_std: 0.14946211576900414
2022-07-12 23:53:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=59 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.5954877266441114 --embedding_layers=4 --encoder_heads=3 --encoder_layers=3 --learning_rate=0.0004715104987604961 --max_steps=2246 --net_layers=7 --noise_std=0.14946211576900414
2022-07-12 23:53:44 INFO Running runs: ['pe4bv2t8']
2022-07-12 23:58:55 INFO Cleaning up finished run: pe4bv2t8
2022-07-12 23:58:55 INFO Agent received command: run
2022-07-12 23:58:55 INFO Agent starting run with config:
	batch_size: 128
	d_model: 60
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.49331214282467806
	embedding_layers: 5
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0008281632672736474
	max_steps: 3629
	net_layers: 4
	noise_std: 0.2563076818116033
2022-07-12 23:58:55 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=60 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.49331214282467806 --embedding_layers=5 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0008281632672736474 --max_steps=3629 --net_layers=4 --noise_std=0.2563076818116033
2022-07-12 23:59:00 INFO Running runs: ['fgocqace']
2022-07-13 00:04:22 INFO Cleaning up finished run: fgocqace
2022-07-13 00:04:23 INFO Agent received command: run
2022-07-13 00:04:23 INFO Agent starting run with config:
	batch_size: 128
	d_model: 36
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.6050086482637288
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00055569133003961
	max_steps: 3732
	net_layers: 1
	noise_std: 0.32892009527123706
2022-07-13 00:04:23 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=36 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.6050086482637288 --embedding_layers=6 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00055569133003961 --max_steps=3732 --net_layers=1 --noise_std=0.32892009527123706
2022-07-13 00:04:28 INFO Running runs: ['t64w72y0']
2022-07-13 00:09:44 INFO Cleaning up finished run: t64w72y0
2022-07-13 00:09:45 INFO Agent received command: run
2022-07-13 00:09:45 INFO Agent starting run with config:
	batch_size: 128
	d_model: 101
	decoder_heads: 5
	decoder_layers: 5
	early_stopping: 0.4406022395804267
	embedding_layers: 1
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0008047981538142024
	max_steps: 3193
	net_layers: 1
	noise_std: 0.174207225157961
2022-07-13 00:09:45 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=101 --decoder_heads=5 --decoder_layers=5 --early_stopping=0.4406022395804267 --embedding_layers=1 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0008047981538142024 --max_steps=3193 --net_layers=1 --noise_std=0.174207225157961
2022-07-13 00:09:50 INFO Running runs: ['zhftiax4']
2022-07-13 00:17:40 INFO Cleaning up finished run: zhftiax4
2022-07-13 00:17:42 INFO Agent received command: run
2022-07-13 00:17:42 INFO Agent starting run with config:
	batch_size: 128
	d_model: 115
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.5870030485973902
	embedding_layers: 5
	encoder_heads: 4
	encoder_layers: 5
	learning_rate: 0.0005536995079867338
	max_steps: 2925
	net_layers: 2
	noise_std: 0.3826016021587785
2022-07-13 00:17:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=115 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.5870030485973902 --embedding_layers=5 --encoder_heads=4 --encoder_layers=5 --learning_rate=0.0005536995079867338 --max_steps=2925 --net_layers=2 --noise_std=0.3826016021587785
2022-07-13 00:17:47 INFO Running runs: ['u5caf5pi']
2022-07-13 00:34:03 INFO Cleaning up finished run: u5caf5pi
2022-07-13 00:34:04 INFO Agent received command: run
2022-07-13 00:34:04 INFO Agent starting run with config:
	batch_size: 128
	d_model: 89
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.545635965601236
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0005114706899253102
	max_steps: 2319
	net_layers: 3
	noise_std: 0.10372274931293328
2022-07-13 00:34:04 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=89 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.545635965601236 --embedding_layers=3 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0005114706899253102 --max_steps=2319 --net_layers=3 --noise_std=0.10372274931293328
2022-07-13 00:34:09 INFO Running runs: ['mszacdn8']
2022-07-13 00:40:21 INFO Cleaning up finished run: mszacdn8
2022-07-13 00:40:22 INFO Agent received command: run
2022-07-13 00:40:22 INFO Agent starting run with config:
	batch_size: 128
	d_model: 82
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.8280340887682833
	embedding_layers: 8
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.00023203148031703132
	max_steps: 2662
	net_layers: 2
	noise_std: 0.12175059405835012
2022-07-13 00:40:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=82 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.8280340887682833 --embedding_layers=8 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.00023203148031703132 --max_steps=2662 --net_layers=2 --noise_std=0.12175059405835012
2022-07-13 00:40:27 INFO Running runs: ['4gy7eww3']
2022-07-13 00:50:41 INFO Cleaning up finished run: 4gy7eww3
2022-07-13 00:50:43 INFO Agent received command: run
2022-07-13 00:50:43 INFO Agent starting run with config:
	batch_size: 128
	d_model: 75
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.6533764358460917
	embedding_layers: 5
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.00047315033444206154
	max_steps: 3482
	net_layers: 2
	noise_std: 0.14726184053672248
2022-07-13 00:50:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=75 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.6533764358460917 --embedding_layers=5 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.00047315033444206154 --max_steps=3482 --net_layers=2 --noise_std=0.14726184053672248
2022-07-13 00:50:48 INFO Running runs: ['n34a3aty']
2022-07-13 00:55:48 INFO Cleaning up finished run: n34a3aty
2022-07-13 00:55:49 INFO Agent received command: run
2022-07-13 00:55:49 INFO Agent starting run with config:
	batch_size: 128
	d_model: 52
	decoder_heads: 2
	decoder_layers: 1
	early_stopping: 0.4636495777722971
	embedding_layers: 1
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.0009281405697064096
	max_steps: 2532
	net_layers: 1
	noise_std: 0.28563698606624593
2022-07-13 00:55:49 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=52 --decoder_heads=2 --decoder_layers=1 --early_stopping=0.4636495777722971 --embedding_layers=1 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.0009281405697064096 --max_steps=2532 --net_layers=1 --noise_std=0.28563698606624593
2022-07-13 00:55:54 INFO Running runs: ['2ochm76n']
2022-07-13 00:59:28 INFO Cleaning up finished run: 2ochm76n
2022-07-13 00:59:28 INFO Agent received command: run
2022-07-13 00:59:28 INFO Agent starting run with config:
	batch_size: 128
	d_model: 48
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.09470812076620529
	embedding_layers: 1
	encoder_heads: 2
	encoder_layers: 3
	learning_rate: 0.0005308063691801378
	max_steps: 2531
	net_layers: 1
	noise_std: 0.19810093927845204
2022-07-13 00:59:28 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=48 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.09470812076620529 --embedding_layers=1 --encoder_heads=2 --encoder_layers=3 --learning_rate=0.0005308063691801378 --max_steps=2531 --net_layers=1 --noise_std=0.19810093927845204
2022-07-13 00:59:33 INFO Running runs: ['vi6xmva9']
2022-07-13 01:02:34 INFO Cleaning up finished run: vi6xmva9
2022-07-13 01:02:35 INFO Agent received command: run
2022-07-13 01:02:35 INFO Agent starting run with config:
	batch_size: 128
	d_model: 63
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.8204146663939549
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.00091396995133054
	max_steps: 2909
	net_layers: 4
	noise_std: 0.15232939717285326
2022-07-13 01:02:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=63 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.8204146663939549 --embedding_layers=4 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.00091396995133054 --max_steps=2909 --net_layers=4 --noise_std=0.15232939717285326
2022-07-13 01:02:40 INFO Running runs: ['bto5qmli']
2022-07-13 01:07:51 INFO Cleaning up finished run: bto5qmli
2022-07-13 01:07:51 INFO Agent received command: run
2022-07-13 01:07:51 INFO Agent starting run with config:
	batch_size: 128
	d_model: 76
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.111008672487491
	embedding_layers: 4
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.0006087505463437282
	max_steps: 2817
	net_layers: 4
	noise_std: 0.1065922375119534
2022-07-13 01:07:51 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=76 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.111008672487491 --embedding_layers=4 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.0006087505463437282 --max_steps=2817 --net_layers=4 --noise_std=0.1065922375119534
2022-07-13 01:07:56 INFO Running runs: ['52xw9z4t']
2022-07-13 01:13:04 INFO Cleaning up finished run: 52xw9z4t
2022-07-13 01:13:05 INFO Agent received command: run
2022-07-13 01:13:05 INFO Agent starting run with config:
	batch_size: 128
	d_model: 64
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.6196039332512263
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 6
	learning_rate: 0.0007330100974190881
	max_steps: 2670
	net_layers: 2
	noise_std: 0.4670756957699995
2022-07-13 01:13:05 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=64 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.6196039332512263 --embedding_layers=2 --encoder_heads=1 --encoder_layers=6 --learning_rate=0.0007330100974190881 --max_steps=2670 --net_layers=2 --noise_std=0.4670756957699995
2022-07-13 01:13:10 INFO Running runs: ['n3d1y8dr']
2022-07-13 01:19:44 INFO Cleaning up finished run: n3d1y8dr
2022-07-13 01:19:44 INFO Agent received command: run
2022-07-13 01:19:44 INFO Agent starting run with config:
	batch_size: 128
	d_model: 81
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.27148113843044924
	embedding_layers: 6
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.00033253877368210726
	max_steps: 2409
	net_layers: 1
	noise_std: 0.693598705444841
2022-07-13 01:19:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=81 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.27148113843044924 --embedding_layers=6 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.00033253877368210726 --max_steps=2409 --net_layers=1 --noise_std=0.693598705444841
2022-07-13 01:19:49 INFO Running runs: ['tresdbtd']
2022-07-13 01:25:04 INFO Cleaning up finished run: tresdbtd
2022-07-13 01:25:05 INFO Agent received command: run
2022-07-13 01:25:05 INFO Agent starting run with config:
	batch_size: 128
	d_model: 39
	decoder_heads: 1
	decoder_layers: 11
	early_stopping: 0.02265332845349553
	embedding_layers: 7
	encoder_heads: 5
	encoder_layers: 6
	learning_rate: 0.000873188300392941
	max_steps: 4287
	net_layers: 1
	noise_std: 0.1223131768498093
2022-07-13 01:25:05 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=39 --decoder_heads=1 --decoder_layers=11 --early_stopping=0.02265332845349553 --embedding_layers=7 --encoder_heads=5 --encoder_layers=6 --learning_rate=0.000873188300392941 --max_steps=4287 --net_layers=1 --noise_std=0.1223131768498093
2022-07-13 01:25:10 INFO Running runs: ['d3fgdd9r']
2022-07-13 01:33:48 INFO Cleaning up finished run: d3fgdd9r
2022-07-13 01:33:48 INFO Agent received command: run
2022-07-13 01:33:48 INFO Agent starting run with config:
	batch_size: 128
	d_model: 100
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.3633624938834643
	embedding_layers: 2
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.0007123972227006952
	max_steps: 2013
	net_layers: 2
	noise_std: 0.3508843388319757
2022-07-13 01:33:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=100 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.3633624938834643 --embedding_layers=2 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.0007123972227006952 --max_steps=2013 --net_layers=2 --noise_std=0.3508843388319757
2022-07-13 01:33:53 INFO Running runs: ['d3q1jbxs']
2022-07-13 01:37:53 INFO Cleaning up finished run: d3q1jbxs
2022-07-13 01:37:54 INFO Agent received command: run
2022-07-13 01:37:54 INFO Agent starting run with config:
	batch_size: 128
	d_model: 73
	decoder_heads: 5
	decoder_layers: 4
	early_stopping: 0.6726943101453782
	embedding_layers: 4
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.0006323084213450924
	max_steps: 3606
	net_layers: 2
	noise_std: 0.13869780278489835
2022-07-13 01:37:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=73 --decoder_heads=5 --decoder_layers=4 --early_stopping=0.6726943101453782 --embedding_layers=4 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.0006323084213450924 --max_steps=3606 --net_layers=2 --noise_std=0.13869780278489835
2022-07-13 01:37:59 INFO Running runs: ['3tlc297t']
2022-07-13 01:44:26 INFO Cleaning up finished run: 3tlc297t
2022-07-13 01:44:27 INFO Agent received command: run
2022-07-13 01:44:27 INFO Agent starting run with config:
	batch_size: 128
	d_model: 67
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.30082651224241924
	embedding_layers: 2
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.00038514589403142115
	max_steps: 2657
	net_layers: 2
	noise_std: 0.1597560078005392
2022-07-13 01:44:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=67 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.30082651224241924 --embedding_layers=2 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.00038514589403142115 --max_steps=2657 --net_layers=2 --noise_std=0.1597560078005392
2022-07-13 01:44:32 INFO Running runs: ['b5qqfa90']
2022-07-13 01:47:48 INFO Cleaning up finished run: b5qqfa90
2022-07-13 01:47:48 INFO Agent received command: run
2022-07-13 01:47:48 INFO Agent starting run with config:
	batch_size: 64
	d_model: 33
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.8538968916061773
	embedding_layers: 1
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0006398761537286021
	max_steps: 2278
	net_layers: 1
	noise_std: 0.16809504280636642
2022-07-13 01:47:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=33 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.8538968916061773 --embedding_layers=1 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0006398761537286021 --max_steps=2278 --net_layers=1 --noise_std=0.16809504280636642
2022-07-13 01:47:53 INFO Running runs: ['klwm6w0g']
2022-07-13 01:51:16 INFO Cleaning up finished run: klwm6w0g
2022-07-13 01:51:17 INFO Agent received command: run
2022-07-13 01:51:17 INFO Agent starting run with config:
	batch_size: 64
	d_model: 83
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.4748598800483205
	embedding_layers: 1
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.000455515230503553
	max_steps: 2652
	net_layers: 1
	noise_std: 0.38225404622194115
2022-07-13 01:51:17 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=83 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.4748598800483205 --embedding_layers=1 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.000455515230503553 --max_steps=2652 --net_layers=1 --noise_std=0.38225404622194115
2022-07-13 01:51:22 INFO Running runs: ['ducjkn3z']
2022-07-13 01:54:22 INFO Cleaning up finished run: ducjkn3z
2022-07-13 01:54:22 INFO Agent received command: run
2022-07-13 01:54:22 INFO Agent starting run with config:
	batch_size: 128
	d_model: 90
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.4003626590489933
	embedding_layers: 2
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.0005301144143400935
	max_steps: 2073
	net_layers: 1
	noise_std: 0.11989934169201288
2022-07-13 01:54:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=90 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.4003626590489933 --embedding_layers=2 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.0005301144143400935 --max_steps=2073 --net_layers=1 --noise_std=0.11989934169201288
2022-07-13 01:54:27 INFO Running runs: ['n9d8lb5v']
2022-07-13 01:59:00 INFO Cleaning up finished run: n9d8lb5v
2022-07-13 01:59:01 INFO Agent received command: run
2022-07-13 01:59:01 INFO Agent starting run with config:
	batch_size: 64
	d_model: 53
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.002171556869760638
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 5
	learning_rate: 0.0008517243533491573
	max_steps: 2602
	net_layers: 4
	noise_std: 0.10343863483584212
2022-07-13 01:59:01 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=53 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.002171556869760638 --embedding_layers=2 --encoder_heads=1 --encoder_layers=5 --learning_rate=0.0008517243533491573 --max_steps=2602 --net_layers=4 --noise_std=0.10343863483584212
2022-07-13 01:59:06 INFO Running runs: ['j369xduy']
2022-07-13 02:03:05 INFO Cleaning up finished run: j369xduy
2022-07-13 02:03:06 INFO Agent received command: run
2022-07-13 02:03:06 INFO Agent starting run with config:
	batch_size: 128
	d_model: 61
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.685818783987601
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.0005404106191495285
	max_steps: 3838
	net_layers: 3
	noise_std: 0.21746439870117515
2022-07-13 02:03:06 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=61 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.685818783987601 --embedding_layers=8 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.0005404106191495285 --max_steps=3838 --net_layers=3 --noise_std=0.21746439870117515
2022-07-13 02:03:11 INFO Running runs: ['pkt6e90x']
2022-07-13 02:10:43 INFO Cleaning up finished run: pkt6e90x
2022-07-13 02:10:44 INFO Agent received command: run
2022-07-13 02:10:44 INFO Agent starting run with config:
	batch_size: 128
	d_model: 123
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.2990540576036855
	embedding_layers: 7
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.0003919742933995797
	max_steps: 2696
	net_layers: 6
	noise_std: 0.18737563890275433
2022-07-13 02:10:44 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=123 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.2990540576036855 --embedding_layers=7 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.0003919742933995797 --max_steps=2696 --net_layers=6 --noise_std=0.18737563890275433
2022-07-13 02:10:49 INFO Running runs: ['l18qj8b2']
2022-07-13 02:20:46 INFO Cleaning up finished run: l18qj8b2
2022-07-13 02:20:47 INFO Agent received command: run
2022-07-13 02:20:47 INFO Agent starting run with config:
	batch_size: 128
	d_model: 78
	decoder_heads: 3
	decoder_layers: 3
	early_stopping: 0.8802736537479895
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0005044182681281976
	max_steps: 4201
	net_layers: 5
	noise_std: 0.16567186352645316
2022-07-13 02:20:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=78 --decoder_heads=3 --decoder_layers=3 --early_stopping=0.8802736537479895 --embedding_layers=2 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0005044182681281976 --max_steps=4201 --net_layers=5 --noise_std=0.16567186352645316
2022-07-13 02:20:52 INFO Running runs: ['0y3ar807']
2022-07-13 02:27:41 INFO Cleaning up finished run: 0y3ar807
2022-07-13 02:27:48 INFO Running runs: []
2022-07-13 02:27:49 INFO Agent received command: run
2022-07-13 02:27:49 INFO Agent starting run with config:
	lightgbm_learning_rate: 3.706616846076993e-05
	max_bin: 119
	max_depth: 22
	min_data_in_leaf: 15
	num_iterations: 683
	num_leaves: 38
2022-07-13 02:27:49 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=3.706616846076993e-05 --max_bin=119 --max_depth=22 --min_data_in_leaf=15 --num_iterations=683 --num_leaves=38
2022-07-13 02:27:54 INFO Running runs: ['vseiy9mo']
2022-07-13 02:28:48 INFO Cleaning up finished run: vseiy9mo
2022-07-13 02:28:48 INFO Agent received command: run
2022-07-13 02:28:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00422167759318371
	max_bin: 75
	max_depth: 9
	min_data_in_leaf: 17
	num_iterations: 585
	num_leaves: 10
2022-07-13 02:28:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00422167759318371 --max_bin=75 --max_depth=9 --min_data_in_leaf=17 --num_iterations=585 --num_leaves=10
2022-07-13 02:28:53 INFO Running runs: ['267saedc']
2022-07-13 02:29:20 INFO Cleaning up finished run: 267saedc
2022-07-13 02:29:21 INFO Agent received command: run
2022-07-13 02:29:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00013349718400748506
	max_bin: 243
	max_depth: 25
	min_data_in_leaf: 22
	num_iterations: 958
	num_leaves: 13
2022-07-13 02:29:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00013349718400748506 --max_bin=243 --max_depth=25 --min_data_in_leaf=22 --num_iterations=958 --num_leaves=13
2022-07-13 02:29:26 INFO Running runs: ['887kj5ok']
2022-07-13 02:30:03 INFO Cleaning up finished run: 887kj5ok
2022-07-13 02:30:04 INFO Agent received command: run
2022-07-13 02:30:04 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0005042573399991132
	max_bin: 47
	max_depth: 11
	min_data_in_leaf: 29
	num_iterations: 400
	num_leaves: 9
2022-07-13 02:30:04 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0005042573399991132 --max_bin=47 --max_depth=11 --min_data_in_leaf=29 --num_iterations=400 --num_leaves=9
2022-07-13 02:30:09 INFO Running runs: ['sac6k9ij']
2022-07-13 02:30:30 INFO Cleaning up finished run: sac6k9ij
2022-07-13 02:30:31 INFO Agent received command: run
2022-07-13 02:30:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 9.51266320739007e-05
	max_bin: 101
	max_depth: 19
	min_data_in_leaf: 15
	num_iterations: 836
	num_leaves: 23
2022-07-13 02:30:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=9.51266320739007e-05 --max_bin=101 --max_depth=19 --min_data_in_leaf=15 --num_iterations=836 --num_leaves=23
2022-07-13 02:30:36 INFO Running runs: ['quwtjhhl']
2022-07-13 02:31:31 INFO Cleaning up finished run: quwtjhhl
2022-07-13 02:31:31 INFO Agent received command: run
2022-07-13 02:31:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.006289022927273854
	max_bin: 127
	max_depth: 11
	min_data_in_leaf: 14
	num_iterations: 496
	num_leaves: 13
2022-07-13 02:31:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.006289022927273854 --max_bin=127 --max_depth=11 --min_data_in_leaf=14 --num_iterations=496 --num_leaves=13
2022-07-13 02:31:36 INFO Running runs: ['xpi0791d']
2022-07-13 02:32:03 INFO Cleaning up finished run: xpi0791d
2022-07-13 02:32:04 INFO Agent received command: run
2022-07-13 02:32:04 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.010845989978046762
	max_bin: 112
	max_depth: 6
	min_data_in_leaf: 10
	num_iterations: 487
	num_leaves: 8
2022-07-13 02:32:04 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.010845989978046762 --max_bin=112 --max_depth=6 --min_data_in_leaf=10 --num_iterations=487 --num_leaves=8
2022-07-13 02:32:09 INFO Running runs: ['zlzfqylw']
2022-07-13 02:32:30 INFO Cleaning up finished run: zlzfqylw
2022-07-13 02:32:31 INFO Agent received command: run
2022-07-13 02:32:31 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03822669499588195
	max_bin: 112
	max_depth: 13
	min_data_in_leaf: 12
	num_iterations: 198
	num_leaves: 12
2022-07-13 02:32:31 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03822669499588195 --max_bin=112 --max_depth=13 --min_data_in_leaf=12 --num_iterations=198 --num_leaves=12
2022-07-13 02:32:36 INFO Running runs: ['65eenuhr']
2022-07-13 02:32:52 INFO Cleaning up finished run: 65eenuhr
2022-07-13 02:32:53 INFO Agent received command: run
2022-07-13 02:32:53 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09361924500337349
	max_bin: 118
	max_depth: 4
	min_data_in_leaf: 12
	num_iterations: 269
	num_leaves: 18
2022-07-13 02:32:53 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09361924500337349 --max_bin=118 --max_depth=4 --min_data_in_leaf=12 --num_iterations=269 --num_leaves=18
2022-07-13 02:32:58 INFO Running runs: ['pjt4k18i']
2022-07-13 02:33:14 INFO Cleaning up finished run: pjt4k18i
2022-07-13 02:33:15 INFO Agent received command: run
2022-07-13 02:33:15 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04889662436724322
	max_bin: 75
	max_depth: 11
	min_data_in_leaf: 14
	num_iterations: 549
	num_leaves: 9
2022-07-13 02:33:15 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04889662436724322 --max_bin=75 --max_depth=11 --min_data_in_leaf=14 --num_iterations=549 --num_leaves=9
2022-07-13 02:33:20 INFO Running runs: ['9hikwhm8']
2022-07-13 02:33:36 INFO Cleaning up finished run: 9hikwhm8
2022-07-13 02:33:37 INFO Agent received command: run
2022-07-13 02:33:37 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05192813884213909
	max_bin: 207
	max_depth: 10
	min_data_in_leaf: 18
	num_iterations: 392
	num_leaves: 11
2022-07-13 02:33:37 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05192813884213909 --max_bin=207 --max_depth=10 --min_data_in_leaf=18 --num_iterations=392 --num_leaves=11
2022-07-13 02:33:42 INFO Running runs: ['dy7w0sup']
2022-07-13 02:33:58 INFO Cleaning up finished run: dy7w0sup
2022-07-13 02:33:59 INFO Agent received command: run
2022-07-13 02:33:59 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07715170375758629
	max_bin: 123
	max_depth: 10
	min_data_in_leaf: 14
	num_iterations: 448
	num_leaves: 6
2022-07-13 02:33:59 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07715170375758629 --max_bin=123 --max_depth=10 --min_data_in_leaf=14 --num_iterations=448 --num_leaves=6
2022-07-13 02:34:04 INFO Running runs: ['2fej7tsb']
2022-07-13 02:34:26 INFO Cleaning up finished run: 2fej7tsb
2022-07-13 02:34:26 INFO Agent received command: run
2022-07-13 02:34:26 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05864047078761582
	max_bin: 250
	max_depth: 8
	min_data_in_leaf: 14
	num_iterations: 174
	num_leaves: 15
2022-07-13 02:34:26 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05864047078761582 --max_bin=250 --max_depth=8 --min_data_in_leaf=14 --num_iterations=174 --num_leaves=15
2022-07-13 02:34:31 INFO Running runs: ['4ibqjjhn']
2022-07-13 02:34:53 INFO Cleaning up finished run: 4ibqjjhn
2022-07-13 02:34:54 INFO Agent received command: run
2022-07-13 02:34:54 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05444883811218653
	max_bin: 139
	max_depth: 9
	min_data_in_leaf: 14
	num_iterations: 633
	num_leaves: 14
2022-07-13 02:34:54 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05444883811218653 --max_bin=139 --max_depth=9 --min_data_in_leaf=14 --num_iterations=633 --num_leaves=14
2022-07-13 02:34:59 INFO Running runs: ['gx2zaw8l']
2022-07-13 02:35:20 INFO Cleaning up finished run: gx2zaw8l
2022-07-13 02:35:21 INFO Agent received command: run
2022-07-13 02:35:21 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03082837331673216
	max_bin: 176
	max_depth: 5
	min_data_in_leaf: 18
	num_iterations: 289
	num_leaves: 14
2022-07-13 02:35:21 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03082837331673216 --max_bin=176 --max_depth=5 --min_data_in_leaf=18 --num_iterations=289 --num_leaves=14
2022-07-13 02:35:26 INFO Running runs: ['ciaxhs8b']
2022-07-13 02:35:47 INFO Cleaning up finished run: ciaxhs8b
2022-07-13 02:35:48 INFO Agent received command: run
2022-07-13 02:35:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07945433416509544
	max_bin: 169
	max_depth: 5
	min_data_in_leaf: 15
	num_iterations: 730
	num_leaves: 6
2022-07-13 02:35:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07945433416509544 --max_bin=169 --max_depth=5 --min_data_in_leaf=15 --num_iterations=730 --num_leaves=6
2022-07-13 02:35:53 INFO Running runs: ['1a12k988']
2022-07-13 02:36:09 INFO Cleaning up finished run: 1a12k988
2022-07-13 02:36:10 INFO Agent received command: run
2022-07-13 02:36:10 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09725524359272188
	max_bin: 227
	max_depth: 4
	min_data_in_leaf: 18
	num_iterations: 589
	num_leaves: 10
2022-07-13 02:36:10 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09725524359272188 --max_bin=227 --max_depth=4 --min_data_in_leaf=18 --num_iterations=589 --num_leaves=10
2022-07-13 02:36:15 INFO Running runs: ['qst5f6au']
2022-07-13 02:36:31 INFO Cleaning up finished run: qst5f6au
2022-07-13 02:36:32 INFO Agent received command: run
2022-07-13 02:36:32 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09944311370690756
	max_bin: 32
	max_depth: 6
	min_data_in_leaf: 12
	num_iterations: 788
	num_leaves: 14
2022-07-13 02:36:32 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09944311370690756 --max_bin=32 --max_depth=6 --min_data_in_leaf=12 --num_iterations=788 --num_leaves=14
2022-07-13 02:36:37 INFO Running runs: ['4bo2qc0u']
2022-07-13 02:36:53 INFO Cleaning up finished run: 4bo2qc0u
2022-07-13 02:36:54 INFO Agent received command: run
2022-07-13 02:36:54 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05093792115191203
	max_bin: 31
	max_depth: 4
	min_data_in_leaf: 12
	num_iterations: 277
	num_leaves: 20
2022-07-13 02:36:54 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05093792115191203 --max_bin=31 --max_depth=4 --min_data_in_leaf=12 --num_iterations=277 --num_leaves=20
2022-07-13 02:36:59 INFO Running runs: ['n7kxtrbw']
2022-07-13 02:37:15 INFO Cleaning up finished run: n7kxtrbw
2022-07-13 02:37:16 INFO Agent received command: run
2022-07-13 02:37:16 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09388473571701132
	max_bin: 179
	max_depth: 6
	min_data_in_leaf: 14
	num_iterations: 451
	num_leaves: 7
2022-07-13 02:37:16 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09388473571701132 --max_bin=179 --max_depth=6 --min_data_in_leaf=14 --num_iterations=451 --num_leaves=7
2022-07-13 02:37:21 INFO Running runs: ['jy9kj8op']
2022-07-13 02:37:37 INFO Cleaning up finished run: jy9kj8op
2022-07-13 02:37:38 INFO Agent received command: run
2022-07-13 02:37:38 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.03699351470098689
	max_bin: 50
	max_depth: 5
	min_data_in_leaf: 13
	num_iterations: 197
	num_leaves: 5
2022-07-13 02:37:38 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.03699351470098689 --max_bin=50 --max_depth=5 --min_data_in_leaf=13 --num_iterations=197 --num_leaves=5
2022-07-13 02:37:43 INFO Running runs: ['1q23pcue']
2022-07-13 02:37:59 INFO Cleaning up finished run: 1q23pcue
2022-07-13 02:38:00 INFO Agent received command: run
2022-07-13 02:38:00 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07955865781976543
	max_bin: 53
	max_depth: 6
	min_data_in_leaf: 11
	num_iterations: 448
	num_leaves: 19
2022-07-13 02:38:00 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07955865781976543 --max_bin=53 --max_depth=6 --min_data_in_leaf=11 --num_iterations=448 --num_leaves=19
2022-07-13 02:38:05 INFO Running runs: ['q3sjwbll']
2022-07-13 02:38:22 INFO Cleaning up finished run: q3sjwbll
2022-07-13 02:38:22 INFO Agent received command: run
2022-07-13 02:38:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09994503402661732
	max_bin: 47
	max_depth: 7
	min_data_in_leaf: 10
	num_iterations: 109
	num_leaves: 15
2022-07-13 02:38:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09994503402661732 --max_bin=47 --max_depth=7 --min_data_in_leaf=10 --num_iterations=109 --num_leaves=15
2022-07-13 02:38:27 INFO Running runs: ['koit83tl']
2022-07-13 02:38:43 INFO Cleaning up finished run: koit83tl
2022-07-13 02:38:44 INFO Agent received command: run
2022-07-13 02:38:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.056861878018120496
	max_bin: 66
	max_depth: 5
	min_data_in_leaf: 18
	num_iterations: 589
	num_leaves: 12
2022-07-13 02:38:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.056861878018120496 --max_bin=66 --max_depth=5 --min_data_in_leaf=18 --num_iterations=589 --num_leaves=12
2022-07-13 02:38:49 INFO Running runs: ['ebpv5maf']
2022-07-13 02:39:05 INFO Cleaning up finished run: ebpv5maf
2022-07-13 02:39:06 INFO Agent received command: run
2022-07-13 02:39:06 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.02733083259336312
	max_bin: 88
	max_depth: 6
	min_data_in_leaf: 17
	num_iterations: 506
	num_leaves: 11
2022-07-13 02:39:06 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.02733083259336312 --max_bin=88 --max_depth=6 --min_data_in_leaf=17 --num_iterations=506 --num_leaves=11
2022-07-13 02:39:11 INFO Running runs: ['y9in01lf']
2022-07-13 02:39:33 INFO Cleaning up finished run: y9in01lf
2022-07-13 02:39:33 INFO Agent received command: run
2022-07-13 02:39:33 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07751175006704826
	max_bin: 181
	max_depth: 6
	min_data_in_leaf: 16
	num_iterations: 212
	num_leaves: 40
2022-07-13 02:39:33 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07751175006704826 --max_bin=181 --max_depth=6 --min_data_in_leaf=16 --num_iterations=212 --num_leaves=40
2022-07-13 02:39:38 INFO Running runs: ['pyw6bn6g']
2022-07-13 02:39:55 INFO Cleaning up finished run: pyw6bn6g
2022-07-13 02:39:56 INFO Agent received command: run
2022-07-13 02:39:56 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09812590317542227
	max_bin: 187
	max_depth: 8
	min_data_in_leaf: 17
	num_iterations: 432
	num_leaves: 14
2022-07-13 02:39:56 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09812590317542227 --max_bin=187 --max_depth=8 --min_data_in_leaf=17 --num_iterations=432 --num_leaves=14
2022-07-13 02:40:01 INFO Running runs: ['qpayci17']
2022-07-13 02:40:22 INFO Cleaning up finished run: qpayci17
2022-07-13 02:40:23 INFO Agent received command: run
2022-07-13 02:40:23 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04168803323036185
	max_bin: 209
	max_depth: 5
	min_data_in_leaf: 12
	num_iterations: 108
	num_leaves: 36
2022-07-13 02:40:23 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04168803323036185 --max_bin=209 --max_depth=5 --min_data_in_leaf=12 --num_iterations=108 --num_leaves=36
2022-07-13 02:40:28 INFO Running runs: ['v81ziz54']
2022-07-13 02:40:45 INFO Cleaning up finished run: v81ziz54
2022-07-13 02:40:45 INFO Agent received command: run
2022-07-13 02:40:45 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09012384637181148
	max_bin: 21
	max_depth: 10
	min_data_in_leaf: 15
	num_iterations: 389
	num_leaves: 6
2022-07-13 02:40:45 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09012384637181148 --max_bin=21 --max_depth=10 --min_data_in_leaf=15 --num_iterations=389 --num_leaves=6
2022-07-13 02:40:50 INFO Running runs: ['fop9lgzt']
2022-07-13 02:41:07 INFO Cleaning up finished run: fop9lgzt
2022-07-13 02:41:08 INFO Agent received command: run
2022-07-13 02:41:08 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.028719013847443457
	max_bin: 26
	max_depth: 6
	min_data_in_leaf: 14
	num_iterations: 665
	num_leaves: 5
2022-07-13 02:41:08 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 3 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.028719013847443457 --max_bin=26 --max_depth=6 --min_data_in_leaf=14 --num_iterations=665 --num_leaves=5
2022-07-13 02:41:13 INFO Running runs: ['gh0dcekq']
2022-07-13 02:41:30 INFO Cleaning up finished run: gh0dcekq
2022-07-13 02:41:38 INFO Running runs: []
2022-07-13 02:41:39 INFO Agent received command: run
2022-07-13 02:41:39 INFO Agent starting run with config:
	batch_size: 128
	d_model: 108
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.6192365894383675
	embedding_layers: 3
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.0009256214427138358
	max_steps: 3321
	net_layers: 3
	noise_std: 0.9170570340038994
2022-07-13 02:41:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=108 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.6192365894383675 --embedding_layers=3 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.0009256214427138358 --max_steps=3321 --net_layers=3 --noise_std=0.9170570340038994
2022-07-13 02:41:44 INFO Running runs: ['dksqs4su']
2022-07-13 02:43:17 INFO Cleaning up finished run: dksqs4su
2022-07-13 02:43:18 INFO Agent received command: run
2022-07-13 02:43:18 INFO Agent starting run with config:
	batch_size: 128
	d_model: 103
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 0.5674464696497992
	embedding_layers: 2
	encoder_heads: 2
	encoder_layers: 9
	learning_rate: 0.0005963604652410921
	max_steps: 2416
	net_layers: 6
	noise_std: 0.13174971490488233
2022-07-13 02:43:18 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=103 --decoder_heads=3 --decoder_layers=8 --early_stopping=0.5674464696497992 --embedding_layers=2 --encoder_heads=2 --encoder_layers=9 --learning_rate=0.0005963604652410921 --max_steps=2416 --net_layers=6 --noise_std=0.13174971490488233
2022-07-13 02:43:23 INFO Running runs: ['lg7g1wr4']
2022-07-13 02:45:17 INFO Cleaning up finished run: lg7g1wr4
2022-07-13 02:45:18 INFO Agent received command: run
2022-07-13 02:45:18 INFO Agent starting run with config:
	batch_size: 32
	d_model: 44
	decoder_heads: 1
	decoder_layers: 8
	early_stopping: 0.13177467075786453
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 12
	learning_rate: 0.00016274463057054355
	max_steps: 2180
	net_layers: 8
	noise_std: 0.5249950740655625
2022-07-13 02:45:18 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=44 --decoder_heads=1 --decoder_layers=8 --early_stopping=0.13177467075786453 --embedding_layers=3 --encoder_heads=1 --encoder_layers=12 --learning_rate=0.00016274463057054355 --max_steps=2180 --net_layers=8 --noise_std=0.5249950740655625
2022-07-13 02:45:23 INFO Running runs: ['t3j04oy3']
2022-07-13 02:47:06 INFO Cleaning up finished run: t3j04oy3
2022-07-13 02:47:07 INFO Agent received command: run
2022-07-13 02:47:07 INFO Agent starting run with config:
	batch_size: 32
	d_model: 47
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.8471713133068653
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 12
	learning_rate: 0.0002224346368012562
	max_steps: 3449
	net_layers: 7
	noise_std: 0.8878610869499565
2022-07-13 02:47:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=47 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.8471713133068653 --embedding_layers=8 --encoder_heads=2 --encoder_layers=12 --learning_rate=0.0002224346368012562 --max_steps=3449 --net_layers=7 --noise_std=0.8878610869499565
2022-07-13 02:47:12 INFO Running runs: ['irinelfy']
2022-07-13 02:49:28 INFO Cleaning up finished run: irinelfy
2022-07-13 02:49:29 INFO Agent received command: run
2022-07-13 02:49:29 INFO Agent starting run with config:
	batch_size: 128
	d_model: 46
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.7697142384773759
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 9
	learning_rate: 0.0009594961814764198
	max_steps: 4291
	net_layers: 7
	noise_std: 0.26922726839414596
2022-07-13 02:49:29 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=46 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.7697142384773759 --embedding_layers=2 --encoder_heads=1 --encoder_layers=9 --learning_rate=0.0009594961814764198 --max_steps=4291 --net_layers=7 --noise_std=0.26922726839414596
2022-07-13 02:49:34 INFO Running runs: ['xlk3g7a4']
2022-07-13 02:51:56 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-13 02:51:56 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-13 02:52:04 INFO Running runs: []
2022-07-13 02:52:05 INFO Agent received command: run
2022-07-13 02:52:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.01264855786528645
	max_bin: 26
	max_depth: 12
	min_data_in_leaf: 28
	num_iterations: 855
	num_leaves: 15
2022-07-13 02:52:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.01264855786528645 --max_bin=26 --max_depth=12 --min_data_in_leaf=28 --num_iterations=855 --num_leaves=15
2022-07-13 02:52:10 INFO Running runs: ['wybxdknh']
2022-07-13 02:52:26 INFO Cleaning up finished run: wybxdknh
2022-07-13 02:52:27 INFO Agent received command: run
2022-07-13 02:52:27 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0016755031846138015
	max_bin: 98
	max_depth: 5
	min_data_in_leaf: 29
	num_iterations: 789
	num_leaves: 19
2022-07-13 02:52:27 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0016755031846138015 --max_bin=98 --max_depth=5 --min_data_in_leaf=29 --num_iterations=789 --num_leaves=19
2022-07-13 02:52:32 INFO Running runs: ['6n5qtdag']
2022-07-13 02:52:48 INFO Cleaning up finished run: 6n5qtdag
2022-07-13 02:52:48 INFO Agent received command: run
2022-07-13 02:52:48 INFO Agent starting run with config:
	lightgbm_learning_rate: 8.87507597879834e-05
	max_bin: 136
	max_depth: 30
	min_data_in_leaf: 12
	num_iterations: 146
	num_leaves: 8
2022-07-13 02:52:48 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=8.87507597879834e-05 --max_bin=136 --max_depth=30 --min_data_in_leaf=12 --num_iterations=146 --num_leaves=8
2022-07-13 02:52:53 INFO Running runs: ['a0j51sis']
2022-07-13 02:53:04 INFO Cleaning up finished run: a0j51sis
2022-07-13 02:53:05 INFO Agent received command: run
2022-07-13 02:53:05 INFO Agent starting run with config:
	lightgbm_learning_rate: 8.855557626790124e-05
	max_bin: 110
	max_depth: 26
	min_data_in_leaf: 22
	num_iterations: 531
	num_leaves: 39
2022-07-13 02:53:05 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=8.855557626790124e-05 --max_bin=110 --max_depth=26 --min_data_in_leaf=22 --num_iterations=531 --num_leaves=39
2022-07-13 02:53:10 INFO Running runs: ['xgs5luml']
2022-07-13 02:53:26 INFO Cleaning up finished run: xgs5luml
2022-07-13 02:53:27 INFO Agent received command: run
2022-07-13 02:53:27 INFO Agent starting run with config:
	lightgbm_learning_rate: 2.664347344741992e-05
	max_bin: 41
	max_depth: 31
	min_data_in_leaf: 13
	num_iterations: 352
	num_leaves: 36
2022-07-13 02:53:27 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=2.664347344741992e-05 --max_bin=41 --max_depth=31 --min_data_in_leaf=13 --num_iterations=352 --num_leaves=36
2022-07-13 02:53:32 INFO Running runs: ['i2vly5xa']
2022-07-13 02:53:48 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-13 02:53:48 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-13 02:54:00 INFO Running runs: []
2022-07-13 02:54:00 INFO Agent received command: run
2022-07-13 02:54:00 INFO Agent starting run with config:
	batch_size: 32
	d_model: 79
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.3084785056367139
	embedding_layers: 7
	encoder_heads: 3
	encoder_layers: 3
	learning_rate: 0.0006253456487668374
	max_steps: 4174
	net_layers: 5
	noise_std: 0.14465981717233248
2022-07-13 02:54:00 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=79 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.3084785056367139 --embedding_layers=7 --encoder_heads=3 --encoder_layers=3 --learning_rate=0.0006253456487668374 --max_steps=4174 --net_layers=5 --noise_std=0.14465981717233248
2022-07-13 02:54:05 INFO Running runs: ['1eumr0cw']
2022-07-13 02:55:49 INFO Cleaning up finished run: 1eumr0cw
2022-07-13 02:55:50 INFO Agent received command: run
2022-07-13 02:55:50 INFO Agent starting run with config:
	batch_size: 128
	d_model: 42
	decoder_heads: 4
	decoder_layers: 5
	early_stopping: 0.177718150999012
	embedding_layers: 2
	encoder_heads: 4
	encoder_layers: 2
	learning_rate: 0.000930291660166694
	max_steps: 2149
	net_layers: 3
	noise_std: 0.15946640068860515
2022-07-13 02:55:50 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=42 --decoder_heads=4 --decoder_layers=5 --early_stopping=0.177718150999012 --embedding_layers=2 --encoder_heads=4 --encoder_layers=2 --learning_rate=0.000930291660166694 --max_steps=2149 --net_layers=3 --noise_std=0.15946640068860515
2022-07-13 02:55:55 INFO Running runs: ['6dykxqn4']
2022-07-13 02:56:57 INFO Cleaning up finished run: 6dykxqn4
2022-07-13 02:56:58 INFO Agent received command: run
2022-07-13 02:56:58 INFO Agent starting run with config:
	batch_size: 64
	d_model: 122
	decoder_heads: 2
	decoder_layers: 7
	early_stopping: 0.4514761923114235
	embedding_layers: 8
	encoder_heads: 1
	encoder_layers: 12
	learning_rate: 0.00010448990484406194
	max_steps: 2683
	net_layers: 5
	noise_std: 2.648378984538388
2022-07-13 02:56:58 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=122 --decoder_heads=2 --decoder_layers=7 --early_stopping=0.4514761923114235 --embedding_layers=8 --encoder_heads=1 --encoder_layers=12 --learning_rate=0.00010448990484406194 --max_steps=2683 --net_layers=5 --noise_std=2.648378984538388
2022-07-13 02:57:03 INFO Running runs: ['xnyzwwix']
2022-07-13 03:00:13 INFO Cleaning up finished run: xnyzwwix
2022-07-13 03:00:14 INFO Agent received command: run
2022-07-13 03:00:14 INFO Agent starting run with config:
	batch_size: 128
	d_model: 118
	decoder_heads: 4
	decoder_layers: 6
	early_stopping: 0.7722738348052035
	embedding_layers: 1
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0007940318677125474
	max_steps: 4583
	net_layers: 1
	noise_std: 0.59307299313844
2022-07-13 03:00:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=118 --decoder_heads=4 --decoder_layers=6 --early_stopping=0.7722738348052035 --embedding_layers=1 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0007940318677125474 --max_steps=4583 --net_layers=1 --noise_std=0.59307299313844
2022-07-13 03:00:19 INFO Running runs: ['loeweit3']
2022-07-13 03:04:41 INFO Cleaning up finished run: loeweit3
2022-07-13 03:04:42 INFO Agent received command: run
2022-07-13 03:04:42 INFO Agent starting run with config:
	batch_size: 32
	d_model: 41
	decoder_heads: 3
	decoder_layers: 12
	early_stopping: 0.3453289212182669
	embedding_layers: 3
	encoder_heads: 5
	encoder_layers: 12
	learning_rate: 0.00016342128013052164
	max_steps: 4849
	net_layers: 7
	noise_std: 0.6787615666130967
2022-07-13 03:04:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=41 --decoder_heads=3 --decoder_layers=12 --early_stopping=0.3453289212182669 --embedding_layers=3 --encoder_heads=5 --encoder_layers=12 --learning_rate=0.00016342128013052164 --max_steps=4849 --net_layers=7 --noise_std=0.6787615666130967
2022-07-13 03:04:47 INFO Running runs: ['3tn4peh9']
2022-07-13 03:07:08 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-13 03:07:08 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-13 03:07:16 INFO Running runs: []
2022-07-13 03:07:17 INFO Agent received command: run
2022-07-13 03:07:17 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0024632288573440994
	max_bin: 170
	max_depth: 15
	min_data_in_leaf: 20
	num_iterations: 676
	num_leaves: 18
2022-07-13 03:07:17 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0024632288573440994 --max_bin=170 --max_depth=15 --min_data_in_leaf=20 --num_iterations=676 --num_leaves=18
2022-07-13 03:07:22 INFO Running runs: ['jao70d10']
2022-07-13 03:07:38 INFO Cleaning up finished run: jao70d10
2022-07-13 03:07:39 INFO Agent received command: run
2022-07-13 03:07:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 2.277695028243425e-05
	max_bin: 245
	max_depth: 30
	min_data_in_leaf: 26
	num_iterations: 934
	num_leaves: 11
2022-07-13 03:07:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=2.277695028243425e-05 --max_bin=245 --max_depth=30 --min_data_in_leaf=26 --num_iterations=934 --num_leaves=11
2022-07-13 03:07:44 INFO Running runs: ['d3nliam2']
2022-07-13 03:08:01 INFO Cleaning up finished run: d3nliam2
2022-07-13 03:08:01 INFO Agent received command: run
2022-07-13 03:08:01 INFO Agent starting run with config:
	lightgbm_learning_rate: 3.4416575369849215e-05
	max_bin: 29
	max_depth: 4
	min_data_in_leaf: 11
	num_iterations: 102
	num_leaves: 19
2022-07-13 03:08:01 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=3.4416575369849215e-05 --max_bin=29 --max_depth=4 --min_data_in_leaf=11 --num_iterations=102 --num_leaves=19
2022-07-13 03:08:06 INFO Running runs: ['critax19']
2022-07-13 03:08:17 INFO Cleaning up finished run: critax19
2022-07-13 03:08:18 INFO Agent received command: run
2022-07-13 03:08:18 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.007131470829397935
	max_bin: 52
	max_depth: 4
	min_data_in_leaf: 29
	num_iterations: 900
	num_leaves: 10
2022-07-13 03:08:18 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.007131470829397935 --max_bin=52 --max_depth=4 --min_data_in_leaf=29 --num_iterations=900 --num_leaves=10
2022-07-13 03:08:23 INFO Running runs: ['aq7tl8fu']
2022-07-13 03:08:39 INFO Cleaning up finished run: aq7tl8fu
2022-07-13 03:08:40 INFO Agent received command: run
2022-07-13 03:08:40 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07099514487912015
	max_bin: 142
	max_depth: 14
	min_data_in_leaf: 30
	num_iterations: 149
	num_leaves: 40
2022-07-13 03:08:40 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 5 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07099514487912015 --max_bin=142 --max_depth=14 --min_data_in_leaf=30 --num_iterations=149 --num_leaves=40
2022-07-13 03:08:45 INFO Running runs: ['e7jyobn3']
2022-07-13 03:08:58 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-13 03:08:58 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-13 03:09:06 INFO Running runs: []
2022-07-13 03:09:06 INFO Agent received command: run
2022-07-13 03:09:06 INFO Agent starting run with config:
	batch_size: 128
	d_model: 126
	decoder_heads: 4
	decoder_layers: 10
	early_stopping: 0.7905087254916756
	embedding_layers: 5
	encoder_heads: 4
	encoder_layers: 10
	learning_rate: 0.00016187168613597484
	max_steps: 4307
	net_layers: 7
	noise_std: 0.15395766665813035
2022-07-13 03:09:06 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=126 --decoder_heads=4 --decoder_layers=10 --early_stopping=0.7905087254916756 --embedding_layers=5 --encoder_heads=4 --encoder_layers=10 --learning_rate=0.00016187168613597484 --max_steps=4307 --net_layers=7 --noise_std=0.15395766665813035
2022-07-13 03:09:11 INFO Running runs: ['7d0s8ltm']
2022-07-13 03:29:26 INFO Cleaning up finished run: 7d0s8ltm
2022-07-13 03:29:27 INFO Agent received command: run
2022-07-13 03:29:27 INFO Agent starting run with config:
	batch_size: 32
	d_model: 50
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.8398709528973892
	embedding_layers: 8
	encoder_heads: 5
	encoder_layers: 2
	learning_rate: 0.0001452138724397464
	max_steps: 3396
	net_layers: 6
	noise_std: 0.10974972869977774
2022-07-13 03:29:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=50 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.8398709528973892 --embedding_layers=8 --encoder_heads=5 --encoder_layers=2 --learning_rate=0.0001452138724397464 --max_steps=3396 --net_layers=6 --noise_std=0.10974972869977774
2022-07-13 03:29:32 INFO Running runs: ['ala0c5ms']
2022-07-13 03:31:42 INFO Cleaning up finished run: ala0c5ms
2022-07-13 03:31:43 INFO Agent received command: run
2022-07-13 03:31:43 INFO Agent starting run with config:
	batch_size: 32
	d_model: 121
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.026541877391758863
	embedding_layers: 8
	encoder_heads: 1
	encoder_layers: 11
	learning_rate: 0.0007586312284727697
	max_steps: 2641
	net_layers: 6
	noise_std: 2.987335072014462
2022-07-13 03:31:43 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=121 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.026541877391758863 --embedding_layers=8 --encoder_heads=1 --encoder_layers=11 --learning_rate=0.0007586312284727697 --max_steps=2641 --net_layers=6 --noise_std=2.987335072014462
2022-07-13 03:31:48 INFO Running runs: ['0u89tzxp']
2022-07-13 03:33:47 INFO Cleaning up finished run: 0u89tzxp
2022-07-13 03:33:48 INFO Agent received command: run
2022-07-13 03:33:48 INFO Agent starting run with config:
	batch_size: 64
	d_model: 48
	decoder_heads: 2
	decoder_layers: 2
	early_stopping: 0.8793926470840747
	embedding_layers: 1
	encoder_heads: 5
	encoder_layers: 6
	learning_rate: 0.0005551546653158801
	max_steps: 3459
	net_layers: 3
	noise_std: 1.7147260724767808
2022-07-13 03:33:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=48 --decoder_heads=2 --decoder_layers=2 --early_stopping=0.8793926470840747 --embedding_layers=1 --encoder_heads=5 --encoder_layers=6 --learning_rate=0.0005551546653158801 --max_steps=3459 --net_layers=3 --noise_std=1.7147260724767808
2022-07-13 03:33:53 INFO Running runs: ['o66vp5ko']
2022-07-13 03:37:25 INFO Cleaning up finished run: o66vp5ko
2022-07-13 03:37:26 INFO Agent received command: run
2022-07-13 03:37:26 INFO Agent starting run with config:
	batch_size: 64
	d_model: 103
	decoder_heads: 4
	decoder_layers: 7
	early_stopping: 0.02332760324035371
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 3
	learning_rate: 0.0001030128567912684
	max_steps: 4442
	net_layers: 4
	noise_std: 0.19421277267031123
2022-07-13 03:37:26 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=103 --decoder_heads=4 --decoder_layers=7 --early_stopping=0.02332760324035371 --embedding_layers=3 --encoder_heads=1 --encoder_layers=3 --learning_rate=0.0001030128567912684 --max_steps=4442 --net_layers=4 --noise_std=0.19421277267031123
2022-07-13 03:37:31 INFO Running runs: ['kz2vov1t']
2022-07-13 03:39:31 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-13 03:39:31 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-13 03:39:38 INFO Running runs: []
2022-07-13 03:39:39 INFO Agent received command: run
2022-07-13 03:39:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04373534642487702
	max_bin: 237
	max_depth: 8
	min_data_in_leaf: 26
	num_iterations: 211
	num_leaves: 39
2022-07-13 03:39:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04373534642487702 --max_bin=237 --max_depth=8 --min_data_in_leaf=26 --num_iterations=211 --num_leaves=39
2022-07-13 03:39:44 INFO Running runs: ['loevfpsb']
2022-07-13 03:39:55 INFO Cleaning up finished run: loevfpsb
2022-07-13 03:39:55 INFO Agent received command: run
2022-07-13 03:39:55 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00401112697324347
	max_bin: 151
	max_depth: 17
	min_data_in_leaf: 19
	num_iterations: 276
	num_leaves: 17
2022-07-13 03:39:55 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00401112697324347 --max_bin=151 --max_depth=17 --min_data_in_leaf=19 --num_iterations=276 --num_leaves=17
2022-07-13 03:40:00 INFO Running runs: ['ls7dfzny']
2022-07-13 03:40:17 INFO Cleaning up finished run: ls7dfzny
2022-07-13 03:40:17 INFO Agent received command: run
2022-07-13 03:40:17 INFO Agent starting run with config:
	lightgbm_learning_rate: 8.741553009537878e-05
	max_bin: 19
	max_depth: 31
	min_data_in_leaf: 24
	num_iterations: 926
	num_leaves: 17
2022-07-13 03:40:17 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=8.741553009537878e-05 --max_bin=19 --max_depth=31 --min_data_in_leaf=24 --num_iterations=926 --num_leaves=17
2022-07-13 03:40:22 INFO Running runs: ['kxr25lwq']
2022-07-13 03:40:39 INFO Cleaning up finished run: kxr25lwq
2022-07-13 03:40:39 INFO Agent received command: run
2022-07-13 03:40:39 INFO Agent starting run with config:
	lightgbm_learning_rate: 9.543380644110368e-05
	max_bin: 103
	max_depth: 30
	min_data_in_leaf: 14
	num_iterations: 963
	num_leaves: 5
2022-07-13 03:40:39 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=9.543380644110368e-05 --max_bin=103 --max_depth=30 --min_data_in_leaf=14 --num_iterations=963 --num_leaves=5
2022-07-13 03:40:44 INFO Running runs: ['8dsof6sy']
2022-07-13 03:41:01 INFO Cleaning up finished run: 8dsof6sy
2022-07-13 03:41:01 INFO Agent received command: run
2022-07-13 03:41:01 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05618684721859023
	max_bin: 197
	max_depth: 28
	min_data_in_leaf: 27
	num_iterations: 929
	num_leaves: 21
2022-07-13 03:41:01 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 6 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05618684721859023 --max_bin=197 --max_depth=28 --min_data_in_leaf=27 --num_iterations=929 --num_leaves=21
2022-07-13 03:41:06 INFO Running runs: ['ontfnkpu']
2022-07-13 03:41:17 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-13 03:41:17 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-13 03:41:25 INFO Running runs: []
2022-07-13 03:41:25 INFO Agent received command: run
2022-07-13 03:41:25 INFO Agent starting run with config:
	batch_size: 128
	d_model: 32
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.2077878777873763
	embedding_layers: 8
	encoder_heads: 5
	encoder_layers: 9
	learning_rate: 0.000621771835482959
	max_steps: 4957
	net_layers: 8
	noise_std: 2.9294975312607656
2022-07-13 03:41:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=32 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.2077878777873763 --embedding_layers=8 --encoder_heads=5 --encoder_layers=9 --learning_rate=0.000621771835482959 --max_steps=4957 --net_layers=8 --noise_std=2.9294975312607656
2022-07-13 03:41:30 INFO Running runs: ['a4c7bvxz']
2022-07-13 03:48:47 INFO Cleaning up finished run: a4c7bvxz
2022-07-13 03:48:47 INFO Agent received command: run
2022-07-13 03:48:47 INFO Agent starting run with config:
	batch_size: 128
	d_model: 109
	decoder_heads: 5
	decoder_layers: 7
	early_stopping: 0.5934408356828272
	embedding_layers: 2
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.000964781782630932
	max_steps: 2481
	net_layers: 3
	noise_std: 0.21295634704764396
2022-07-13 03:48:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=109 --decoder_heads=5 --decoder_layers=7 --early_stopping=0.5934408356828272 --embedding_layers=2 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.000964781782630932 --max_steps=2481 --net_layers=3 --noise_std=0.21295634704764396
2022-07-13 03:48:52 INFO Running runs: ['7syy43v4']
2022-07-13 03:56:53 INFO Cleaning up finished run: 7syy43v4
2022-07-13 03:56:54 INFO Agent received command: run
2022-07-13 03:56:54 INFO Agent starting run with config:
	batch_size: 64
	d_model: 114
	decoder_heads: 4
	decoder_layers: 3
	early_stopping: 0.3777334619959054
	embedding_layers: 4
	encoder_heads: 4
	encoder_layers: 7
	learning_rate: 0.00013630936800680703
	max_steps: 4854
	net_layers: 1
	noise_std: 0.26732322685525006
2022-07-13 03:56:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=114 --decoder_heads=4 --decoder_layers=3 --early_stopping=0.3777334619959054 --embedding_layers=4 --encoder_heads=4 --encoder_layers=7 --learning_rate=0.00013630936800680703 --max_steps=4854 --net_layers=1 --noise_std=0.26732322685525006
2022-07-13 03:56:59 INFO Running runs: ['i62n7zua']
2022-07-13 04:11:12 INFO Cleaning up finished run: i62n7zua
2022-07-13 04:11:12 INFO Agent received command: run
2022-07-13 04:11:12 INFO Agent starting run with config:
	batch_size: 128
	d_model: 115
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.364345805917566
	embedding_layers: 3
	encoder_heads: 5
	encoder_layers: 3
	learning_rate: 0.00019627081310727977
	max_steps: 4867
	net_layers: 3
	noise_std: 0.4539700223137206
2022-07-13 04:11:12 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=115 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.364345805917566 --embedding_layers=3 --encoder_heads=5 --encoder_layers=3 --learning_rate=0.00019627081310727977 --max_steps=4867 --net_layers=3 --noise_std=0.4539700223137206
2022-07-13 04:11:17 INFO Running runs: ['55d0chy4']
2022-07-13 04:22:30 INFO Cleaning up finished run: 55d0chy4
2022-07-13 04:22:31 INFO Agent received command: run
2022-07-13 04:22:31 INFO Agent starting run with config:
	batch_size: 64
	d_model: 123
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.30782034693934995
	embedding_layers: 3
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.0001746855331488174
	max_steps: 4546
	net_layers: 4
	noise_std: 0.11487126991708584
2022-07-13 04:22:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=123 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.30782034693934995 --embedding_layers=3 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.0001746855331488174 --max_steps=4546 --net_layers=4 --noise_std=0.11487126991708584
2022-07-13 04:22:36 INFO Running runs: ['hk9q71n3']
2022-07-13 04:32:35 INFO Cleaning up finished run: hk9q71n3
2022-07-13 04:32:36 INFO Agent received command: run
2022-07-13 04:32:36 INFO Agent starting run with config:
	batch_size: 128
	d_model: 95
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.4255141219189358
	embedding_layers: 1
	encoder_heads: 4
	encoder_layers: 8
	learning_rate: 0.0001008867141827075
	max_steps: 3774
	net_layers: 1
	noise_std: 0.13026824655834943
2022-07-13 04:32:36 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=95 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.4255141219189358 --embedding_layers=1 --encoder_heads=4 --encoder_layers=8 --learning_rate=0.0001008867141827075 --max_steps=3774 --net_layers=1 --noise_std=0.13026824655834943
2022-07-13 04:32:41 INFO Running runs: ['b1uo752y']
2022-07-13 04:42:31 INFO Cleaning up finished run: b1uo752y
2022-07-13 04:42:32 INFO Agent received command: run
2022-07-13 04:42:32 INFO Agent starting run with config:
	batch_size: 128
	d_model: 124
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.33406865675356234
	embedding_layers: 1
	encoder_heads: 3
	encoder_layers: 3
	learning_rate: 0.00010682377583936822
	max_steps: 4636
	net_layers: 1
	noise_std: 0.11723881924100116
2022-07-13 04:42:32 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=124 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.33406865675356234 --embedding_layers=1 --encoder_heads=3 --encoder_layers=3 --learning_rate=0.00010682377583936822 --max_steps=4636 --net_layers=1 --noise_std=0.11723881924100116
2022-07-13 04:42:37 INFO Running runs: ['i4cuqzwr']
2022-07-13 04:52:35 INFO Cleaning up finished run: i4cuqzwr
2022-07-13 04:52:35 INFO Agent received command: run
2022-07-13 04:52:35 INFO Agent starting run with config:
	batch_size: 32
	d_model: 125
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.5508450965675369
	embedding_layers: 2
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00018261861865987903
	max_steps: 2606
	net_layers: 1
	noise_std: 0.9485827935308686
2022-07-13 04:52:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=125 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.5508450965675369 --embedding_layers=2 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00018261861865987903 --max_steps=2606 --net_layers=1 --noise_std=0.9485827935308686
2022-07-13 04:52:40 INFO Running runs: ['2i00hnyk']
2022-07-13 04:57:35 INFO Cleaning up finished run: 2i00hnyk
2022-07-13 04:57:35 INFO Agent received command: run
2022-07-13 04:57:35 INFO Agent starting run with config:
	batch_size: 128
	d_model: 125
	decoder_heads: 4
	decoder_layers: 7
	early_stopping: 0.7974042832421332
	embedding_layers: 1
	encoder_heads: 4
	encoder_layers: 12
	learning_rate: 0.00011000875129873385
	max_steps: 4580
	net_layers: 2
	noise_std: 0.16493547835740807
2022-07-13 04:57:35 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=125 --decoder_heads=4 --decoder_layers=7 --early_stopping=0.7974042832421332 --embedding_layers=1 --encoder_heads=4 --encoder_layers=12 --learning_rate=0.00011000875129873385 --max_steps=4580 --net_layers=2 --noise_std=0.16493547835740807
2022-07-13 04:57:40 INFO Running runs: ['487afahc']
2022-07-13 05:32:01 INFO Cleaning up finished run: 487afahc
2022-07-13 05:32:02 INFO Agent received command: run
2022-07-13 05:32:02 INFO Agent starting run with config:
	batch_size: 32
	d_model: 124
	decoder_heads: 3
	decoder_layers: 11
	early_stopping: 0.8983620328414862
	embedding_layers: 1
	encoder_heads: 4
	encoder_layers: 9
	learning_rate: 0.0001920910020885567
	max_steps: 4101
	net_layers: 4
	noise_std: 0.10148476605001748
2022-07-13 05:32:02 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=124 --decoder_heads=3 --decoder_layers=11 --early_stopping=0.8983620328414862 --embedding_layers=1 --encoder_heads=4 --encoder_layers=9 --learning_rate=0.0001920910020885567 --max_steps=4101 --net_layers=4 --noise_std=0.10148476605001748
2022-07-13 05:32:07 INFO Running runs: ['3qo4e6le']
2022-07-13 05:52:03 INFO Cleaning up finished run: 3qo4e6le
2022-07-13 05:52:04 INFO Agent received command: run
2022-07-13 05:52:04 INFO Agent starting run with config:
	batch_size: 128
	d_model: 124
	decoder_heads: 5
	decoder_layers: 7
	early_stopping: 0.6097685325907662
	embedding_layers: 4
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0001360976731315272
	max_steps: 4743
	net_layers: 1
	noise_std: 0.15224494647575473
2022-07-13 05:52:04 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=124 --decoder_heads=5 --decoder_layers=7 --early_stopping=0.6097685325907662 --embedding_layers=4 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0001360976731315272 --max_steps=4743 --net_layers=1 --noise_std=0.15224494647575473
2022-07-13 05:52:09 INFO Running runs: ['lovilwee']
2022-07-13 06:12:53 INFO Cleaning up finished run: lovilwee
2022-07-13 06:12:54 INFO Agent received command: run
2022-07-13 06:12:54 INFO Agent starting run with config:
	batch_size: 64
	d_model: 125
	decoder_heads: 4
	decoder_layers: 2
	early_stopping: 0.1443341428760578
	embedding_layers: 4
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.00012812753057941107
	max_steps: 4371
	net_layers: 4
	noise_std: 0.3864750205287732
2022-07-13 06:12:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=125 --decoder_heads=4 --decoder_layers=2 --early_stopping=0.1443341428760578 --embedding_layers=4 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.00012812753057941107 --max_steps=4371 --net_layers=4 --noise_std=0.3864750205287732
2022-07-13 06:12:59 INFO Running runs: ['ukm0xthx']
2022-07-13 06:19:26 INFO Cleaning up finished run: ukm0xthx
2022-07-13 06:19:27 INFO Agent received command: run
2022-07-13 06:19:27 INFO Agent starting run with config:
	batch_size: 128
	d_model: 126
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.8552286722231615
	embedding_layers: 2
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0001109636571816812
	max_steps: 4579
	net_layers: 4
	noise_std: 0.5611883993726432
2022-07-13 06:19:27 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=126 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.8552286722231615 --embedding_layers=2 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0001109636571816812 --max_steps=4579 --net_layers=4 --noise_std=0.5611883993726432
2022-07-13 06:19:32 INFO Running runs: ['8mbzotm4']
2022-07-13 06:37:59 INFO Cleaning up finished run: 8mbzotm4
2022-07-13 06:38:00 INFO Agent received command: run
2022-07-13 06:38:00 INFO Agent starting run with config:
	batch_size: 128
	d_model: 104
	decoder_heads: 4
	decoder_layers: 4
	early_stopping: 0.36941101970755263
	embedding_layers: 3
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.00011339185934365216
	max_steps: 4919
	net_layers: 2
	noise_std: 1.32560506268691
2022-07-13 06:38:00 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=104 --decoder_heads=4 --decoder_layers=4 --early_stopping=0.36941101970755263 --embedding_layers=3 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.00011339185934365216 --max_steps=4919 --net_layers=2 --noise_std=1.32560506268691
2022-07-13 06:38:05 INFO Running runs: ['ccosyfi6']
2022-07-13 06:45:04 INFO Cleaning up finished run: ccosyfi6
2022-07-13 06:45:05 INFO Agent received command: run
2022-07-13 06:45:05 INFO Agent starting run with config:
	batch_size: 64
	d_model: 127
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.21760346456490717
	embedding_layers: 2
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.0003839077591190374
	max_steps: 4588
	net_layers: 1
	noise_std: 0.3238825142024157
2022-07-13 06:45:05 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=127 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.21760346456490717 --embedding_layers=2 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.0003839077591190374 --max_steps=4588 --net_layers=1 --noise_std=0.3238825142024157
2022-07-13 06:45:10 INFO Running runs: ['ii74nah9']
2022-07-13 06:50:53 INFO Cleaning up finished run: ii74nah9
2022-07-13 06:50:54 INFO Agent received command: run
2022-07-13 06:50:54 INFO Agent starting run with config:
	batch_size: 128
	d_model: 122
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.8063565400505537
	embedding_layers: 2
	encoder_heads: 3
	encoder_layers: 7
	learning_rate: 0.0001395677946535264
	max_steps: 4258
	net_layers: 3
	noise_std: 0.13572415070036262
2022-07-13 06:50:54 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=122 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.8063565400505537 --embedding_layers=2 --encoder_heads=3 --encoder_layers=7 --learning_rate=0.0001395677946535264 --max_steps=4258 --net_layers=3 --noise_std=0.13572415070036262
2022-07-13 06:50:59 INFO Running runs: ['6p1adiur']
2022-07-13 07:07:38 INFO Cleaning up finished run: 6p1adiur
2022-07-13 07:07:38 INFO Agent received command: run
2022-07-13 07:07:38 INFO Agent starting run with config:
	batch_size: 128
	d_model: 102
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.03191763402598698
	embedding_layers: 1
	encoder_heads: 1
	encoder_layers: 2
	learning_rate: 0.0005076812245451213
	max_steps: 3790
	net_layers: 1
	noise_std: 0.7274822549043809
2022-07-13 07:07:38 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=102 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.03191763402598698 --embedding_layers=1 --encoder_heads=1 --encoder_layers=2 --learning_rate=0.0005076812245451213 --max_steps=3790 --net_layers=1 --noise_std=0.7274822549043809
2022-07-13 07:07:43 INFO Running runs: ['qu85sbrn']
2022-07-13 07:11:39 INFO Cleaning up finished run: qu85sbrn
2022-07-13 07:11:40 INFO Agent received command: run
2022-07-13 07:11:40 INFO Agent starting run with config:
	batch_size: 128
	d_model: 122
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.18720624208788816
	embedding_layers: 7
	encoder_heads: 2
	encoder_layers: 9
	learning_rate: 0.00013292735384267418
	max_steps: 3188
	net_layers: 2
	noise_std: 0.11879683432165664
2022-07-13 07:11:40 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=122 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.18720624208788816 --embedding_layers=7 --encoder_heads=2 --encoder_layers=9 --learning_rate=0.00013292735384267418 --max_steps=3188 --net_layers=2 --noise_std=0.11879683432165664
2022-07-13 07:11:45 INFO Running runs: ['5tw1z7w8']
2022-07-13 07:24:31 INFO Cleaning up finished run: 5tw1z7w8
2022-07-13 07:24:31 INFO Agent received command: run
2022-07-13 07:24:31 INFO Agent starting run with config:
	batch_size: 64
	d_model: 123
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.22459544875873533
	embedding_layers: 3
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.00023331161723598993
	max_steps: 2629
	net_layers: 2
	noise_std: 0.1885411880244321
2022-07-13 07:24:31 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=123 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.22459544875873533 --embedding_layers=3 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.00023331161723598993 --max_steps=2629 --net_layers=2 --noise_std=0.1885411880244321
2022-07-13 07:24:36 INFO Running runs: ['v2hosnz6']
2022-07-13 07:29:41 INFO Cleaning up finished run: v2hosnz6
2022-07-13 07:29:41 INFO Agent received command: run
2022-07-13 07:29:41 INFO Agent starting run with config:
	batch_size: 64
	d_model: 125
	decoder_heads: 3
	decoder_layers: 4
	early_stopping: 0.0062914613609984515
	embedding_layers: 7
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0002065566005076972
	max_steps: 4703
	net_layers: 1
	noise_std: 0.11625273691523086
2022-07-13 07:29:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=125 --decoder_heads=3 --decoder_layers=4 --early_stopping=0.0062914613609984515 --embedding_layers=7 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0002065566005076972 --max_steps=4703 --net_layers=1 --noise_std=0.11625273691523086
2022-07-13 07:29:46 INFO Running runs: ['0pff2zkc']
2022-07-13 07:36:46 INFO Cleaning up finished run: 0pff2zkc
2022-07-13 07:36:47 INFO Agent received command: run
2022-07-13 07:36:47 INFO Agent starting run with config:
	batch_size: 128
	d_model: 124
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.7270179170813184
	embedding_layers: 5
	encoder_heads: 1
	encoder_layers: 10
	learning_rate: 0.0001151379259144382
	max_steps: 3228
	net_layers: 2
	noise_std: 0.2620164085829544
2022-07-13 07:36:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=124 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.7270179170813184 --embedding_layers=5 --encoder_heads=1 --encoder_layers=10 --learning_rate=0.0001151379259144382 --max_steps=3228 --net_layers=2 --noise_std=0.2620164085829544
2022-07-13 07:36:52 INFO Running runs: ['sqe5oyck']
2022-07-13 07:50:59 INFO Cleaning up finished run: sqe5oyck
2022-07-13 07:51:00 INFO Agent received command: run
2022-07-13 07:51:00 INFO Agent starting run with config:
	batch_size: 128
	d_model: 108
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.5709106675907709
	embedding_layers: 1
	encoder_heads: 2
	encoder_layers: 8
	learning_rate: 0.0001139068218883295
	max_steps: 4074
	net_layers: 2
	noise_std: 2.114147969108051
2022-07-13 07:51:00 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=108 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.5709106675907709 --embedding_layers=1 --encoder_heads=2 --encoder_layers=8 --learning_rate=0.0001139068218883295 --max_steps=4074 --net_layers=2 --noise_std=2.114147969108051
2022-07-13 07:51:05 INFO Running runs: ['fktmgw61']
2022-07-13 08:04:31 INFO Cleaning up finished run: fktmgw61
2022-07-13 08:04:32 INFO Agent received command: run
2022-07-13 08:04:32 INFO Agent starting run with config:
	batch_size: 128
	d_model: 124
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.7441848883289496
	embedding_layers: 7
	encoder_heads: 3
	encoder_layers: 1
	learning_rate: 0.00023988973753900775
	max_steps: 3639
	net_layers: 4
	noise_std: 0.14820915296758433
2022-07-13 08:04:32 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=124 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.7441848883289496 --embedding_layers=7 --encoder_heads=3 --encoder_layers=1 --learning_rate=0.00023988973753900775 --max_steps=3639 --net_layers=4 --noise_std=0.14820915296758433
2022-07-13 08:04:37 INFO Running runs: ['n7rwg82j']
2022-07-13 08:12:20 INFO Cleaning up finished run: n7rwg82j
2022-07-13 08:12:21 INFO Agent received command: run
2022-07-13 08:12:21 INFO Agent starting run with config:
	batch_size: 128
	d_model: 118
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.24804437981546495
	embedding_layers: 5
	encoder_heads: 4
	encoder_layers: 4
	learning_rate: 0.0006577216870931661
	max_steps: 3911
	net_layers: 1
	noise_std: 0.13839481887920674
2022-07-13 08:12:21 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=118 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.24804437981546495 --embedding_layers=5 --encoder_heads=4 --encoder_layers=4 --learning_rate=0.0006577216870931661 --max_steps=3911 --net_layers=1 --noise_std=0.13839481887920674
2022-07-13 08:12:26 INFO Running runs: ['rwsh66f1']
2022-07-13 08:18:18 INFO Cleaning up finished run: rwsh66f1
2022-07-13 08:18:19 INFO Agent received command: run
2022-07-13 08:18:19 INFO Agent starting run with config:
	batch_size: 128
	d_model: 120
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.7248858225578586
	embedding_layers: 2
	encoder_heads: 3
	encoder_layers: 12
	learning_rate: 0.00020175281294799712
	max_steps: 4377
	net_layers: 1
	noise_std: 0.10698318333888296
2022-07-13 08:18:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=120 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.7248858225578586 --embedding_layers=2 --encoder_heads=3 --encoder_layers=12 --learning_rate=0.00020175281294799712 --max_steps=4377 --net_layers=1 --noise_std=0.10698318333888296
2022-07-13 08:18:24 INFO Running runs: ['ru60rj92']
2022-07-13 08:43:06 INFO Cleaning up finished run: ru60rj92
2022-07-13 08:43:06 INFO Agent received command: run
2022-07-13 08:43:06 INFO Agent starting run with config:
	batch_size: 128
	d_model: 127
	decoder_heads: 5
	decoder_layers: 2
	early_stopping: 0.5162228113413839
	embedding_layers: 5
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.0001292774946008631
	max_steps: 3292
	net_layers: 1
	noise_std: 0.3601238377960207
2022-07-13 08:43:06 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=127 --decoder_heads=5 --decoder_layers=2 --early_stopping=0.5162228113413839 --embedding_layers=5 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.0001292774946008631 --max_steps=3292 --net_layers=1 --noise_std=0.3601238377960207
2022-07-13 08:43:11 INFO Running runs: ['i1qprg3w']
2022-07-13 08:53:56 INFO Cleaning up finished run: i1qprg3w
2022-07-13 08:53:56 INFO Agent received command: run
2022-07-13 08:53:56 INFO Agent starting run with config:
	batch_size: 128
	d_model: 106
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.806265298532162
	embedding_layers: 2
	encoder_heads: 3
	encoder_layers: 2
	learning_rate: 0.00010701089944592488
	max_steps: 3565
	net_layers: 6
	noise_std: 0.5178761313291507
2022-07-13 08:53:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=106 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.806265298532162 --embedding_layers=2 --encoder_heads=3 --encoder_layers=2 --learning_rate=0.00010701089944592488 --max_steps=3565 --net_layers=6 --noise_std=0.5178761313291507
2022-07-13 08:54:01 INFO Running runs: ['p0nranis']
2022-07-13 09:01:21 INFO Cleaning up finished run: p0nranis
2022-07-13 09:01:22 INFO Agent received command: run
2022-07-13 09:01:22 INFO Agent starting run with config:
	batch_size: 64
	d_model: 120
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.07556836261839926
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.00010983280074493108
	max_steps: 3405
	net_layers: 4
	noise_std: 0.15133565002287272
2022-07-13 09:01:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=120 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.07556836261839926 --embedding_layers=3 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.00010983280074493108 --max_steps=3405 --net_layers=4 --noise_std=0.15133565002287272
2022-07-13 09:01:27 INFO Running runs: ['awpjkyoo']
2022-07-13 09:05:56 INFO Cleaning up finished run: awpjkyoo
2022-07-13 09:05:56 INFO Agent received command: run
2022-07-13 09:05:56 INFO Agent starting run with config:
	batch_size: 128
	d_model: 114
	decoder_heads: 4
	decoder_layers: 1
	early_stopping: 0.1127929255340601
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 3
	learning_rate: 0.00013814095034616296
	max_steps: 4992
	net_layers: 2
	noise_std: 0.10333124849774725
2022-07-13 09:05:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=114 --decoder_heads=4 --decoder_layers=1 --early_stopping=0.1127929255340601 --embedding_layers=6 --encoder_heads=2 --encoder_layers=3 --learning_rate=0.00013814095034616296 --max_steps=4992 --net_layers=2 --noise_std=0.10333124849774725
2022-07-13 09:06:01 INFO Running runs: ['vlacqc2l']
2022-07-13 09:15:07 INFO Cleaning up finished run: vlacqc2l
2022-07-13 09:15:07 INFO Agent received command: run
2022-07-13 09:15:07 INFO Agent starting run with config:
	batch_size: 64
	d_model: 94
	decoder_heads: 5
	decoder_layers: 1
	early_stopping: 0.5545017281211735
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 1
	learning_rate: 0.0003754383515479299
	max_steps: 2102
	net_layers: 4
	noise_std: 0.11476729718929612
2022-07-13 09:15:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=94 --decoder_heads=5 --decoder_layers=1 --early_stopping=0.5545017281211735 --embedding_layers=4 --encoder_heads=1 --encoder_layers=1 --learning_rate=0.0003754383515479299 --max_steps=2102 --net_layers=4 --noise_std=0.11476729718929612
2022-07-13 09:15:12 INFO Running runs: ['qwzbdwu3']
2022-07-13 09:18:22 INFO Cleaning up finished run: qwzbdwu3
2022-07-13 09:18:29 INFO Running runs: []
2022-07-13 09:18:30 INFO Agent received command: run
2022-07-13 09:18:30 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0021216289336353548
	max_bin: 168
	max_depth: 19
	min_data_in_leaf: 12
	num_iterations: 962
	num_leaves: 24
2022-07-13 09:18:30 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0021216289336353548 --max_bin=168 --max_depth=19 --min_data_in_leaf=12 --num_iterations=962 --num_leaves=24
2022-07-13 09:18:35 INFO Running runs: ['5o9afyfw']
2022-07-13 09:19:02 INFO Cleaning up finished run: 5o9afyfw
2022-07-13 09:19:03 INFO Agent received command: run
2022-07-13 09:19:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.004859446435278044
	max_bin: 241
	max_depth: 16
	min_data_in_leaf: 19
	num_iterations: 595
	num_leaves: 28
2022-07-13 09:19:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.004859446435278044 --max_bin=241 --max_depth=16 --min_data_in_leaf=19 --num_iterations=595 --num_leaves=28
2022-07-13 09:19:08 INFO Running runs: ['7pxdcvwo']
2022-07-13 09:19:30 INFO Cleaning up finished run: 7pxdcvwo
2022-07-13 09:19:30 INFO Agent received command: run
2022-07-13 09:19:30 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.002950314983136283
	max_bin: 170
	max_depth: 15
	min_data_in_leaf: 20
	num_iterations: 633
	num_leaves: 28
2022-07-13 09:19:30 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.002950314983136283 --max_bin=170 --max_depth=15 --min_data_in_leaf=20 --num_iterations=633 --num_leaves=28
2022-07-13 09:19:35 INFO Running runs: ['qrwdvzy8']
2022-07-13 09:19:57 INFO Cleaning up finished run: qrwdvzy8
2022-07-13 09:19:57 INFO Agent received command: run
2022-07-13 09:19:57 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06535812568994866
	max_bin: 188
	max_depth: 5
	min_data_in_leaf: 30
	num_iterations: 567
	num_leaves: 39
2022-07-13 09:19:57 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06535812568994866 --max_bin=188 --max_depth=5 --min_data_in_leaf=30 --num_iterations=567 --num_leaves=39
2022-07-13 09:20:02 INFO Running runs: ['j6g709oi']
2022-07-13 09:20:19 INFO Cleaning up finished run: j6g709oi
2022-07-13 09:20:19 INFO Agent received command: run
2022-07-13 09:20:19 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.02796201100840992
	max_bin: 250
	max_depth: 10
	min_data_in_leaf: 13
	num_iterations: 324
	num_leaves: 38
2022-07-13 09:20:19 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.02796201100840992 --max_bin=250 --max_depth=10 --min_data_in_leaf=13 --num_iterations=324 --num_leaves=38
2022-07-13 09:20:24 INFO Running runs: ['6y2whjuy']
2022-07-13 09:20:46 INFO Cleaning up finished run: 6y2whjuy
2022-07-13 09:20:46 INFO Agent received command: run
2022-07-13 09:20:46 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.008979523502238004
	max_bin: 196
	max_depth: 29
	min_data_in_leaf: 19
	num_iterations: 703
	num_leaves: 21
2022-07-13 09:20:46 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.008979523502238004 --max_bin=196 --max_depth=29 --min_data_in_leaf=19 --num_iterations=703 --num_leaves=21
2022-07-13 09:20:51 INFO Running runs: ['xpsv8z2l']
2022-07-13 09:21:13 INFO Cleaning up finished run: xpsv8z2l
2022-07-13 09:21:14 INFO Agent received command: run
2022-07-13 09:21:14 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00020246441102472824
	max_bin: 214
	max_depth: 9
	min_data_in_leaf: 28
	num_iterations: 587
	num_leaves: 19
2022-07-13 09:21:14 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00020246441102472824 --max_bin=214 --max_depth=9 --min_data_in_leaf=28 --num_iterations=587 --num_leaves=19
2022-07-13 09:21:19 INFO Running runs: ['s5zfwgfn']
2022-07-13 09:21:40 INFO Cleaning up finished run: s5zfwgfn
2022-07-13 09:21:41 INFO Agent received command: run
2022-07-13 09:21:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.020225911240896222
	max_bin: 236
	max_depth: 20
	min_data_in_leaf: 13
	num_iterations: 455
	num_leaves: 36
2022-07-13 09:21:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.020225911240896222 --max_bin=236 --max_depth=20 --min_data_in_leaf=13 --num_iterations=455 --num_leaves=36
2022-07-13 09:21:46 INFO Running runs: ['uxy4w1zd']
2022-07-13 09:22:07 INFO Cleaning up finished run: uxy4w1zd
2022-07-13 09:22:08 INFO Agent received command: run
2022-07-13 09:22:08 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04576103932967615
	max_bin: 220
	max_depth: 24
	min_data_in_leaf: 18
	num_iterations: 718
	num_leaves: 31
2022-07-13 09:22:08 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04576103932967615 --max_bin=220 --max_depth=24 --min_data_in_leaf=18 --num_iterations=718 --num_leaves=31
2022-07-13 09:22:13 INFO Running runs: ['rvkjievg']
2022-07-13 09:22:29 INFO Cleaning up finished run: rvkjievg
2022-07-13 09:22:29 INFO Agent received command: run
2022-07-13 09:22:29 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07973133005773611
	max_bin: 91
	max_depth: 11
	min_data_in_leaf: 11
	num_iterations: 552
	num_leaves: 40
2022-07-13 09:22:29 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07973133005773611 --max_bin=91 --max_depth=11 --min_data_in_leaf=11 --num_iterations=552 --num_leaves=40
2022-07-13 09:22:34 INFO Running runs: ['7oo4bdhn']
2022-07-13 09:22:51 INFO Cleaning up finished run: 7oo4bdhn
2022-07-13 09:22:51 INFO Agent received command: run
2022-07-13 09:22:51 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07755726864039116
	max_bin: 166
	max_depth: 16
	min_data_in_leaf: 21
	num_iterations: 432
	num_leaves: 40
2022-07-13 09:22:51 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07755726864039116 --max_bin=166 --max_depth=16 --min_data_in_leaf=21 --num_iterations=432 --num_leaves=40
2022-07-13 09:22:56 INFO Running runs: ['3dawydb3']
2022-07-13 09:23:12 INFO Cleaning up finished run: 3dawydb3
2022-07-13 09:23:13 INFO Agent received command: run
2022-07-13 09:23:13 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.027943987270476103
	max_bin: 208
	max_depth: 32
	min_data_in_leaf: 12
	num_iterations: 340
	num_leaves: 19
2022-07-13 09:23:13 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.027943987270476103 --max_bin=208 --max_depth=32 --min_data_in_leaf=12 --num_iterations=340 --num_leaves=19
2022-07-13 09:23:18 INFO Running runs: ['rec39zvv']
2022-07-13 09:23:34 INFO Cleaning up finished run: rec39zvv
2022-07-13 09:23:35 INFO Agent received command: run
2022-07-13 09:23:35 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04119415236856734
	max_bin: 84
	max_depth: 28
	min_data_in_leaf: 16
	num_iterations: 520
	num_leaves: 37
2022-07-13 09:23:35 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04119415236856734 --max_bin=84 --max_depth=28 --min_data_in_leaf=16 --num_iterations=520 --num_leaves=37
2022-07-13 09:23:40 INFO Running runs: ['rf46n7df']
2022-07-13 09:24:02 INFO Cleaning up finished run: rf46n7df
2022-07-13 09:24:03 INFO Agent received command: run
2022-07-13 09:24:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08975489132595975
	max_bin: 109
	max_depth: 28
	min_data_in_leaf: 11
	num_iterations: 554
	num_leaves: 17
2022-07-13 09:24:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08975489132595975 --max_bin=109 --max_depth=28 --min_data_in_leaf=11 --num_iterations=554 --num_leaves=17
2022-07-13 09:24:08 INFO Running runs: ['n3p197yn']
2022-07-13 09:24:24 INFO Cleaning up finished run: n3p197yn
2022-07-13 09:24:25 INFO Agent received command: run
2022-07-13 09:24:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06980750128118318
	max_bin: 205
	max_depth: 23
	min_data_in_leaf: 10
	num_iterations: 593
	num_leaves: 20
2022-07-13 09:24:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06980750128118318 --max_bin=205 --max_depth=23 --min_data_in_leaf=10 --num_iterations=593 --num_leaves=20
2022-07-13 09:24:30 INFO Running runs: ['cljk3up4']
2022-07-13 09:24:46 INFO Cleaning up finished run: cljk3up4
2022-07-13 09:24:46 INFO Agent received command: run
2022-07-13 09:24:46 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08653419365154233
	max_bin: 43
	max_depth: 18
	min_data_in_leaf: 11
	num_iterations: 188
	num_leaves: 18
2022-07-13 09:24:46 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08653419365154233 --max_bin=43 --max_depth=18 --min_data_in_leaf=11 --num_iterations=188 --num_leaves=18
2022-07-13 09:24:51 INFO Running runs: ['hyaden0k']
2022-07-13 09:25:07 INFO Cleaning up finished run: hyaden0k
2022-07-13 09:25:08 INFO Agent received command: run
2022-07-13 09:25:08 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09977136882334198
	max_bin: 107
	max_depth: 24
	min_data_in_leaf: 14
	num_iterations: 127
	num_leaves: 32
2022-07-13 09:25:08 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09977136882334198 --max_bin=107 --max_depth=24 --min_data_in_leaf=14 --num_iterations=127 --num_leaves=32
2022-07-13 09:25:13 INFO Running runs: ['h4rhprnv']
2022-07-13 09:25:35 INFO Cleaning up finished run: h4rhprnv
2022-07-13 09:25:35 INFO Agent received command: run
2022-07-13 09:25:35 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08043752670349602
	max_bin: 92
	max_depth: 5
	min_data_in_leaf: 12
	num_iterations: 167
	num_leaves: 40
2022-07-13 09:25:35 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08043752670349602 --max_bin=92 --max_depth=5 --min_data_in_leaf=12 --num_iterations=167 --num_leaves=40
2022-07-13 09:25:40 INFO Running runs: ['gmxss8kw']
2022-07-13 09:25:56 INFO Cleaning up finished run: gmxss8kw
2022-07-13 09:25:58 INFO Agent received command: run
2022-07-13 09:25:58 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08059655504066097
	max_bin: 195
	max_depth: 8
	min_data_in_leaf: 15
	num_iterations: 809
	num_leaves: 38
2022-07-13 09:25:58 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08059655504066097 --max_bin=195 --max_depth=8 --min_data_in_leaf=15 --num_iterations=809 --num_leaves=38
2022-07-13 09:26:03 INFO Running runs: ['5g9pk6am']
2022-07-13 09:26:19 INFO Cleaning up finished run: 5g9pk6am
2022-07-13 09:26:20 INFO Agent received command: run
2022-07-13 09:26:20 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08916511576635634
	max_bin: 130
	max_depth: 30
	min_data_in_leaf: 25
	num_iterations: 937
	num_leaves: 40
2022-07-13 09:26:20 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08916511576635634 --max_bin=130 --max_depth=30 --min_data_in_leaf=25 --num_iterations=937 --num_leaves=40
2022-07-13 09:26:25 INFO Running runs: ['nvga57gl']
2022-07-13 09:26:41 INFO Cleaning up finished run: nvga57gl
2022-07-13 09:26:41 INFO Agent received command: run
2022-07-13 09:26:41 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.06447189958945132
	max_bin: 253
	max_depth: 32
	min_data_in_leaf: 14
	num_iterations: 874
	num_leaves: 23
2022-07-13 09:26:41 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.06447189958945132 --max_bin=253 --max_depth=32 --min_data_in_leaf=14 --num_iterations=874 --num_leaves=23
2022-07-13 09:26:46 INFO Running runs: ['ej8m9a8l']
2022-07-13 09:27:03 INFO Cleaning up finished run: ej8m9a8l
2022-07-13 09:27:03 INFO Agent received command: run
2022-07-13 09:27:03 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.05081669253129569
	max_bin: 19
	max_depth: 23
	min_data_in_leaf: 26
	num_iterations: 122
	num_leaves: 40
2022-07-13 09:27:03 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.05081669253129569 --max_bin=19 --max_depth=23 --min_data_in_leaf=26 --num_iterations=122 --num_leaves=40
2022-07-13 09:27:08 INFO Running runs: ['8x1aguab']
2022-07-13 09:27:24 INFO Cleaning up finished run: 8x1aguab
2022-07-13 09:27:25 INFO Agent received command: run
2022-07-13 09:27:25 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.045252043015771425
	max_bin: 26
	max_depth: 31
	min_data_in_leaf: 18
	num_iterations: 886
	num_leaves: 5
2022-07-13 09:27:25 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.045252043015771425 --max_bin=26 --max_depth=31 --min_data_in_leaf=18 --num_iterations=886 --num_leaves=5
2022-07-13 09:27:30 INFO Running runs: ['95l207zt']
2022-07-13 09:27:46 INFO Cleaning up finished run: 95l207zt
2022-07-13 09:27:47 INFO Agent received command: run
2022-07-13 09:27:47 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.022004344199860103
	max_bin: 6
	max_depth: 4
	min_data_in_leaf: 20
	num_iterations: 209
	num_leaves: 40
2022-07-13 09:27:47 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.022004344199860103 --max_bin=6 --max_depth=4 --min_data_in_leaf=20 --num_iterations=209 --num_leaves=40
2022-07-13 09:27:52 INFO Running runs: ['09ki7jgi']
2022-07-13 09:28:08 INFO Cleaning up finished run: 09ki7jgi
2022-07-13 09:28:09 INFO Agent received command: run
2022-07-13 09:28:09 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09909328000196356
	max_bin: 165
	max_depth: 31
	min_data_in_leaf: 26
	num_iterations: 396
	num_leaves: 32
2022-07-13 09:28:09 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09909328000196356 --max_bin=165 --max_depth=31 --min_data_in_leaf=26 --num_iterations=396 --num_leaves=32
2022-07-13 09:28:14 INFO Running runs: ['kuc63kuc']
2022-07-13 09:28:30 INFO Cleaning up finished run: kuc63kuc
2022-07-13 09:28:30 INFO Agent received command: run
2022-07-13 09:28:30 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.07942842862072383
	max_bin: 17
	max_depth: 32
	min_data_in_leaf: 22
	num_iterations: 540
	num_leaves: 28
2022-07-13 09:28:30 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.07942842862072383 --max_bin=17 --max_depth=32 --min_data_in_leaf=22 --num_iterations=540 --num_leaves=28
2022-07-13 09:28:36 INFO Running runs: ['ewltpn7o']
2022-07-13 09:28:52 INFO Cleaning up finished run: ewltpn7o
2022-07-13 09:28:52 INFO Agent received command: run
2022-07-13 09:28:52 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08987475398908368
	max_bin: 220
	max_depth: 12
	min_data_in_leaf: 10
	num_iterations: 413
	num_leaves: 27
2022-07-13 09:28:52 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08987475398908368 --max_bin=220 --max_depth=12 --min_data_in_leaf=10 --num_iterations=413 --num_leaves=27
2022-07-13 09:28:57 INFO Running runs: ['c48jo7be']
2022-07-13 09:29:13 INFO Cleaning up finished run: c48jo7be
2022-07-13 09:29:14 INFO Agent received command: run
2022-07-13 09:29:14 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.08400970217261787
	max_bin: 214
	max_depth: 18
	min_data_in_leaf: 24
	num_iterations: 161
	num_leaves: 40
2022-07-13 09:29:14 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.08400970217261787 --max_bin=214 --max_depth=18 --min_data_in_leaf=24 --num_iterations=161 --num_leaves=40
2022-07-13 09:29:19 INFO Running runs: ['ibevsw33']
2022-07-13 09:29:35 INFO Cleaning up finished run: ibevsw33
2022-07-13 09:29:35 INFO Agent received command: run
2022-07-13 09:29:35 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.09850580749779998
	max_bin: 182
	max_depth: 19
	min_data_in_leaf: 15
	num_iterations: 114
	num_leaves: 38
2022-07-13 09:29:35 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.09850580749779998 --max_bin=182 --max_depth=19 --min_data_in_leaf=15 --num_iterations=114 --num_leaves=38
2022-07-13 09:29:41 INFO Running runs: ['80jomft8']
2022-07-13 09:29:57 INFO Cleaning up finished run: 80jomft8
2022-07-13 09:29:58 INFO Agent received command: run
2022-07-13 09:29:58 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.04240699256204001
	max_bin: 57
	max_depth: 29
	min_data_in_leaf: 27
	num_iterations: 182
	num_leaves: 40
2022-07-13 09:29:58 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 7 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.04240699256204001 --max_bin=57 --max_depth=29 --min_data_in_leaf=27 --num_iterations=182 --num_leaves=40
2022-07-13 09:30:03 INFO Running runs: ['y4wvh0ci']
2022-07-13 09:30:19 INFO Cleaning up finished run: y4wvh0ci
2022-07-13 09:30:21 ERROR Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
ValueError: Sweep cardiac-ml/missingness/jz8csqg0 not found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 97, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/cli/cli.py", line 1288, in agent
    wandb_agent.agent(sweep_id, entity=entity, project=project, count=count)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 606, in agent
    return run_agent(
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 548, in run_agent
    agent.run()
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/wandb_agent.py", line 181, in run
    sweep_obj = self._api.sweep(self._sweep_id, "{}")
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/internal.py", line 99, in sweep
    return self.api.sweep(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 61, in wrapper
    raise CommError(message, err).with_traceback(sys.exc_info()[2])
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/apis/normalize.py", line 25, in wrapper
    return func(*args, **kwargs)
  File "/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/wandb/sdk/internal/internal_api.py", line 599, in sweep
    raise ValueError(f"Sweep {entity}/{project}/{sweep} not found")
wandb.errors.CommError: Sweep cardiac-ml/missingness/jz8csqg0 not found

2022-07-13 09:30:28 INFO Running runs: []
2022-07-13 09:30:29 INFO Agent received command: run
2022-07-13 09:30:29 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.00012981725502149557
	max_bin: 128
	max_depth: 12
	min_data_in_leaf: 26
	num_iterations: 644
	num_leaves: 17
2022-07-13 09:30:29 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.00012981725502149557 --max_bin=128 --max_depth=12 --min_data_in_leaf=26 --num_iterations=644 --num_leaves=17
2022-07-13 09:30:34 INFO Running runs: ['1gq8dwqa']
2022-07-13 09:30:50 INFO Cleaning up finished run: 1gq8dwqa
2022-07-13 09:30:50 INFO Agent received command: run
2022-07-13 09:30:50 INFO Agent starting run with config:
	lightgbm_learning_rate: 2.6934113835135596e-05
	max_bin: 23
	max_depth: 19
	min_data_in_leaf: 29
	num_iterations: 908
	num_leaves: 11
2022-07-13 09:30:50 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=2.6934113835135596e-05 --max_bin=23 --max_depth=19 --min_data_in_leaf=29 --num_iterations=908 --num_leaves=11
2022-07-13 09:30:55 INFO Running runs: ['v8i69z7t']
2022-07-13 09:31:11 INFO Cleaning up finished run: v8i69z7t
2022-07-13 09:31:12 INFO Agent received command: run
2022-07-13 09:31:12 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.0001216396649985908
	max_bin: 235
	max_depth: 29
	min_data_in_leaf: 10
	num_iterations: 243
	num_leaves: 35
2022-07-13 09:31:12 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.0001216396649985908 --max_bin=235 --max_depth=29 --min_data_in_leaf=10 --num_iterations=243 --num_leaves=35
2022-07-13 09:31:17 INFO Running runs: ['8cirptue']
2022-07-13 09:31:33 INFO Cleaning up finished run: 8cirptue
2022-07-13 09:31:34 INFO Agent received command: run
2022-07-13 09:31:34 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.033322825515901114
	max_bin: 147
	max_depth: 32
	min_data_in_leaf: 16
	num_iterations: 170
	num_leaves: 28
2022-07-13 09:31:34 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.033322825515901114 --max_bin=147 --max_depth=32 --min_data_in_leaf=16 --num_iterations=170 --num_leaves=28
2022-07-13 09:31:39 INFO Running runs: ['mjnuamrm']
2022-07-13 09:31:55 INFO Cleaning up finished run: mjnuamrm
2022-07-13 09:31:55 INFO Agent received command: run
2022-07-13 09:31:55 INFO Agent starting run with config:
	lightgbm_learning_rate: 0.006056566426636663
	max_bin: 133
	max_depth: 30
	min_data_in_leaf: 12
	num_iterations: 878
	num_leaves: 7
2022-07-13 09:31:55 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 8 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=0.006056566426636663 --max_bin=133 --max_depth=30 --min_data_in_leaf=12 --num_iterations=878 --num_leaves=7
2022-07-13 09:32:00 INFO Running runs: ['d85vdcyp']
2022-07-13 09:32:16 ERROR Detected 5 failed runs in a row, shutting down.
2022-07-13 09:32:16 INFO To change this value set WANDB_AGENT_MAX_INITIAL_FAILURES=val
2022-07-13 09:32:24 INFO Running runs: []
2022-07-13 09:32:25 INFO Agent received command: run
2022-07-13 09:32:25 INFO Agent starting run with config:
	batch_size: 32
	d_model: 66
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.6407662357007131
	embedding_layers: 7
	encoder_heads: 2
	encoder_layers: 10
	learning_rate: 0.000132508782085886
	max_steps: 3392
	net_layers: 8
	noise_std: 0.2667941667569153
2022-07-13 09:32:25 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=66 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.6407662357007131 --embedding_layers=7 --encoder_heads=2 --encoder_layers=10 --learning_rate=0.000132508782085886 --max_steps=3392 --net_layers=8 --noise_std=0.2667941667569153
2022-07-13 09:32:30 INFO Running runs: ['1r0xt3sw']
2022-07-13 09:35:08 INFO Cleaning up finished run: 1r0xt3sw
2022-07-13 09:35:08 INFO Agent received command: run
2022-07-13 09:35:08 INFO Agent starting run with config:
	batch_size: 128
	d_model: 64
	decoder_heads: 2
	decoder_layers: 12
	early_stopping: 0.43766571415213407
	embedding_layers: 7
	encoder_heads: 2
	encoder_layers: 7
	learning_rate: 0.00011612081100989236
	max_steps: 4221
	net_layers: 4
	noise_std: 1.929652315126006
2022-07-13 09:35:08 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=64 --decoder_heads=2 --decoder_layers=12 --early_stopping=0.43766571415213407 --embedding_layers=7 --encoder_heads=2 --encoder_layers=7 --learning_rate=0.00011612081100989236 --max_steps=4221 --net_layers=4 --noise_std=1.929652315126006
2022-07-13 09:35:13 INFO Running runs: ['dwe22zw3']
2022-07-13 09:38:02 INFO Cleaning up finished run: dwe22zw3
2022-07-13 09:38:03 INFO Agent received command: run
2022-07-13 09:38:03 INFO Agent starting run with config:
	batch_size: 64
	d_model: 76
	decoder_heads: 5
	decoder_layers: 12
	early_stopping: 0.49493422430892503
	embedding_layers: 1
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.0006180721780075295
	max_steps: 2121
	net_layers: 2
	noise_std: 0.15097266289024625
2022-07-13 09:38:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=76 --decoder_heads=5 --decoder_layers=12 --early_stopping=0.49493422430892503 --embedding_layers=1 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.0006180721780075295 --max_steps=2121 --net_layers=2 --noise_std=0.15097266289024625
2022-07-13 09:38:08 INFO Running runs: ['b1n2y0vn']
2022-07-13 09:40:02 INFO Cleaning up finished run: b1n2y0vn
2022-07-13 09:40:03 INFO Agent received command: run
2022-07-13 09:40:03 INFO Agent starting run with config:
	batch_size: 32
	d_model: 88
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.15065580846773252
	embedding_layers: 2
	encoder_heads: 5
	encoder_layers: 12
	learning_rate: 0.0008375865662533179
	max_steps: 2885
	net_layers: 1
	noise_std: 2.5253944151206364
2022-07-13 09:40:03 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 9 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=88 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.15065580846773252 --embedding_layers=2 --encoder_heads=5 --encoder_layers=12 --learning_rate=0.0008375865662533179 --max_steps=2885 --net_layers=1 --noise_std=2.5253944151206364
2022-07-13 09:40:08 INFO Running runs: ['6iw893d1']
2022-07-13 10:02:40 INFO Running runs: []
2022-07-13 10:02:41 INFO Agent received command: run
2022-07-13 10:02:41 INFO Agent starting run with config:
	batch_size: 32
	d_model: 32
	decoder_heads: 3
	decoder_layers: 6
	early_stopping: 0.4979790245520536
	embedding_layers: 4
	encoder_heads: 1
	encoder_layers: 12
	learning_rate: 0.0001222996919349208
	max_steps: 2927
	net_layers: 3
	noise_std: 2.196437529856112
2022-07-13 10:02:41 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=32 --decoder_heads=3 --decoder_layers=6 --early_stopping=0.4979790245520536 --embedding_layers=4 --encoder_heads=1 --encoder_layers=12 --learning_rate=0.0001222996919349208 --max_steps=2927 --net_layers=3 --noise_std=2.196437529856112
2022-07-13 10:02:46 INFO Running runs: ['wdj5mr3h']
2022-07-13 10:04:23 INFO Cleaning up finished run: wdj5mr3h
2022-07-13 10:04:24 INFO Agent received command: run
2022-07-13 10:04:24 INFO Agent starting run with config:
	batch_size: 64
	d_model: 74
	decoder_heads: 2
	decoder_layers: 10
	early_stopping: 0.8800115998558992
	embedding_layers: 7
	encoder_heads: 2
	encoder_layers: 11
	learning_rate: 0.0009712328645110146
	max_steps: 2172
	net_layers: 3
	noise_std: 1.3081410826915836
2022-07-13 10:04:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=74 --decoder_heads=2 --decoder_layers=10 --early_stopping=0.8800115998558992 --embedding_layers=7 --encoder_heads=2 --encoder_layers=11 --learning_rate=0.0009712328645110146 --max_steps=2172 --net_layers=3 --noise_std=1.3081410826915836
2022-07-13 10:09:41 INFO Running runs: []
2022-07-13 10:09:42 INFO Agent received command: run
2022-07-13 10:09:42 INFO Agent starting run with config:
	batch_size: 128
	d_model: 83
	decoder_heads: 3
	decoder_layers: 10
	early_stopping: 0.08436188162806137
	embedding_layers: 3
	encoder_heads: 2
	encoder_layers: 11
	learning_rate: 0.0001172170822573829
	max_steps: 4607
	net_layers: 2
	noise_std: 2.5790682809606125
2022-07-13 10:09:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=83 --decoder_heads=3 --decoder_layers=10 --early_stopping=0.08436188162806137 --embedding_layers=3 --encoder_heads=2 --encoder_layers=11 --learning_rate=0.0001172170822573829 --max_steps=4607 --net_layers=2 --noise_std=2.5790682809606125
2022-07-13 10:09:47 INFO Running runs: ['rq0otrad']
2022-07-13 10:11:35 INFO Cleaning up finished run: rq0otrad
2022-07-13 10:11:36 INFO Agent received command: run
2022-07-13 10:11:36 INFO Agent starting run with config:
	batch_size: 128
	d_model: 73
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.36414000126526885
	embedding_layers: 8
	encoder_heads: 5
	encoder_layers: 4
	learning_rate: 0.000539445601379303
	max_steps: 3394
	net_layers: 3
	noise_std: 0.7561949102225456
2022-07-13 10:11:36 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=73 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.36414000126526885 --embedding_layers=8 --encoder_heads=5 --encoder_layers=4 --learning_rate=0.000539445601379303 --max_steps=3394 --net_layers=3 --noise_std=0.7561949102225456
2022-07-13 10:11:41 INFO Running runs: ['qakz00wd']
2022-07-13 10:12:22 INFO Running runs: []
2022-07-13 10:12:22 INFO Agent received command: run
2022-07-13 10:12:22 INFO Agent starting run with config:
	lightgbm_learning_rate: 9.024719149086471e-05
	max_bin: 106
	max_depth: 11
	min_data_in_leaf: 29
	num_iterations: 629
	num_leaves: 39
2022-07-13 10:12:22 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=9.024719149086471e-05 --max_bin=106 --max_depth=11 --min_data_in_leaf=29 --num_iterations=629 --num_leaves=39
2022-07-13 10:12:28 INFO Running runs: ['15jih4na']
2022-07-13 10:12:43 INFO Cleaning up finished run: 15jih4na
2022-07-13 10:12:44 INFO Agent received command: run
2022-07-13 10:12:44 INFO Agent starting run with config:
	lightgbm_learning_rate: 4.361718774745228e-05
	max_bin: 217
	max_depth: 32
	min_data_in_leaf: 14
	num_iterations: 781
	num_leaves: 19
2022-07-13 10:12:44 INFO About to run command: /usr/bin/env python train.py --model LightGBM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --lightgbm_learning_rate=4.361718774745228e-05 --max_bin=217 --max_depth=32 --min_data_in_leaf=14 --num_iterations=781 --num_leaves=19
2022-07-13 10:12:49 INFO Running runs: ['mgpqu6r6']
2022-07-13 10:17:09 INFO Running runs: []
2022-07-13 10:17:10 INFO Agent received command: run
2022-07-13 10:17:10 INFO Agent starting run with config:
	batch_size: 128
	d_model: 91
	decoder_heads: 1
	decoder_layers: 2
	early_stopping: 0.8197026392916145
	embedding_layers: 7
	encoder_heads: 5
	encoder_layers: 5
	learning_rate: 0.00010323615078048852
	max_steps: 2439
	net_layers: 8
	noise_std: 0.5777544434714618
2022-07-13 10:17:10 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=91 --decoder_heads=1 --decoder_layers=2 --early_stopping=0.8197026392916145 --embedding_layers=7 --encoder_heads=5 --encoder_layers=5 --learning_rate=0.00010323615078048852 --max_steps=2439 --net_layers=8 --noise_std=0.5777544434714618
2022-07-13 10:17:15 INFO Running runs: ['ibmi8isa']
2022-07-13 10:18:47 INFO Cleaning up finished run: ibmi8isa
2022-07-13 10:18:47 INFO Agent received command: run
2022-07-13 10:18:47 INFO Agent starting run with config:
	batch_size: 128
	d_model: 104
	decoder_heads: 4
	decoder_layers: 9
	early_stopping: 0.3526744406369423
	embedding_layers: 7
	encoder_heads: 5
	encoder_layers: 11
	learning_rate: 0.0006560299566732266
	max_steps: 3824
	net_layers: 5
	noise_std: 0.17208881054611566
2022-07-13 10:18:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=104 --decoder_heads=4 --decoder_layers=9 --early_stopping=0.3526744406369423 --embedding_layers=7 --encoder_heads=5 --encoder_layers=11 --learning_rate=0.0006560299566732266 --max_steps=3824 --net_layers=5 --noise_std=0.17208881054611566
2022-07-13 10:18:52 INFO Running runs: ['ofvwpolp']
2022-07-13 10:21:57 INFO Running runs: []
2022-07-13 10:21:57 INFO Agent received command: run
2022-07-13 10:21:57 INFO Agent starting run with config:
	batch_size: 128
	d_model: 32
	decoder_heads: 3
	decoder_layers: 9
	early_stopping: 0.7483740297952353
	embedding_layers: 7
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.0003319281349275638
	max_steps: 3794
	net_layers: 3
	noise_std: 0.1777777742257626
2022-07-13 10:21:57 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=32 --decoder_heads=3 --decoder_layers=9 --early_stopping=0.7483740297952353 --embedding_layers=7 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.0003319281349275638 --max_steps=3794 --net_layers=3 --noise_std=0.1777777742257626
2022-07-13 10:22:02 INFO Running runs: ['qs0h07ql']
2022-07-13 10:29:38 INFO Cleaning up finished run: qs0h07ql
2022-07-13 10:29:39 INFO Agent received command: run
2022-07-13 10:29:39 INFO Agent starting run with config:
	batch_size: 32
	d_model: 127
	decoder_heads: 1
	decoder_layers: 11
	early_stopping: 0.8910503067044022
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 9
	learning_rate: 0.00012188825062764828
	max_steps: 4346
	net_layers: 3
	noise_std: 0.11223185322597998
2022-07-13 10:29:39 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=127 --decoder_heads=1 --decoder_layers=11 --early_stopping=0.8910503067044022 --embedding_layers=6 --encoder_heads=2 --encoder_layers=9 --learning_rate=0.00012188825062764828 --max_steps=4346 --net_layers=3 --noise_std=0.11223185322597998
2022-07-13 10:29:44 INFO Running runs: ['clc4lsgh']
2022-07-13 10:41:15 INFO Cleaning up finished run: clc4lsgh
2022-07-13 10:41:17 INFO Agent received command: run
2022-07-13 10:41:17 INFO Agent starting run with config:
	batch_size: 64
	d_model: 125
	decoder_heads: 3
	decoder_layers: 7
	early_stopping: 0.6436402875475384
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 5
	learning_rate: 0.00015764580200296977
	max_steps: 2003
	net_layers: 4
	noise_std: 0.2478541524357011
2022-07-13 10:41:17 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=125 --decoder_heads=3 --decoder_layers=7 --early_stopping=0.6436402875475384 --embedding_layers=6 --encoder_heads=2 --encoder_layers=5 --learning_rate=0.00015764580200296977 --max_steps=2003 --net_layers=4 --noise_std=0.2478541524357011
2022-07-13 10:41:22 INFO Running runs: ['czgnpv4s']
2022-07-13 10:46:19 INFO Cleaning up finished run: czgnpv4s
2022-07-13 10:46:19 INFO Agent received command: run
2022-07-13 10:46:19 INFO Agent starting run with config:
	batch_size: 32
	d_model: 47
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.1268845688516485
	embedding_layers: 7
	encoder_heads: 2
	encoder_layers: 12
	learning_rate: 0.0001441220550549259
	max_steps: 2839
	net_layers: 4
	noise_std: 0.20740058107375317
2022-07-13 10:46:19 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=47 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.1268845688516485 --embedding_layers=7 --encoder_heads=2 --encoder_layers=12 --learning_rate=0.0001441220550549259 --max_steps=2839 --net_layers=4 --noise_std=0.20740058107375317
2022-07-13 10:46:24 INFO Running runs: ['e9n2k6z6']
2022-07-13 10:50:55 INFO Cleaning up finished run: e9n2k6z6
2022-07-13 10:50:56 INFO Agent received command: run
2022-07-13 10:50:56 INFO Agent starting run with config:
	batch_size: 128
	d_model: 66
	decoder_heads: 1
	decoder_layers: 7
	early_stopping: 0.441480483456998
	embedding_layers: 3
	encoder_heads: 1
	encoder_layers: 12
	learning_rate: 0.0008652682007081195
	max_steps: 4959
	net_layers: 6
	noise_std: 0.3179832860687015
2022-07-13 10:50:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=66 --decoder_heads=1 --decoder_layers=7 --early_stopping=0.441480483456998 --embedding_layers=3 --encoder_heads=1 --encoder_layers=12 --learning_rate=0.0008652682007081195 --max_steps=4959 --net_layers=6 --noise_std=0.3179832860687015
2022-07-13 10:51:01 INFO Running runs: ['yhewjrnb']
2022-07-13 10:58:55 INFO Cleaning up finished run: yhewjrnb
2022-07-13 10:58:56 INFO Agent received command: run
2022-07-13 10:58:56 INFO Agent starting run with config:
	batch_size: 128
	d_model: 53
	decoder_heads: 3
	decoder_layers: 8
	early_stopping: 0.2326515725755988
	embedding_layers: 5
	encoder_heads: 2
	encoder_layers: 9
	learning_rate: 0.0009277215364559244
	max_steps: 4977
	net_layers: 3
	noise_std: 0.14224152877348792
2022-07-13 10:58:56 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=53 --decoder_heads=3 --decoder_layers=8 --early_stopping=0.2326515725755988 --embedding_layers=5 --encoder_heads=2 --encoder_layers=9 --learning_rate=0.0009277215364559244 --max_steps=4977 --net_layers=3 --noise_std=0.14224152877348792
2022-07-13 10:59:01 INFO Running runs: ['89yphchy']
2022-07-13 11:05:33 INFO Cleaning up finished run: 89yphchy
2022-07-13 11:05:34 INFO Agent received command: run
2022-07-13 11:05:34 INFO Agent starting run with config:
	batch_size: 32
	d_model: 63
	decoder_heads: 1
	decoder_layers: 9
	early_stopping: 0.6327963094344837
	embedding_layers: 6
	encoder_heads: 3
	encoder_layers: 4
	learning_rate: 0.0004125094821551161
	max_steps: 4135
	net_layers: 6
	noise_std: 0.21553801035335024
2022-07-13 11:05:34 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=63 --decoder_heads=1 --decoder_layers=9 --early_stopping=0.6327963094344837 --embedding_layers=6 --encoder_heads=3 --encoder_layers=4 --learning_rate=0.0004125094821551161 --max_steps=4135 --net_layers=6 --noise_std=0.21553801035335024
2022-07-13 11:05:39 INFO Running runs: ['pozkqhjs']
2022-07-13 12:27:22 INFO Running runs: []
2022-07-13 12:27:23 INFO Agent received command: run
2022-07-13 12:27:23 INFO Agent starting run with config:
	batch_size: 64
	d_model: 92
	decoder_heads: 2
	decoder_layers: 4
	early_stopping: 0.8710702126966721
	embedding_layers: 6
	encoder_heads: 1
	encoder_layers: 8
	learning_rate: 0.0004424698525978427
	max_steps: 2055
	net_layers: 3
	noise_std: 0.6807637692119843
2022-07-13 12:27:23 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=92 --decoder_heads=2 --decoder_layers=4 --early_stopping=0.8710702126966721 --embedding_layers=6 --encoder_heads=1 --encoder_layers=8 --learning_rate=0.0004424698525978427 --max_steps=2055 --net_layers=3 --noise_std=0.6807637692119843
2022-07-13 12:27:28 INFO Running runs: ['hl8y8dia']
2022-07-13 12:27:28 INFO Cleaning up finished run: hl8y8dia
2022-07-13 12:27:29 INFO Agent received command: run
2022-07-13 12:27:29 INFO Agent starting run with config:
	batch_size: 32
	d_model: 126
	decoder_heads: 1
	decoder_layers: 4
	early_stopping: 0.2886178402281633
	embedding_layers: 4
	encoder_heads: 5
	encoder_layers: 1
	learning_rate: 0.000593117793995666
	max_steps: 2790
	net_layers: 1
	noise_std: 2.250512184024137
2022-07-13 12:27:29 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=126 --decoder_heads=1 --decoder_layers=4 --early_stopping=0.2886178402281633 --embedding_layers=4 --encoder_heads=5 --encoder_layers=1 --learning_rate=0.000593117793995666 --max_steps=2790 --net_layers=1 --noise_std=2.250512184024137
2022-07-13 12:28:24 INFO Running runs: []
2022-07-13 12:28:24 INFO Agent received command: run
2022-07-13 12:28:24 INFO Agent starting run with config:
	batch_size: 128
	d_model: 128
	decoder_heads: 3
	decoder_layers: 2
	early_stopping: 0.6893872396982241
	embedding_layers: 5
	encoder_heads: 4
	encoder_layers: 3
	learning_rate: 0.00028210618333103656
	max_steps: 2150
	net_layers: 3
	noise_std: 0.32284433148535796
2022-07-13 12:28:24 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=128 --decoder_heads=3 --decoder_layers=2 --early_stopping=0.6893872396982241 --embedding_layers=5 --encoder_heads=4 --encoder_layers=3 --learning_rate=0.00028210618333103656 --max_steps=2150 --net_layers=3 --noise_std=0.32284433148535796
2022-07-13 12:28:29 INFO Running runs: ['pvb0amgt']
2022-07-13 12:28:29 INFO Cleaning up finished run: pvb0amgt
2022-07-13 12:28:30 INFO Agent received command: run
2022-07-13 12:28:30 INFO Agent starting run with config:
	batch_size: 64
	d_model: 114
	decoder_heads: 5
	decoder_layers: 3
	early_stopping: 0.348259427007998
	embedding_layers: 1
	encoder_heads: 2
	encoder_layers: 4
	learning_rate: 0.00029455193458393557
	max_steps: 2173
	net_layers: 3
	noise_std: 0.40958295776675513
2022-07-13 12:28:30 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=114 --decoder_heads=5 --decoder_layers=3 --early_stopping=0.348259427007998 --embedding_layers=1 --encoder_heads=2 --encoder_layers=4 --learning_rate=0.00029455193458393557 --max_steps=2173 --net_layers=3 --noise_std=0.40958295776675513
2022-07-13 12:29:36 INFO Running runs: []
2022-07-13 12:29:37 INFO Agent received command: run
2022-07-13 12:29:37 INFO Agent starting run with config:
	batch_size: 128
	d_model: 97
	decoder_heads: 1
	decoder_layers: 1
	early_stopping: 0.712618201847973
	embedding_layers: 7
	encoder_heads: 4
	encoder_layers: 1
	learning_rate: 0.0004751882458415087
	max_steps: 2457
	net_layers: 5
	noise_std: 2.2349503584817074
2022-07-13 12:29:37 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=97 --decoder_heads=1 --decoder_layers=1 --early_stopping=0.712618201847973 --embedding_layers=7 --encoder_heads=4 --encoder_layers=1 --learning_rate=0.0004751882458415087 --max_steps=2457 --net_layers=5 --noise_std=2.2349503584817074
2022-07-13 12:29:42 INFO Running runs: ['7s0ong7r']
2022-07-13 12:29:42 INFO Cleaning up finished run: 7s0ong7r
2022-07-13 12:29:42 INFO Agent received command: run
2022-07-13 12:29:42 INFO Agent starting run with config:
	batch_size: 64
	d_model: 67
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.09288784045903208
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 1
	learning_rate: 0.00015169273593844168
	max_steps: 4280
	net_layers: 4
	noise_std: 2.317712051707819
2022-07-13 12:29:42 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=67 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.09288784045903208 --embedding_layers=6 --encoder_heads=2 --encoder_layers=1 --learning_rate=0.00015169273593844168 --max_steps=4280 --net_layers=4 --noise_std=2.317712051707819
2022-07-13 12:29:47 INFO Running runs: ['6ywuy9rz']
2022-07-13 12:29:47 INFO Cleaning up finished run: 6ywuy9rz
2022-07-13 12:29:48 INFO Agent received command: run
2022-07-13 12:29:48 INFO Agent starting run with config:
	batch_size: 128
	d_model: 56
	decoder_heads: 3
	decoder_layers: 1
	early_stopping: 0.2048280727118459
	embedding_layers: 5
	encoder_heads: 3
	encoder_layers: 10
	learning_rate: 0.0004467510881116706
	max_steps: 3575
	net_layers: 7
	noise_std: 0.3465410865784302
2022-07-13 12:29:48 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=56 --decoder_heads=3 --decoder_layers=1 --early_stopping=0.2048280727118459 --embedding_layers=5 --encoder_heads=3 --encoder_layers=10 --learning_rate=0.0004467510881116706 --max_steps=3575 --net_layers=7 --noise_std=0.3465410865784302
2022-07-13 12:33:21 INFO Running runs: []
2022-07-13 12:33:22 INFO Agent received command: run
2022-07-13 12:33:22 INFO Agent starting run with config:
	batch_size: 128
	d_model: 114
	decoder_heads: 3
	decoder_layers: 5
	early_stopping: 0.8652935808326357
	embedding_layers: 6
	encoder_heads: 2
	encoder_layers: 2
	learning_rate: 0.00038589596250568223
	max_steps: 2579
	net_layers: 8
	noise_std: 1.425770067430549
2022-07-13 12:33:22 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=128 --d_model=114 --decoder_heads=3 --decoder_layers=5 --early_stopping=0.8652935808326357 --embedding_layers=6 --encoder_heads=2 --encoder_layers=2 --learning_rate=0.00038589596250568223 --max_steps=2579 --net_layers=8 --noise_std=1.425770067430549
2022-07-13 12:33:27 INFO Running runs: ['4sjo9ros']
2022-07-13 12:35:47 INFO Running runs: []
2022-07-13 12:35:47 INFO Agent received command: run
2022-07-13 12:35:47 INFO Agent starting run with config:
	batch_size: 64
	d_model: 108
	decoder_heads: 1
	decoder_layers: 9
	early_stopping: 0.2699458084796943
	embedding_layers: 7
	encoder_heads: 1
	encoder_layers: 4
	learning_rate: 0.0001541169846760307
	max_steps: 2923
	net_layers: 7
	noise_std: 1.741481106229657
2022-07-13 12:35:47 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=108 --decoder_heads=1 --decoder_layers=9 --early_stopping=0.2699458084796943 --embedding_layers=7 --encoder_heads=1 --encoder_layers=4 --learning_rate=0.0001541169846760307 --max_steps=2923 --net_layers=7 --noise_std=1.741481106229657
2022-07-13 12:35:52 INFO Running runs: ['wxmvkxxu']
2022-07-13 12:41:13 INFO Cleaning up finished run: wxmvkxxu
2022-07-13 12:41:14 INFO Agent received command: run
2022-07-13 12:41:14 INFO Agent starting run with config:
	batch_size: 64
	d_model: 113
	decoder_heads: 4
	decoder_layers: 7
	early_stopping: 0.8904005434617682
	embedding_layers: 3
	encoder_heads: 5
	encoder_layers: 8
	learning_rate: 0.00025303365541574495
	max_steps: 3201
	net_layers: 7
	noise_std: 0.49647407721110054
2022-07-13 12:41:14 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=113 --decoder_heads=4 --decoder_layers=7 --early_stopping=0.8904005434617682 --embedding_layers=3 --encoder_heads=5 --encoder_layers=8 --learning_rate=0.00025303365541574495 --max_steps=3201 --net_layers=7 --noise_std=0.49647407721110054
2022-07-13 12:41:19 INFO Running runs: ['t5niop9s']
2022-07-13 12:49:07 INFO Cleaning up finished run: t5niop9s
2022-07-13 12:49:07 INFO Agent received command: run
2022-07-13 12:49:07 INFO Agent starting run with config:
	batch_size: 32
	d_model: 46
	decoder_heads: 2
	decoder_layers: 3
	early_stopping: 0.6859472521026218
	embedding_layers: 7
	encoder_heads: 4
	encoder_layers: 11
	learning_rate: 0.00015260023501136909
	max_steps: 3191
	net_layers: 6
	noise_std: 0.23995438894893964
2022-07-13 12:49:07 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=32 --d_model=46 --decoder_heads=2 --decoder_layers=3 --early_stopping=0.6859472521026218 --embedding_layers=7 --encoder_heads=4 --encoder_layers=11 --learning_rate=0.00015260023501136909 --max_steps=3191 --net_layers=6 --noise_std=0.23995438894893964
2022-07-13 12:49:12 INFO Running runs: ['0tmky8vr']
2022-07-13 12:55:45 INFO Cleaning up finished run: 0tmky8vr
2022-07-13 12:55:46 INFO Agent received command: run
2022-07-13 12:55:46 INFO Agent starting run with config:
	batch_size: 64
	d_model: 48
	decoder_heads: 2
	decoder_layers: 5
	early_stopping: 0.39694889238516945
	embedding_layers: 8
	encoder_heads: 2
	encoder_layers: 9
	learning_rate: 0.00013900335342232462
	max_steps: 3487
	net_layers: 7
	noise_std: 0.1534623730781387
2022-07-13 12:55:46 INFO About to run command: /usr/bin/env python train.py --model LSAM --dataset 4 --k 4 --repeats 1 --notes "hyperparameter search" --batch_size=64 --d_model=48 --decoder_heads=2 --decoder_layers=5 --early_stopping=0.39694889238516945 --embedding_layers=8 --encoder_heads=2 --encoder_layers=9 --learning_rate=0.00013900335342232462 --max_steps=3487 --net_layers=7 --noise_std=0.1534623730781387
2022-07-13 12:55:51 INFO Running runs: ['dlgu94yk']
