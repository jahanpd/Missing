/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
name: Supervised Classification, features: MiceProtein
{'X_train': {'cols': 0.015498904387793278, 'rows': 0.48010973936899864}, 'X_valid': {'cols': 0.017741821020509547, 'rows': 0.48633879781420764}, 'X_test': {'cols': 0.018518518518518517, 'rows': 0.5222222222222223}}
dataset sizes
(776, 77) (183, 77) (270, 77)
dropped dataset sizes
(403, 77) (94, 77) (129, 77)
key: 8619, k: 1/4, dataset: 40966, missing: None, impute: None
training gbm for 5000 epochs
{'num_leaves': 13, 'max_bin': 23, 'max_depth': 6, 'min_data_in_leaf': 10, 'learning_rate': 0.12344592665717158, 'num_iterations': 956, 'objective': 'softmax', 'verbose': -1, 'num_class': 8}
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[299]	valid_0's multi_logloss: 0.0357471
strategy:None, acc gbm: 0.9814814814814815
strategy:None, nll xbg:0.05693495646119118
name: Supervised Classification, features: MiceProtein
{'X_train': {'cols': 0.016517285531370038, 'rows': 0.48450704225352115}, 'X_valid': {'cols': 0.018459069020866775, 'rows': 0.4887640449438202}, 'X_test': {'cols': 0.014718614718614718, 'rows': 0.48148148148148145}}
dataset sizes
(768, 77) (178, 77) (270, 77)
dropped dataset sizes
(392, 77) (91, 77) (140, 77)
key: 5908, k: 2/4, dataset: 40966, missing: None, impute: None
training gbm for 5000 epochs
{'num_leaves': 13, 'max_bin': 23, 'max_depth': 6, 'min_data_in_leaf': 10, 'learning_rate': 0.12344592665717158, 'num_iterations': 956, 'objective': 'softmax', 'verbose': -1, 'num_class': 8}
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[171]	valid_0's multi_logloss: 0.0577621
/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
strategy:None, acc gbm: 0.9888888888888889
strategy:None, nll xbg:0.041423361748456955
name: Supervised Classification, features: MiceProtein
{'X_train': {'cols': 0.015755562267190173, 'rows': 0.4664082687338501}, 'X_valid': {'cols': 0.01807470879635828, 'rows': 0.5463917525773195}, 'X_test': {'cols': 0.017075517075517074, 'rows': 0.4703703703703704}}
dataset sizes
(816, 77) (194, 77) (270, 77)
dropped dataset sizes
(434, 77) (88, 77) (143, 77)
key: 8922, k: 3/4, dataset: 40966, missing: None, impute: None
training gbm for 5000 epochs
{'num_leaves': 13, 'max_bin': 23, 'max_depth': 6, 'min_data_in_leaf': 10, 'learning_rate': 0.12344592665717158, 'num_iterations': 956, 'objective': 'softmax', 'verbose': -1, 'num_class': 8}
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[348]	valid_0's multi_logloss: 0.0148099
strategy:None, acc gbm: 0.9814814814814815
strategy:None, nll xbg:0.06475542485713959
name: Supervised Classification, features: MiceProtein
{'X_train': {'cols': 0.015069169960474308, 'rows': 0.4578804347826087}, 'X_valid': {'cols': 0.0195511010728402, 'rows': 0.5543478260869565}, 'X_test': {'cols': 0.01683501683501683, 'rows': 0.48148148148148145}}
dataset sizes
(776, 77) (184, 77) (270, 77)
dropped dataset sizes
(421, 77) (82, 77) (140, 77)
key: 6089, k: 4/4, dataset: 40966, missing: None, impute: None
training gbm for 5000 epochs
{'num_leaves': 13, 'max_bin': 23, 'max_depth': 6, 'min_data_in_leaf': 10, 'learning_rate': 0.12344592665717158, 'num_iterations': 956, 'objective': 'softmax', 'verbose': -1, 'num_class': 8}
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[273]	valid_0's multi_logloss: 0.0728454
strategy:None, acc gbm: 0.9555555555555556
strategy:None, nll xbg:0.0894058346748352