name: Supervised Classification, features: dresses-sales
{'X_train': {'cols': 0.13369467028003612, 'rows': 0.8130081300813008}, 'X_valid': {'cols': 0.15053763440860216, 'rows': 0.7741935483870968}, 'X_test': {'cols': 0.14166666666666666, 'rows': 0.81}}
dataset sizes
(380, 12) (93, 12) (100, 12)
dropped dataset sizes
(71, 12) (21, 12) (19, 12)
key: 2197, k: 1/20, dataset: 23381, missing: None, impute: None
{'d_model': 32, 'embedding_size': 32, 'embedding_layers': 2, 'encoder_heads': 5, 'encoder_layers': 2, 'decoder_heads': 5, 'decoder_layers': 2, 'net_size': 32, 'net_layers': 2, 'max_steps': 1000, 'learning_rate': 0.001, 'early_stop': 0.5, 'noise_std': 5.0}
MAP
2 device(s)
  0%|                                                                                                                                                                                                                                                             | 0/100 [00:00<?, ?it/s]
  0%|                                                                                                                                                                                                                                                              | 0/11 [00:00<?, ?it/s]



  0%|                                                                                                                                                                                                                                                              | 0/11 [00:00<?, ?it/s]
early stop or epoch
2 device(s)
optimizer: adam, lr: 0.0010000000474974513, batch_size=32




  0%|                                                                                                                                                                                                                                                              | 0/11 [00:00<?, ?it/s]

Final test loss: 1.3840311765670776, epoch: 58, time: 0:00:22.812819
(1000, 2)

 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 11/15 [00:03<00:01,  3.40it/s]
-0.47335583 -0.64084536
0.53328884 0.4667111
strategy:None, acc lsam:0.4099999964237213
strategy:None, nll lsam:1.4144518375396729
training gbm for 5000 epochs
{'num_leaves': 31, 'max_bin': 155, 'max_depth': -1, 'min_data_in_leaf': 20, 'learning_rate': 0.001, 'num_iterations': 100, 'objective': 'softmax', 'verbose': -1, 'num_class': 2}
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's multi_logloss: 0.685147
strategy:None, acc gbm: 0.61
strategy:None, nll xbg:1.3685330152511597
name: Supervised Classification, features: dresses-sales
{'X_train': {'cols': 0.14047619047619048, 'rows': 0.7896103896103897}, 'X_valid': {'cols': 0.12800687285223367, 'rows': 0.7835051546391752}, 'X_test': {'cols': 0.14416666666666667, 'rows': 0.81}}
dataset sizes
(386, 12) (97, 12) (100, 12)
dropped dataset sizes
(81, 12) (21, 12) (19, 12)
key: 2353, k: 2/20, dataset: 23381, missing: None, impute: None
{'d_model': 32, 'embedding_size': 32, 'embedding_layers': 2, 'encoder_heads': 5, 'encoder_layers': 2, 'decoder_heads': 5, 'decoder_layers': 2, 'net_size': 32, 'net_layers': 2, 'max_steps': 1000, 'learning_rate': 0.001, 'early_stop': 0.5, 'noise_std': 5.0}
MAP
2 device(s)
/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
  0%|                                                                                                                                                                                                                                                             | 0/100 [00:00<?, ?it/s]

  0%|                                                                                                                                                                                                                                                              | 0/12 [00:00<?, ?it/s]
early stop or epoch
2 device(s)
  0%|                                                                                                                                                                                                                                                              | 0/83 [00:00<?, ?it/s]

 31%|████████████████████████████████████████████████████████████████▏                                                                                                                                            | 26/83 [00:13<00:10,  5.47it/s, l=1.4, tl=inf, tlc=1.39, tc=0, e=-.693]
  0%|                                                                                                                                                                                                                                                              | 0/12 [00:00<?, ?it/s]

Final test loss: 1.3862764835357666, epoch: 52, time: 0:00:16.548654
(1000, 2)
softmax
-1.2435476 -1.3121502
0.5127277 0.48727238
strategy:None, acc lsam:0.4899999797344208
strategy:None, nll lsam:1.3879276514053345
training gbm for 5000 epochs
{'num_leaves': 31, 'max_bin': 155, 'max_depth': -1, 'min_data_in_leaf': 20, 'learning_rate': 0.001, 'num_iterations': 100, 'objective': 'softmax', 'verbose': -1, 'num_class': 2}
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[100]	valid_0's multi_logloss: 0.674137
strategy:None, acc gbm: 0.53
strategy:None, nll xbg:1.3783332109451294
name: Supervised Classification, features: dresses-sales
{'X_train': {'cols': 0.14465408805031446, 'rows': 0.8194070080862533}, 'X_valid': {'cols': 0.13620071684587814, 'rows': 0.7634408602150538}, 'X_test': {'cols': 0.14833333333333334, 'rows': 0.81}}
dataset sizes
(376, 12) (93, 12) (100, 12)
dropped dataset sizes
(68, 12) (22, 12) (19, 12)
key: 5370, k: 3/20, dataset: 23381, missing: None, impute: None
{'d_model': 32, 'embedding_size': 32, 'embedding_layers': 2, 'encoder_heads': 5, 'encoder_layers': 2, 'decoder_heads': 5, 'decoder_layers': 2, 'net_size': 32, 'net_layers': 2, 'max_steps': 1000, 'learning_rate': 0.001, 'early_stop': 0.5, 'noise_std': 5.0}
MAP
2 device(s)
/home/jahan/.conda/envs/jax/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
  0%|                                                                                                                                                                                                                                                             | 0/100 [00:00<?, ?it/s]

 17%|██████████████████████████████████████▌                                                                                                                                                                                            | 17/100 [00:07<00:16,  5.03it/s, loss=0.41949287]
  0%|                                                                                                                                                                                                                                                              | 0/11 [00:00<?, ?it/s]
early stop or epoch
2 device(s)



 37%|██████████████████████████████████████████████████████████████████████████▊                                                                                                                                 | 33/90 [00:13<00:09,  5.99it/s, l=1.41, tl=inf, tlc=1.38, tc=0, e=-.693]


  0%|                                                                                                                                                                                                                                                              | 0/11 [00:00<?, ?it/s]

  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
(1000, 2)
softmax
0.038959537 -2.1473396
0.70276743 0.2972326
strategy:None, acc lsam:0.5899999737739563
strategy:None, nll lsam:1.406302809715271
training gbm for 5000 epochs
{'num_leaves': 31, 'max_bin': 155, 'max_depth': -1, 'min_data_in_leaf': 20, 'learning_rate': 0.001, 'num_iterations': 100, 'objective': 'softmax', 'verbose': -1, 'num_class': 2}
Training until validation scores don't improve for 100 rounds
Did not meet early stopping. Best iteration is:
[33]	valid_0's multi_logloss: 0.692998
strategy:None, acc gbm: 0.46
strategy:None, nll xbg:1.3882720470428467
name: Supervised Classification, features: dresses-sales
{'X_train': {'cols': 0.14560439560439561, 'rows': 0.804945054945055}, 'X_valid': {'cols': 0.1331521739130435, 'rows': 0.717391304347826}, 'X_test': {'cols': 0.12833333333333333, 'rows': 0.83}}
dataset sizes
(368, 12) (92, 12) (100, 12)
dropped dataset sizes
(74, 12) (26, 12) (17, 12)
key: 1355, k: 4/20, dataset: 23381, missing: None, impute: None
{'d_model': 32, 'embedding_size': 32, 'embedding_layers': 2, 'encoder_heads': 5, 'encoder_layers': 2, 'decoder_heads': 5, 'decoder_layers': 2, 'net_size': 32, 'net_layers': 2, 'max_steps': 1000, 'learning_rate': 0.001, 'early_stop': 0.5, 'noise_std': 5.0}
MAP
2 device(s)
optimizer: adabelief, lr: 0.001, batch_size=32
  0%|                                                                                                                                                                                                                                                             | 0/100 [00:00<?, ?it/s]
